{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook dealing with the final preprocessing steps for the neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import glob\n",
    "import random\n",
    "random.seed(1991)\n",
    "#torch.set_default_tensor_type('torch.cuda.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1991)\n",
    "if not torch.cuda.is_available():\n",
    "    \n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_compounds_list = pkl.load( open( \"/data/dharp/compounding/datasets/novel_compounds_list.pkl\", \"rb\" ) )\n",
    "m, h = zip(*novel_compounds_list)\n",
    "heads_list=list(set(h))\n",
    "modifiers_list=list(set(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_n</th>\n",
       "      <td>0.946819</td>\n",
       "      <td>-0.215910</td>\n",
       "      <td>-0.078663</td>\n",
       "      <td>0.098186</td>\n",
       "      <td>0.031344</td>\n",
       "      <td>-0.128517</td>\n",
       "      <td>-0.040655</td>\n",
       "      <td>-0.052660</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.114906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_n</th>\n",
       "      <td>0.802237</td>\n",
       "      <td>-0.200831</td>\n",
       "      <td>-0.027173</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>-0.026429</td>\n",
       "      <td>-0.094564</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.020185</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>-0.060455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014317</td>\n",
       "      <td>-0.006173</td>\n",
       "      <td>0.104329</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>-0.047576</td>\n",
       "      <td>0.021880</td>\n",
       "      <td>0.034428</td>\n",
       "      <td>-0.081614</td>\n",
       "      <td>-0.009093</td>\n",
       "      <td>-0.025753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa_n</th>\n",
       "      <td>0.538223</td>\n",
       "      <td>-0.113592</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.054010</td>\n",
       "      <td>-0.015412</td>\n",
       "      <td>-0.045805</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>-0.008608</td>\n",
       "      <td>0.024122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.023796</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>-0.077713</td>\n",
       "      <td>0.033013</td>\n",
       "      <td>-0.003302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa_n</th>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-0.011107</td>\n",
       "      <td>0.032347</td>\n",
       "      <td>-0.008947</td>\n",
       "      <td>-0.011360</td>\n",
       "      <td>-0.002168</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>-0.008244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064327</td>\n",
       "      <td>-0.017990</td>\n",
       "      <td>0.271208</td>\n",
       "      <td>0.101174</td>\n",
       "      <td>-0.167501</td>\n",
       "      <td>0.139280</td>\n",
       "      <td>0.114520</td>\n",
       "      <td>-0.188355</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>-0.082619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa_n</th>\n",
       "      <td>0.002501</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>-0.001491</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>-0.011237</td>\n",
       "      <td>-0.007322</td>\n",
       "      <td>-0.002661</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081080</td>\n",
       "      <td>-0.024664</td>\n",
       "      <td>0.289407</td>\n",
       "      <td>0.111249</td>\n",
       "      <td>-0.173599</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.120406</td>\n",
       "      <td>-0.197147</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>-0.085016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6    \\\n",
       "common                                                                          \n",
       "a_n      0.946819 -0.215910 -0.078663  0.098186  0.031344 -0.128517 -0.040655   \n",
       "aa_n     0.802237 -0.200831 -0.027173  0.068958 -0.026429 -0.094564  0.034699   \n",
       "aaa_n    0.538223 -0.113592  0.006146  0.054010 -0.015412 -0.045805  0.012455   \n",
       "aaaa_n   0.006426  0.002476  0.000166 -0.011107  0.032347 -0.008947 -0.011360   \n",
       "aaaaa_n  0.002501 -0.002978 -0.001491 -0.000103  0.019680 -0.011237 -0.007322   \n",
       "\n",
       "              7         8         9    ...       290       291       292  \\\n",
       "common                                 ...                                 \n",
       "a_n     -0.052660  0.022259  0.114906  ... -0.000052 -0.000006  0.000039   \n",
       "aa_n     0.020185  0.017012 -0.060455  ... -0.014317 -0.006173  0.104329   \n",
       "aaa_n    0.015334 -0.008608  0.024122  ...  0.019392  0.011160  0.117384   \n",
       "aaaa_n  -0.002168  0.004395 -0.008244  ... -0.064327 -0.017990  0.271208   \n",
       "aaaaa_n -0.002661  0.004790 -0.000987  ... -0.081080 -0.024664  0.289407   \n",
       "\n",
       "              293       294       295       296       297       298       299  \n",
       "common                                                                         \n",
       "a_n     -0.000040  0.000092  0.000019  0.000004  0.000010  0.000061  0.000070  \n",
       "aa_n     0.059880 -0.047576  0.021880  0.034428 -0.081614 -0.009093 -0.025753  \n",
       "aaa_n    0.046802  0.023796  0.016095  0.057174 -0.077713  0.033013 -0.003302  \n",
       "aaaa_n   0.101174 -0.167501  0.139280  0.114520 -0.188355  0.010231 -0.082619  \n",
       "aaaaa_n  0.111249 -0.173599  0.167372  0.120406 -0.197147  0.019597 -0.085016  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constituents=pd.read_pickle(\"/data/dharp/compounding/datasets/constituents_CompoundAgnostic_DecadeAgnostic_300.pkl\")\n",
    "constituents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7619 entries, a_n to zwingli_n\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float64(300)\n",
      "memory usage: 17.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_n</th>\n",
       "      <td>0.946819</td>\n",
       "      <td>-0.215910</td>\n",
       "      <td>-0.078663</td>\n",
       "      <td>0.098186</td>\n",
       "      <td>0.031344</td>\n",
       "      <td>-0.128517</td>\n",
       "      <td>-0.040655</td>\n",
       "      <td>-0.052660</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.114906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron_n</th>\n",
       "      <td>0.632065</td>\n",
       "      <td>-0.157938</td>\n",
       "      <td>-0.028958</td>\n",
       "      <td>0.063066</td>\n",
       "      <td>-0.003585</td>\n",
       "      <td>-0.006186</td>\n",
       "      <td>0.037621</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>-0.007278</td>\n",
       "      <td>-0.009055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030316</td>\n",
       "      <td>0.066355</td>\n",
       "      <td>-0.032037</td>\n",
       "      <td>-0.066770</td>\n",
       "      <td>-0.079918</td>\n",
       "      <td>-0.041611</td>\n",
       "      <td>-0.027120</td>\n",
       "      <td>-0.032024</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>-0.064226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_n</th>\n",
       "      <td>0.814786</td>\n",
       "      <td>-0.224023</td>\n",
       "      <td>-0.051034</td>\n",
       "      <td>0.065876</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>-0.142471</td>\n",
       "      <td>0.056350</td>\n",
       "      <td>0.048050</td>\n",
       "      <td>-0.043411</td>\n",
       "      <td>-0.136472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039908</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.022604</td>\n",
       "      <td>-0.006050</td>\n",
       "      <td>-0.028110</td>\n",
       "      <td>-0.031565</td>\n",
       "      <td>-0.053186</td>\n",
       "      <td>-0.058053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonment_n</th>\n",
       "      <td>0.870733</td>\n",
       "      <td>-0.149542</td>\n",
       "      <td>-0.024366</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.025059</td>\n",
       "      <td>0.029089</td>\n",
       "      <td>0.027730</td>\n",
       "      <td>-0.010006</td>\n",
       "      <td>-0.068209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043914</td>\n",
       "      <td>-0.008754</td>\n",
       "      <td>0.037302</td>\n",
       "      <td>0.017370</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.018942</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>-0.048321</td>\n",
       "      <td>-0.024098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbreviation_n</th>\n",
       "      <td>0.679414</td>\n",
       "      <td>-0.186188</td>\n",
       "      <td>-0.050210</td>\n",
       "      <td>0.102159</td>\n",
       "      <td>-0.030931</td>\n",
       "      <td>-0.105050</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.036983</td>\n",
       "      <td>-0.034680</td>\n",
       "      <td>-0.069881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.006853</td>\n",
       "      <td>-0.049400</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>0.013209</td>\n",
       "      <td>-0.002722</td>\n",
       "      <td>-0.015055</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.009347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5    \\\n",
       "head                                                                         \n",
       "a_n             0.946819 -0.215910 -0.078663  0.098186  0.031344 -0.128517   \n",
       "aaron_n         0.632065 -0.157938 -0.028958  0.063066 -0.003585 -0.006186   \n",
       "ab_n            0.814786 -0.224023 -0.051034  0.065876  0.004800 -0.142471   \n",
       "abandonment_n   0.870733 -0.149542 -0.024366  0.037407  0.000038 -0.025059   \n",
       "abbreviation_n  0.679414 -0.186188 -0.050210  0.102159 -0.030931 -0.105050   \n",
       "\n",
       "                     6         7         8         9    ...       290  \\\n",
       "head                                                    ...             \n",
       "a_n            -0.040655 -0.052660  0.022259  0.114906  ... -0.000052   \n",
       "aaron_n         0.037621  0.056535 -0.007278 -0.009055  ... -0.030316   \n",
       "ab_n            0.056350  0.048050 -0.043411 -0.136472  ...  0.039908   \n",
       "abandonment_n   0.029089  0.027730 -0.010006 -0.068209  ... -0.043914   \n",
       "abbreviation_n  0.053795  0.036983 -0.034680 -0.069881  ...  0.017008   \n",
       "\n",
       "                     291       292       293       294       295       296  \\\n",
       "head                                                                         \n",
       "a_n            -0.000006  0.000039 -0.000040  0.000092  0.000019  0.000004   \n",
       "aaron_n         0.066355 -0.032037 -0.066770 -0.079918 -0.041611 -0.027120   \n",
       "ab_n            0.015763  0.010810  0.025355 -0.022604 -0.006050 -0.028110   \n",
       "abandonment_n  -0.008754  0.037302  0.017370  0.006246  0.011758  0.018942   \n",
       "abbreviation_n  0.006853 -0.049400  0.007128 -0.004563  0.013209 -0.002722   \n",
       "\n",
       "                     297       298       299  \n",
       "head                                          \n",
       "a_n             0.000010  0.000061  0.000070  \n",
       "aaron_n        -0.032024  0.004755 -0.064226  \n",
       "ab_n           -0.031565 -0.053186 -0.058053  \n",
       "abandonment_n   0.001336 -0.048321 -0.024098  \n",
       "abbreviation_n -0.015055  0.007906  0.009347  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads=constituents.loc[constituents.index.isin(heads_list)]\n",
    "heads.index.names=['head']\n",
    "heads.info()\n",
    "heads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7901 entries, a_n to zuni_n\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float64(300)\n",
      "memory usage: 18.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_n</th>\n",
       "      <td>0.946819</td>\n",
       "      <td>-0.215910</td>\n",
       "      <td>-0.078663</td>\n",
       "      <td>0.098186</td>\n",
       "      <td>0.031344</td>\n",
       "      <td>-0.128517</td>\n",
       "      <td>-0.040655</td>\n",
       "      <td>-0.052660</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.114906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa_n</th>\n",
       "      <td>0.538223</td>\n",
       "      <td>-0.113592</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.054010</td>\n",
       "      <td>-0.015412</td>\n",
       "      <td>-0.045805</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>-0.008608</td>\n",
       "      <td>0.024122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.023796</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.057174</td>\n",
       "      <td>-0.077713</td>\n",
       "      <td>0.033013</td>\n",
       "      <td>-0.003302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aarhus_n</th>\n",
       "      <td>0.031769</td>\n",
       "      <td>0.051368</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>-0.057539</td>\n",
       "      <td>0.106346</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>-0.010991</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>-0.018179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015531</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.012604</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.014277</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>-0.001458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbreviated_n</th>\n",
       "      <td>0.708724</td>\n",
       "      <td>-0.158414</td>\n",
       "      <td>-0.037277</td>\n",
       "      <td>-0.021225</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>-0.138097</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>0.025533</td>\n",
       "      <td>-0.034397</td>\n",
       "      <td>-0.090336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>-0.003305</td>\n",
       "      <td>0.060561</td>\n",
       "      <td>-0.017757</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>0.071692</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>-0.043158</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>-0.025402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abduction_n</th>\n",
       "      <td>0.510707</td>\n",
       "      <td>-0.074578</td>\n",
       "      <td>-0.034553</td>\n",
       "      <td>-0.048555</td>\n",
       "      <td>0.049102</td>\n",
       "      <td>-0.010484</td>\n",
       "      <td>-0.032769</td>\n",
       "      <td>-0.006869</td>\n",
       "      <td>0.046021</td>\n",
       "      <td>-0.029008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099285</td>\n",
       "      <td>0.070637</td>\n",
       "      <td>0.035214</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.045005</td>\n",
       "      <td>-0.091899</td>\n",
       "      <td>0.032369</td>\n",
       "      <td>0.035032</td>\n",
       "      <td>0.044302</td>\n",
       "      <td>-0.060663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5    \\\n",
       "modifier                                                                    \n",
       "a_n            0.946819 -0.215910 -0.078663  0.098186  0.031344 -0.128517   \n",
       "aaa_n          0.538223 -0.113592  0.006146  0.054010 -0.015412 -0.045805   \n",
       "aarhus_n       0.031769  0.051368  0.015322 -0.057539  0.106346  0.017514   \n",
       "abbreviated_n  0.708724 -0.158414 -0.037277 -0.021225  0.008293 -0.138097   \n",
       "abduction_n    0.510707 -0.074578 -0.034553 -0.048555  0.049102 -0.010484   \n",
       "\n",
       "                    6         7         8         9    ...       290  \\\n",
       "modifier                                               ...             \n",
       "a_n           -0.040655 -0.052660  0.022259  0.114906  ... -0.000052   \n",
       "aaa_n          0.012455  0.015334 -0.008608  0.024122  ...  0.019392   \n",
       "aarhus_n       0.002858 -0.010991  0.008487 -0.018179  ... -0.015531   \n",
       "abbreviated_n  0.047325  0.025533 -0.034397 -0.090336  ... -0.005020   \n",
       "abduction_n   -0.032769 -0.006869  0.046021 -0.029008  ... -0.099285   \n",
       "\n",
       "                    291       292       293       294       295       296  \\\n",
       "modifier                                                                    \n",
       "a_n           -0.000006  0.000039 -0.000040  0.000092  0.000019  0.000004   \n",
       "aaa_n          0.011160  0.117384  0.046802  0.023796  0.016095  0.057174   \n",
       "aarhus_n       0.006199  0.009077 -0.007065  0.012976  0.012604  0.003189   \n",
       "abbreviated_n -0.003305  0.060561 -0.017757 -0.000270  0.071692  0.027068   \n",
       "abduction_n    0.070637  0.035214  0.000986  0.045005 -0.091899  0.032369   \n",
       "\n",
       "                    297       298       299  \n",
       "modifier                                     \n",
       "a_n            0.000010  0.000061  0.000070  \n",
       "aaa_n         -0.077713  0.033013 -0.003302  \n",
       "aarhus_n       0.014277  0.014720 -0.001458  \n",
       "abbreviated_n -0.043158 -0.004612 -0.025402  \n",
       "abduction_n    0.035032  0.044302 -0.060663  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifiers=constituents.loc[constituents.index.isin(modifiers_list)]\n",
    "modifiers.index.names=['modifier']\n",
    "modifiers.info()\n",
    "modifiers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_compounds=pd.DataFrame(novel_compounds_list)\n",
    "novel_compounds.columns=['modifier','head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 25920 entries, (a_n, peaceful_n) to (xxviii_n, olympiad_n)\n",
      "Columns: 600 entries, 0_x to 299_y\n",
      "dtypes: float64(600)\n",
      "memory usage: 118.9+ MB\n"
     ]
    }
   ],
   "source": [
    "positive_df=pd.merge(novel_compounds,heads.reset_index(),on=[\"head\"])\n",
    "positive_df=pd.merge(positive_df,modifiers.reset_index(),on=[\"modifier\"])\n",
    "#positive_df['Plausibility']=True\n",
    "positive_df.set_index(['modifier','head'],inplace=True)\n",
    "positive_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 25920 entries, (a_n, peaceful_n) to (xxviii_n, olympiad_n)\n",
      "Columns: 300 entries, 0_x to 299_x\n",
      "dtypes: float64(300)\n",
      "memory usage: 59.5+ MB\n"
     ]
    }
   ],
   "source": [
    "head_cols=positive_df.columns[:300]\n",
    "positive_heads=positive_df[head_cols]\n",
    "positive_heads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 25920 entries, (a_n, peaceful_n) to (xxviii_n, olympiad_n)\n",
      "Columns: 300 entries, 0_y to 299_y\n",
      "dtypes: float64(300)\n",
      "memory usage: 59.5+ MB\n"
     ]
    }
   ],
   "source": [
    "modifier_cols=positive_df.columns[300:]\n",
    "positive_modifiers=positive_df[modifier_cols]\n",
    "positive_modifiers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25920, 300])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_heads_tensor = torch.tensor(positive_heads.values)\n",
    "positive_heads_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25920, 300])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_modifiers_tensor = torch.tensor(positive_modifiers.values)\n",
    "positive_modifiers_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25920])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_Y=torch.ones(positive_modifiers_tensor.shape[0])\n",
    "positive_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25920, 600])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_class=torch.cat((positive_modifiers_tensor, positive_heads_tensor), 1)\n",
    "positive_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_df_creator(file):\n",
    "    pkl_file=pkl.load( open(file,'rb'))\n",
    "    df=pd.DataFrame(pkl_file)\n",
    "    \n",
    "    df.columns=['modifier','head']\n",
    "    \n",
    "    negative_df=pd.merge(df,heads.reset_index(),on=[\"head\"])\n",
    "    negative_df=pd.merge(negative_df,modifiers.reset_index(),on=[\"modifier\"])\n",
    "\n",
    "    negative_df.set_index(['modifier','head'],inplace=True)\n",
    "    shape_neg=negative_df.shape[1]\n",
    "    head_cols=negative_df.columns[:shape_neg]\n",
    "    negative_heads=negative_df[head_cols]\n",
    "    \n",
    "    modifier_cols=negative_df.columns[shape_neg:]\n",
    "    negative_modifiers=negative_df[modifier_cols]\n",
    "    \n",
    "    negative_heads_tensor = torch.tensor(negative_heads.values)\n",
    "    negative_modifiers_tensor = torch.tensor(negative_modifiers.values)\n",
    "\n",
    "    negative_Y=torch.zeros(negative_modifiers_tensor.shape[0])\n",
    "    negative_class=torch.cat((negative_modifiers_tensor, negative_heads_tensor), 1)\n",
    "\n",
    "    return negative_class,negative_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_joiner(files):\n",
    "    tensor_list=[]\n",
    "    for file in files:\n",
    "        negative_class,negative_Y=neg_df_creator(file)\n",
    "        X=torch.cat((positive_class, negative_class), 0)\n",
    "        Y=torch.cat((positive_Y,negative_Y),0)\n",
    "        tensor_list.append([X,Y])\n",
    "    \n",
    "    return tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_modifier_files=[]\n",
    "for file in glob.glob(\"/data/dharp/compounding/datasets/corrupt_modifier*\"):\n",
    "    corrupt_modifier_files.append(file)\n",
    "corrupt_modifiers=tensor_joiner(corrupt_modifier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_head_files=[]\n",
    "for file in glob.glob(\"/data/dharp/compounding/datasets/corrupt_head*\"):\n",
    "    corrupt_head_files.append(file)\n",
    "corrupt_heads=tensor_joiner(corrupt_head_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = positive_class.shape[1]\n",
    "hidden_size = 300\n",
    "num_classes = 2\n",
    "num_epochs = 50\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes,bias=False)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looper(datasets):\n",
    "    total_accuracy=[]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        X=dataset[0]\n",
    "        Y=dataset[1]\n",
    "        n = len(X)  # how many total elements you have\n",
    "        n_test = int( n * .2 )  # number of test/val elements\n",
    "        n_train = n - n_test\n",
    "        idx = list(range(n))  # indices to all elements\n",
    "        random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "        train_idx = idx[:n_train]\n",
    "        test_idx = idx[n_train:]\n",
    "        trX=X[train_idx].float().to(device)\n",
    "        teX=X[test_idx].float().to(device)\n",
    "\n",
    "        trY=Y[train_idx].long().to(device)\n",
    "        teY=Y[test_idx].long().to(device)\n",
    "        model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        n_examples=trX.shape[0]\n",
    "        for i in range(num_epochs):\n",
    "\n",
    "            cost = 0.\n",
    "\n",
    "            num_batches = n_examples // batch_size\n",
    "            for k in range(num_batches):\n",
    "                start, end = k * batch_size, (k + 1) * batch_size\n",
    "                outputs = model(trX[start:end])\n",
    "                loss = criterion(outputs, trY[start:end])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "            #if (k+1) % 100 == 0:\n",
    "            #print ('Epoch [{}/{}], Loss: {:.4f}'.format(i+1, num_epochs, loss.item()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct=0\n",
    "            total=0\n",
    "            outputs = model(teX)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += teY.size(0)\n",
    "            correct += (predicted == teY).sum().item()\n",
    "        curr_acc=100 * correct / total\n",
    "        print(curr_acc)\n",
    "        total_accuracy.append(curr_acc)\n",
    "    return total_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.68255040030867\n",
      "72.67290440821839\n",
      "71.69865920709945\n",
      "73.02980611555898\n",
      "69.93344265457702\n",
      "72.65361242403782\n",
      "73.42529179126073\n",
      "72.31600270087779\n",
      "72.47998456641265\n",
      "72.89476222629497\n"
     ]
    }
   ],
   "source": [
    "cor_head_acc=looper(corrupt_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "65.83389601620527\n",
    "65.03327867271149\n",
    "65.27442847496864\n",
    "63.66354779589081\n",
    "64.70531494164175\n",
    "65.39018038005209\n",
    "64.8114208546349\n",
    "66.05575383428186\n",
    "64.46416513938459\n",
    "64.99469470435034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.38"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(cor_head_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(cor_head_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.87244897959184\n",
      "75.9386671908787\n",
      "74.231260438157\n",
      "75.03927729772192\n",
      "75.57341697706332\n",
      "74.61094254673583\n",
      "75.02452422993917\n",
      "75.67753338570306\n",
      "74.09041875061293\n",
      "75.16936671575847\n"
     ]
    }
   ],
   "source": [
    "cor_mod_acc=looper(corrupt_modifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "61.92111459968603\n",
    "63.111853744839784\n",
    "61.80371352785146\n",
    "62.81421838177533\n",
    "63.99725544010978\n",
    "62.00450230008809\n",
    "62.016872670198154\n",
    "62.5\n",
    "63.13621653427479\n",
    "62.837506136475206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.02"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(cor_mod_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(cor_mod_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
