{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook dealing with the final preprocessing steps for the neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import glob\n",
    "import random\n",
    "random.seed(1991)\n",
    "#torch.set_default_tensor_type('torch.cuda.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You have a CUDA device, so you should probably run with --cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1991)\n",
    "if torch.cuda.is_available():\n",
    "    \n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53466 entries, a_n to zygote_n\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float64(300)\n",
      "memory usage: 122.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_n</th>\n",
       "      <td>0.440430</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>-0.000983</td>\n",
       "      <td>-0.025453</td>\n",
       "      <td>0.194777</td>\n",
       "      <td>-0.030807</td>\n",
       "      <td>-0.009806</td>\n",
       "      <td>-0.103889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028331</td>\n",
       "      <td>0.027137</td>\n",
       "      <td>-0.043847</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.008193</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>0.018965</td>\n",
       "      <td>-0.011933</td>\n",
       "      <td>-0.015698</td>\n",
       "      <td>0.012663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_n</th>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>-0.002899</td>\n",
       "      <td>0.050492</td>\n",
       "      <td>-0.017074</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.051071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038320</td>\n",
       "      <td>-0.032570</td>\n",
       "      <td>-0.009443</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.025628</td>\n",
       "      <td>0.049950</td>\n",
       "      <td>-0.026634</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.018899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa_n</th>\n",
       "      <td>0.313449</td>\n",
       "      <td>-0.016028</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>-0.000780</td>\n",
       "      <td>-0.016718</td>\n",
       "      <td>0.154211</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>0.108424</td>\n",
       "      <td>-0.081133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046221</td>\n",
       "      <td>-0.058067</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.036212</td>\n",
       "      <td>0.029292</td>\n",
       "      <td>0.029706</td>\n",
       "      <td>-0.039024</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.016696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa_n</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044826</td>\n",
       "      <td>-0.022707</td>\n",
       "      <td>-0.011827</td>\n",
       "      <td>0.016305</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.047539</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>0.012872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaai_n</th>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.034051</td>\n",
       "      <td>-0.004198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023478</td>\n",
       "      <td>0.040822</td>\n",
       "      <td>-0.095591</td>\n",
       "      <td>0.044083</td>\n",
       "      <td>-0.010137</td>\n",
       "      <td>-0.067752</td>\n",
       "      <td>0.141350</td>\n",
       "      <td>0.147728</td>\n",
       "      <td>-0.015423</td>\n",
       "      <td>0.071274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6    \\\n",
       "head                                                                            \n",
       "a_n      0.440430  0.005506  0.002429 -0.002683 -0.000983 -0.025453  0.194777   \n",
       "aa_n     0.011832  0.002295 -0.000676  0.000938  0.000343 -0.002899  0.050492   \n",
       "aaa_n    0.313449 -0.016028  0.011828  0.002696 -0.000780 -0.016718  0.154211   \n",
       "aaaaa_n  0.000827  0.000443  0.000095  0.000450 -0.000050 -0.000347  0.004473   \n",
       "aaai_n   0.000850  0.000880  0.000401  0.002374  0.004960  0.001507  0.003561   \n",
       "\n",
       "              7         8         9    ...       290       291       292  \\\n",
       "head                                   ...                                 \n",
       "a_n     -0.030807 -0.009806 -0.103889  ... -0.028331  0.027137 -0.043847   \n",
       "aa_n    -0.017074  0.000098  0.051071  ... -0.038320 -0.032570 -0.009443   \n",
       "aaa_n   -0.031180  0.108424 -0.081133  ... -0.046221 -0.058067 -0.012101   \n",
       "aaaaa_n -0.000884  0.001146 -0.005078  ... -0.044826 -0.022707 -0.011827   \n",
       "aaai_n  -0.000046  0.034051 -0.004198  ...  0.023478  0.040822 -0.095591   \n",
       "\n",
       "              293       294       295       296       297       298       299  \n",
       "head                                                                           \n",
       "a_n      0.006858  0.008193  0.015432  0.018965 -0.011933 -0.015698  0.012663  \n",
       "aa_n    -0.000768  0.014299  0.025628  0.049950 -0.026634  0.003430  0.018899  \n",
       "aaa_n    0.011162  0.036212  0.029292  0.029706 -0.039024  0.025404  0.016696  \n",
       "aaaaa_n  0.016305  0.012899  0.027791  0.047539  0.007618  0.024552  0.012872  \n",
       "aaai_n   0.044083 -0.010137 -0.067752  0.141350  0.147728 -0.015423  0.071274  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads=pd.read_pickle(\"/data/dharp/compounding/datasets/heads_CompoundCentric_DecadeAgnostic_300.pkl\")\n",
    "heads.info()\n",
    "heads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 54400 entries, a_n to zylobalsamum_n\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float64(300)\n",
      "memory usage: 124.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_n</th>\n",
       "      <td>0.339999</td>\n",
       "      <td>0.032878</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>0.121973</td>\n",
       "      <td>-0.022126</td>\n",
       "      <td>-0.016050</td>\n",
       "      <td>0.114271</td>\n",
       "      <td>-0.025870</td>\n",
       "      <td>0.052949</td>\n",
       "      <td>-0.093165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025719</td>\n",
       "      <td>-0.043307</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.022528</td>\n",
       "      <td>-0.038733</td>\n",
       "      <td>0.035699</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>-0.005785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa_n</th>\n",
       "      <td>0.192280</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>0.036605</td>\n",
       "      <td>-0.006458</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>-0.014895</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>-0.046352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056977</td>\n",
       "      <td>-0.029964</td>\n",
       "      <td>-0.027422</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>0.043846</td>\n",
       "      <td>0.018267</td>\n",
       "      <td>0.062345</td>\n",
       "      <td>0.030111</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>-0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa_n</th>\n",
       "      <td>0.065267</td>\n",
       "      <td>0.047112</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.091206</td>\n",
       "      <td>-0.015523</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>-0.001949</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>-0.005168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039798</td>\n",
       "      <td>-0.023954</td>\n",
       "      <td>-0.025154</td>\n",
       "      <td>0.012599</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>0.034694</td>\n",
       "      <td>0.046989</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>-0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa_n</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044826</td>\n",
       "      <td>-0.022707</td>\n",
       "      <td>-0.011827</td>\n",
       "      <td>0.016305</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.047539</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>0.012872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa_n</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044826</td>\n",
       "      <td>-0.022707</td>\n",
       "      <td>-0.011827</td>\n",
       "      <td>0.016305</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.047539</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>0.012872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5    \\\n",
       "modifier                                                               \n",
       "a_n       0.339999  0.032878 -0.001667  0.121973 -0.022126 -0.016050   \n",
       "aa_n      0.192280  0.011892  0.002212 -0.001564  0.036605 -0.006458   \n",
       "aaa_n     0.065267  0.047112  0.000272  0.091206 -0.015523 -0.003515   \n",
       "aaaa_n    0.000827  0.000443  0.000095  0.000450 -0.000050 -0.000347   \n",
       "aaaaa_n   0.000827  0.000443  0.000095  0.000450 -0.000050 -0.000347   \n",
       "\n",
       "               6         7         8         9    ...       290       291  \\\n",
       "modifier                                          ...                       \n",
       "a_n       0.114271 -0.025870  0.052949 -0.093165  ... -0.025719 -0.043307   \n",
       "aa_n      0.050666 -0.014895  0.001873 -0.046352  ... -0.056977 -0.029964   \n",
       "aaa_n     0.003856 -0.001949 -0.005680 -0.005168  ... -0.039798 -0.023954   \n",
       "aaaa_n    0.004473 -0.000884  0.001146 -0.005078  ... -0.044826 -0.022707   \n",
       "aaaaa_n   0.004473 -0.000884  0.001146 -0.005078  ... -0.044826 -0.022707   \n",
       "\n",
       "               292       293       294       295       296       297  \\\n",
       "modifier                                                               \n",
       "a_n       0.013846  0.022528 -0.038733  0.035699  0.037341  0.012729   \n",
       "aa_n     -0.027422  0.010024  0.043846  0.018267  0.062345  0.030111   \n",
       "aaa_n    -0.025154  0.012599  0.021654  0.034694  0.046989  0.000299   \n",
       "aaaa_n   -0.011827  0.016305  0.012899  0.027791  0.047539  0.007618   \n",
       "aaaaa_n  -0.011827  0.016305  0.012899  0.027791  0.047539  0.007618   \n",
       "\n",
       "               298       299  \n",
       "modifier                      \n",
       "a_n       0.017356 -0.005785  \n",
       "aa_n      0.025396 -0.001170  \n",
       "aaa_n     0.021891 -0.000029  \n",
       "aaaa_n    0.024552  0.012872  \n",
       "aaaaa_n   0.024552  0.012872  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifiers=pd.read_pickle(\"/data/dharp/compounding/datasets/modifiers_CompoundCentric_DecadeAgnostic_300.pkl\")\n",
    "modifiers.info()\n",
    "modifiers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_compounds_list = pkl.load( open( \"/data/dharp/compounding/datasets/novel_compounds_list.pkl\", \"rb\" ) )\n",
    "m, h = zip(*novel_compounds_list)\n",
    "heads_list=list(set(h))\n",
    "modifiers_list=list(set(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_compounds=pd.DataFrame(novel_compounds_list)\n",
    "novel_compounds.columns=['modifier','head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_heads=pd.merge(novel_compounds.drop('modifier',axis=1),heads.reset_index(),on=[\"head\"])\n",
    "\n",
    "positive_modifiers=pd.merge(novel_compounds.drop('head',axis=1),modifiers.reset_index(),on=[\"modifier\"])\n",
    "#positive_df['Plausibility']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peaceful_n</td>\n",
       "      <td>0.094746</td>\n",
       "      <td>0.394519</td>\n",
       "      <td>0.049438</td>\n",
       "      <td>-0.055479</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>-0.067276</td>\n",
       "      <td>-0.005653</td>\n",
       "      <td>0.039678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>-0.016868</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.022061</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>-0.008992</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>0.003950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peaceful_n</td>\n",
       "      <td>0.094746</td>\n",
       "      <td>0.394519</td>\n",
       "      <td>0.049438</td>\n",
       "      <td>-0.055479</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>-0.067276</td>\n",
       "      <td>-0.005653</td>\n",
       "      <td>0.039678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>-0.016868</td>\n",
       "      <td>-0.025363</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.022061</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>-0.008992</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>0.003950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robinson_n</td>\n",
       "      <td>0.516893</td>\n",
       "      <td>-0.027680</td>\n",
       "      <td>-0.009162</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>-0.002822</td>\n",
       "      <td>-0.023920</td>\n",
       "      <td>0.113440</td>\n",
       "      <td>-0.009606</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087203</td>\n",
       "      <td>-0.020085</td>\n",
       "      <td>-0.069696</td>\n",
       "      <td>0.059515</td>\n",
       "      <td>-0.203745</td>\n",
       "      <td>-0.053035</td>\n",
       "      <td>0.066117</td>\n",
       "      <td>-0.016516</td>\n",
       "      <td>0.295535</td>\n",
       "      <td>0.011347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robinson_n</td>\n",
       "      <td>0.516893</td>\n",
       "      <td>-0.027680</td>\n",
       "      <td>-0.009162</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>-0.002822</td>\n",
       "      <td>-0.023920</td>\n",
       "      <td>0.113440</td>\n",
       "      <td>-0.009606</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087203</td>\n",
       "      <td>-0.020085</td>\n",
       "      <td>-0.069696</td>\n",
       "      <td>0.059515</td>\n",
       "      <td>-0.203745</td>\n",
       "      <td>-0.053035</td>\n",
       "      <td>0.066117</td>\n",
       "      <td>-0.016516</td>\n",
       "      <td>0.295535</td>\n",
       "      <td>0.011347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>supply_n</td>\n",
       "      <td>0.849265</td>\n",
       "      <td>-0.049544</td>\n",
       "      <td>-0.023528</td>\n",
       "      <td>-0.010386</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>-0.052200</td>\n",
       "      <td>0.357877</td>\n",
       "      <td>-0.056204</td>\n",
       "      <td>-0.047523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025304</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.022895</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>-0.005519</td>\n",
       "      <td>-0.011278</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>-0.017954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         head         0         1         2         3         4         5  \\\n",
       "0  peaceful_n  0.094746  0.394519  0.049438 -0.055479  0.067019  0.017066   \n",
       "1  peaceful_n  0.094746  0.394519  0.049438 -0.055479  0.067019  0.017066   \n",
       "2  robinson_n  0.516893 -0.027680 -0.009162  0.021842 -0.002822 -0.023920   \n",
       "3  robinson_n  0.516893 -0.027680 -0.009162  0.021842 -0.002822 -0.023920   \n",
       "4    supply_n  0.849265 -0.049544 -0.023528 -0.010386  0.010196 -0.052200   \n",
       "\n",
       "          6         7         8  ...       290       291       292       293  \\\n",
       "0 -0.067276 -0.005653  0.039678  ...  0.008639 -0.016868 -0.025363  0.001678   \n",
       "1 -0.067276 -0.005653  0.039678  ...  0.008639 -0.016868 -0.025363  0.001678   \n",
       "2  0.113440 -0.009606 -0.013875  ...  0.087203 -0.020085 -0.069696  0.059515   \n",
       "3  0.113440 -0.009606 -0.013875  ...  0.087203 -0.020085 -0.069696  0.059515   \n",
       "4  0.357877 -0.056204 -0.047523  ...  0.025304 -0.000088 -0.022895  0.004955   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.022061  0.004521 -0.008992  0.005364 -0.005843  0.003950  \n",
       "1  0.022061  0.004521 -0.008992  0.005364 -0.005843  0.003950  \n",
       "2 -0.203745 -0.053035  0.066117 -0.016516  0.295535  0.011347  \n",
       "3 -0.203745 -0.053035  0.066117 -0.016516  0.295535  0.011347  \n",
       "4  0.006311 -0.000669 -0.005519 -0.011278  0.000614 -0.017954  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_heads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28448, 300])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_heads_tensor = torch.tensor(positive_heads.drop('head',axis=1).values)\n",
    "positive_heads_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28448, 300])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_modifiers_tensor = torch.tensor(positive_modifiers.drop('modifier',axis=1).values)\n",
    "positive_modifiers_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28448])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_Y=torch.ones(positive_modifiers_tensor.shape[0])\n",
    "positive_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28448, 600])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_class=torch.cat((positive_modifiers_tensor, positive_heads_tensor), 1)\n",
    "positive_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_df_creator(file):\n",
    "    pkl_file=pkl.load( open(file,'rb'))\n",
    "    df=pd.DataFrame(pkl_file)\n",
    "    \n",
    "    df.columns=['modifier','head']\n",
    "    negative_heads=pd.merge(df.drop('modifier',axis=1),heads.reset_index(),on=[\"head\"])\n",
    "    negative_modifiers=pd.merge(df.drop('head',axis=1),modifiers.reset_index(),on=[\"modifier\"])\n",
    "    negative_heads_tensor = torch.tensor(negative_heads.drop('head',axis=1).values)\n",
    "    negative_modifiers_tensor = torch.tensor(negative_modifiers.drop('modifier',axis=1).values)\n",
    "\n",
    "    negative_Y=torch.zeros(negative_modifiers_tensor.shape[0])\n",
    "    negative_class=torch.cat((negative_modifiers_tensor, negative_heads_tensor), 1)\n",
    "\n",
    "    return negative_class,negative_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_joiner(files):\n",
    "    tensor_list=[]\n",
    "    for file in files:\n",
    "        negative_class,negative_Y=neg_df_creator(file)\n",
    "        X=torch.cat((positive_class, negative_class), 0)\n",
    "        Y=torch.cat((positive_Y,negative_Y),0)\n",
    "        tensor_list.append([X,Y])\n",
    "    \n",
    "    return tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_modifier_files=[]\n",
    "for file in glob.glob(\"/data/dharp/compounding/datasets/corrupt_modifier*\"):\n",
    "    corrupt_modifier_files.append(file)\n",
    "corrupt_modifiers=tensor_joiner(corrupt_modifier_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_head_files=[]\n",
    "for file in glob.glob(\"/data/dharp/compounding/datasets/corrupt_head*\"):\n",
    "    corrupt_head_files.append(file)\n",
    "corrupt_heads=tensor_joiner(corrupt_head_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 600\n",
    "hidden_size = 300\n",
    "num_classes = 2\n",
    "num_epochs = 50\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes,bias=False)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looper(datasets):\n",
    "    total_accuracy=[]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        X=dataset[0]\n",
    "        Y=dataset[1]\n",
    "        n = len(X)  # how many total elements you have\n",
    "        n_test = int( n * .2 )  # number of test/val elements\n",
    "        n_train = n - n_test\n",
    "        idx = list(range(n))  # indices to all elements\n",
    "        random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
    "        train_idx = idx[:n_train]\n",
    "        test_idx = idx[n_train:]\n",
    "        trX=X[train_idx].float().to(device)\n",
    "        teX=X[test_idx].float().to(device)\n",
    "\n",
    "        trY=Y[train_idx].long().to(device)\n",
    "        teY=Y[test_idx].long().to(device)\n",
    "        model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        n_examples=trX.shape[0]\n",
    "        for i in range(num_epochs):\n",
    "\n",
    "            cost = 0.\n",
    "\n",
    "            num_batches = n_examples // batch_size\n",
    "            for k in range(num_batches):\n",
    "                start, end = k * batch_size, (k + 1) * batch_size\n",
    "                outputs = model(trX[start:end])\n",
    "                loss = criterion(outputs, trY[start:end])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            #if (k+1) % 100 == 0:\n",
    "            #print ('Epoch [{}/{}], Loss: {:.4f}'.format(i+1, num_epochs, loss.item()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct=0\n",
    "            total=0\n",
    "            outputs = model(teX)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += teY.size(0)\n",
    "            correct += (predicted == teY).sum().item()\n",
    "        curr_acc=100 * correct / total\n",
    "        print(curr_acc)\n",
    "        total_accuracy.append(curr_acc)\n",
    "    return total_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.91589770630108\n",
      "83.12681254943317\n",
      "82.59952544160295\n",
      "82.76649969241585\n",
      "83.14438878636084\n",
      "83.05650760172247\n",
      "82.90710958783724\n",
      "83.22348185253537\n",
      "82.67861850777749\n",
      "82.74892345548818\n"
     ]
    }
   ],
   "source": [
    "cor_head_acc=looper(corrupt_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.92"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(cor_head_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(cor_head_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.88074523244573\n",
      "83.40803234027595\n",
      "82.29194129536866\n",
      "81.87889972756832\n",
      "82.72255910009667\n",
      "82.21284822919412\n",
      "82.45891554618156\n",
      "82.5643729677476\n",
      "82.6610422708498\n",
      "82.3007294138325\n"
     ]
    }
   ],
   "source": [
    "cor_mod_acc=looper(corrupt_modifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.54"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(cor_mod_acc),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.std(cor_mod_acc),2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
