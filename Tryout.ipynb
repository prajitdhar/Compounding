{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA,TruncatedSVD,NMF\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import argparse\n",
    "import time\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_binner(year,val=10):\n",
    "    return year - year%val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction(df,rows):\n",
    "    df_svd = TruncatedSVD(n_components=300, n_iter=10, random_state=args.seed)\n",
    "    print(f'Explained variance ratio {(df_svd.fit(df).explained_variance_ratio_.sum()):2.3f}')\n",
    "    #df_list=df_svd.fit(df).explained_variance_ratio_\n",
    "    df_reduced = df_svd.fit_transform(df)\n",
    "    df_reduced = Normalizer(copy=False).fit_transform(df_reduced)\n",
    "    df_reduced=pd.DataFrame(df_reduced,index=rows)\n",
    "    #df_reduced.reset_index(inplace=True)\n",
    "    if args.temporal!=0:\n",
    "        df_reduced.index = pd.MultiIndex.from_tuples(df_reduced.index, names=['common', 'time'])\n",
    "    return df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Gather data necessary for performing Regression')\n",
    "\n",
    "parser.add_argument('--inputdir',type=str,\n",
    "                    help='Provide directory that has the files with the fivegram counts')\n",
    "parser.add_argument('--outputdir',type=str,\n",
    "                    help='Provide directory in that the output files should be stored')\n",
    "parser.add_argument('--temporal',  type=int, default=0,\n",
    "                    help='Value to bin the temporal information: 0 (remove temporal information), 1 (no binning), 10 (binning to decades), 20 (binning each 20 years) or 50 (binning each 50 years)')\n",
    "\n",
    "parser.add_argument('--contextual', action='store_true',\n",
    "                    help='Is the model contextual')\n",
    "\n",
    "parser.add_argument('--cutoff', type=int, default=50,\n",
    "                    help='Cut-off frequency for each compound per time period : none (0), 20, 50 and 100')\n",
    "\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=1991,\n",
    "                    help='random seed')\n",
    "\n",
    "parser.add_argument('--storedf', action='store_true',\n",
    "                    help='Should the embeddings be saved')\n",
    "\n",
    "parser.add_argument('--dims', type=int, default=300,\n",
    "                    help='Desired number of reduced dimensions')\n",
    "\n",
    "parser.add_argument('--input_format',type=str,default='csv',choices=['csv','pkl'],\n",
    "                    help='In what format are the input files : csv or pkl')\n",
    "parser.add_argument('--save_format', type=str,default='pkl',choices=['pkl','csv'],\n",
    "                    help='In what format should the reduced datasets be saved : csv or pkl')\n",
    "\n",
    "\n",
    "args = parser.parse_args('--inputdir ../Compounding/coha_compounds/ --outputdir ../Compounding/coha_compounds/ --cutoff 10 --storedf --input_format csv --save_format csv'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff: 10\n",
      "Time span:  0\n",
      "Dimensionality: 300\n"
     ]
    }
   ],
   "source": [
    "print(f'Cutoff: {args.cutoff}')\n",
    "print(f'Time span:  {args.temporal}')\n",
    "print(f'Dimensionality: {args.dims}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dense embeddings\n",
      "CompoundAgnostic Model\n",
      "No temporal information is stored\n",
      "No temporal information is stored\n",
      "Concatenating all the datasets together\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating dense embeddings\")\n",
    "if args.contextual:\n",
    "    print(\"CompoundCentric Model\")\n",
    "    print(\"Loading the constituent and compound vector datasets\")\n",
    "\n",
    "    if args.input_format==\"csv\":\n",
    "        compounds=pd.read_csv(args.inputdir+\"/compounds.csv\",sep=\"\\t\")\n",
    "    elif args.input==\"pkl\":\n",
    "        compounds=pd.read_pickle(args.inputdir+\"/compounds.pkl\")\n",
    "        compounds.reset_index(inplace=True)\n",
    "    compounds.year=compounds.year.astype(\"int32\")\n",
    "    compounds=compounds.query('1800 <= year <= 2010').copy()\n",
    "    compounds['common']=compounds['modifier']+\" \"+compounds['head']\n",
    "\n",
    "        #head_list_reduced=compounds['head'].unique().tolist()\n",
    "        #modifier_list_reduced=compounds['modifier'].unique().tolist()\n",
    "\n",
    "    if args.temporal==0:\n",
    "        print('No temporal information is stored')\n",
    "        compounds=compounds.groupby(['common','context'])['count'].sum().to_frame()\n",
    "        compounds.reset_index(inplace=True)\n",
    "        compounds=compounds.loc[compounds.groupby(['common'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        compounds=compounds.groupby(['common','context'])['count'].sum()\n",
    "\n",
    "    else:\n",
    "        compounds['time']=year_binner(compounds['year'].values,args.temporal)\n",
    "        compounds=compounds.groupby(['common','context','time'])['count'].sum().to_frame()\n",
    "        compounds.reset_index(inplace=True)\n",
    "        compounds=compounds.loc[compounds.groupby(['common','time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        compounds=compounds.groupby(['common','time','context'])['count'].sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if args.input_format==\"csv\":\n",
    "        modifiers=pd.read_csv(args.inputdir+\"/modifiers.csv\",sep=\"\\t\")\n",
    "    elif args.input==\"pkl\":\n",
    "        modifiers=pd.read_pickle(args.inputdir+\"/modifiers.pkl\")\n",
    "        modifiers.reset_index(inplace=True)\n",
    "    modifiers.year=modifiers.year.astype(\"int32\")\n",
    "    modifiers=modifiers.query('1800 <= year <= 2010').copy()\n",
    "    modifiers.columns=['common','context','year','count']\n",
    "    modifiers['common']=modifiers['common'].str.replace(r'_noun$', r'_m', regex=True)\n",
    "        \n",
    "    if args.temporal==0:\n",
    "        print('No temporal information is stored')\n",
    "        modifiers=modifiers.groupby(['common','context'])['count'].sum().to_frame()\n",
    "        modifiers.reset_index(inplace=True)\n",
    "        modifiers=modifiers.loc[modifiers.groupby(['common'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        modifiers=modifiers.groupby(['common','context'])['count'].sum()\n",
    "    else:\n",
    "        modifiers['time']=year_binner(modifiers['year'].values,args.temporal)\n",
    "        modifiers=modifiers.groupby(['common','context','time'])['count'].sum().to_frame()\n",
    "        modifiers=modifiers.loc[modifiers.groupby(['common','time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        modifiers=modifiers.groupby(['common','time','context'])['count'].sum()\n",
    "\n",
    "    if args.input_format==\"csv\":\n",
    "        heads=pd.read_csv(args.inputdir+\"/heads.csv\",sep=\"\\t\")\n",
    "    elif args.input_format==\"pkl\":\n",
    "        heads=pd.read_pickle(args.inputdir+\"/heads.pkl\")\n",
    "        heads.reset_index(inplace=True)\n",
    "    heads.year=heads.year.astype(\"int32\")\n",
    "    heads=heads.query('1800 <= year <= 2010').copy()\n",
    "    heads.columns=['common','context','year','count']\n",
    "    heads['common']=heads['common'].str.replace(r'_noun$', r'_h', regex=True)\n",
    "    if args.temporal==0:\n",
    "        print('No temporal information is stored')\n",
    "        heads=heads.groupby(['common','context'])['count'].sum().to_frame()\n",
    "        heads.reset_index(inplace=True)\n",
    "        heads=heads.loc[heads.groupby(['common'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        heads=heads.groupby(['common','context'])['count'].sum()\n",
    "    else:\n",
    "        heads['time']=year_binner(heads['year'].values,args.temporal)\n",
    "        heads=heads.groupby(['common','context','time'])['count'].sum().to_frame()\n",
    "        heads=heads.loc[heads.groupby(['common','time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        heads=heads.groupby(['common','time','context'])['count'].sum()\n",
    "\n",
    "    print('Concatenating all the datasets together')\n",
    "    df=pd.concat([heads,modifiers,compounds], sort=True)\n",
    "\n",
    "else:\n",
    "    print(\"CompoundAgnostic Model\")\n",
    "    wordlist = pkl.load( open( \"data/coha_wordlist.pkl\", \"rb\" ) )\n",
    "        \n",
    "    if args.input_format==\"csv\":\n",
    "        compounds=pd.read_csv(args.inputdir+\"/phrases.csv\",sep=\"\\t\")\n",
    "    elif args.input_format==\"pkl\":\n",
    "        compounds=pd.read_pickle(args.inputdir+\"/phrases.pkl\")\n",
    "        compounds.reset_index(inplace=True)\n",
    "    compounds.year=compounds.year.astype(\"int32\")\n",
    "    compounds=compounds.query('1800 <= year <= 2010').copy()\n",
    "    compounds['common']=compounds['modifier']+\" \"+compounds['head']\n",
    "\n",
    "\n",
    "    if args.temporal==0:\n",
    "        print('No temporal information is stored')\n",
    "        compounds=compounds.groupby(['common','context'])['count'].sum().to_frame()\n",
    "        compounds.reset_index(inplace=True)\n",
    "        compounds=compounds.loc[compounds.groupby(['common'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        compounds=compounds.groupby(['common','context'])['count'].sum()\n",
    "    else:\n",
    "        compounds['time']=year_binner(compounds['year'].values,args.temporal)\n",
    "            #compounds = dd.from_pandas(compounds, npartitions=100)\n",
    "        compounds=compounds.groupby(['common','context','time'])['count'].sum().to_frame()\n",
    "        compounds=compounds.loc[compounds.groupby(['common','time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        compounds=compounds.groupby(['common','time','context'])['count'].sum()\n",
    "        \n",
    "    if args.input_format==\"csv\":\n",
    "        constituents=pd.read_csv(args.outputdir+\"/words.csv\",sep=\"\\t\")\n",
    "    elif args.input_format==\"pkl\":\n",
    "        constituents=pd.read_pickle(args.outputdir+\"/words.pkl\")\n",
    "        constituents.reset_index(inplace=True)\n",
    "    constituents.year=constituents.year.astype(\"int32\")\n",
    "    constituents=constituents.query('1800 <= year <= 2010').copy()\n",
    "    constituents.columns=['common','context','year','count']\n",
    "    constituents.query('common in @wordlist',inplace=True)\n",
    "    if args.temporal==0:\n",
    "        print('No temporal information is stored')\n",
    "        constituents=constituents.groupby(['common','context'])['count'].sum().to_frame()\n",
    "        constituents.reset_index(inplace=True)\n",
    "        constituents=constituents.loc[constituents.groupby(['common'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        constituents=constituents.groupby(['common','context'])['count'].sum()           \n",
    "    else:\n",
    "        constituents['time']=year_binner(constituents['year'].values,args.temporal)\n",
    "        constituents=constituents.groupby(['common','context','time'])['count'].sum().to_frame()\n",
    "        constituents.reset_index(inplace=True)\n",
    "        constituents=constituents.loc[constituents.groupby(['common','time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "        constituents=constituents.groupby(['common','time','context'])['count'].sum()\n",
    "\n",
    "    print('Concatenating all the datasets together')\n",
    "    df=pd.concat([constituents,compounds], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = pd.SparseDtype(np.float, fill_value=0)\n",
    "df=df.astype(dtype)\n",
    "if args.temporal!=0:    \n",
    "    df, rows, _ = df.sparse.to_coo(row_levels=['common','time'],column_levels=['context'],sort_labels=False)\n",
    "\n",
    "else:\n",
    "    df, rows, _ = df.sparse.to_coo(row_levels=['common'],column_levels=['context'],sort_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVD\n",
      "Explained variance ratio 0.971\n",
      "Splitting back into individual datasets are saving them\n"
     ]
    }
   ],
   "source": [
    "print('Running SVD')   \n",
    "df_reduced=dim_reduction(df,rows)\n",
    "\n",
    "print('Splitting back into individual datasets are saving them')\n",
    "if args.temporal!=0:\n",
    "    df_reduced.index.names = ['common','time']\n",
    "else:\n",
    "    df_reduced.index.names = ['common']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds_reduced=df_reduced.loc[df_reduced.index.get_level_values(0).str.contains(r'\\w \\w')]\n",
    "compounds_reduced.reset_index(inplace=True)\n",
    "    #print(compounds_reduced.head())\n",
    "#compounds_reduced['modifier'],compounds_reduced['head']=compounds_reduced['common'].str.split(' ', 1).str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users0/pageljs/dh/build/anaconda3/envs/pytorch/lib/python3.7/site-packages/pandas/core/frame.py:3062: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--_noun ernment_noun</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.042117</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.021992</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>0.095712</td>\n",
       "      <td>-0.051622</td>\n",
       "      <td>-0.035909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>-0.007909</td>\n",
       "      <td>-0.011186</td>\n",
       "      <td>-0.034584</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>-0.018117</td>\n",
       "      <td>-0.017537</td>\n",
       "      <td>--_noun</td>\n",
       "      <td>ernment_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.50-caliber_noun machine_noun</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>-0.000756</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>-0.000624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003629</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>-0.009013</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>-0.008112</td>\n",
       "      <td>.50-caliber_noun</td>\n",
       "      <td>machine_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-hole_noun golf_noun</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.029849</td>\n",
       "      <td>-0.021480</td>\n",
       "      <td>-0.024156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>0.012832</td>\n",
       "      <td>-0.023661</td>\n",
       "      <td>0.033115</td>\n",
       "      <td>-0.001968</td>\n",
       "      <td>-0.033928</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>18-hole_noun</td>\n",
       "      <td>golf_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;nul&gt;_noun mead_noun</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.277146</td>\n",
       "      <td>-0.048300</td>\n",
       "      <td>-0.016587</td>\n",
       "      <td>-0.050491</td>\n",
       "      <td>-0.082149</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>0.030586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>0.032068</td>\n",
       "      <td>-0.054139</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>0.032247</td>\n",
       "      <td>-0.050930</td>\n",
       "      <td>0.021734</td>\n",
       "      <td>&lt;nul&gt;_noun</td>\n",
       "      <td>mead_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;nul&gt;_noun tuberculosis_noun</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.093642</td>\n",
       "      <td>-0.069827</td>\n",
       "      <td>-0.009551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050107</td>\n",
       "      <td>0.138060</td>\n",
       "      <td>0.010479</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.026493</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>0.039912</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>&lt;nul&gt;_noun</td>\n",
       "      <td>tuberculosis_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10357</th>\n",
       "      <td>zinc_noun oxide_noun</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.018088</td>\n",
       "      <td>0.055689</td>\n",
       "      <td>-0.053783</td>\n",
       "      <td>-0.003219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052466</td>\n",
       "      <td>-0.032312</td>\n",
       "      <td>0.027851</td>\n",
       "      <td>0.051536</td>\n",
       "      <td>-0.009092</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>-0.021105</td>\n",
       "      <td>0.036009</td>\n",
       "      <td>zinc_noun</td>\n",
       "      <td>oxide_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10358</th>\n",
       "      <td>zinc_noun sulphate_noun</td>\n",
       "      <td>0.030771</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>0.052327</td>\n",
       "      <td>0.036359</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>0.043198</td>\n",
       "      <td>0.122054</td>\n",
       "      <td>-0.090039</td>\n",
       "      <td>-0.038553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025569</td>\n",
       "      <td>0.150223</td>\n",
       "      <td>-0.175859</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>-0.157568</td>\n",
       "      <td>0.122526</td>\n",
       "      <td>-0.121641</td>\n",
       "      <td>-0.150570</td>\n",
       "      <td>zinc_noun</td>\n",
       "      <td>sulphate_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>zintl_noun art_noun</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.022535</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>-0.015936</td>\n",
       "      <td>-0.012259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020603</td>\n",
       "      <td>-0.042375</td>\n",
       "      <td>0.039904</td>\n",
       "      <td>-0.013654</td>\n",
       "      <td>-0.062860</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>0.023237</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>zintl_noun</td>\n",
       "      <td>art_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>zip_noun code_noun</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>0.027632</td>\n",
       "      <td>0.037465</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>0.027326</td>\n",
       "      <td>0.089923</td>\n",
       "      <td>-0.075393</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>0.018017</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.046129</td>\n",
       "      <td>0.036112</td>\n",
       "      <td>-0.043758</td>\n",
       "      <td>0.064175</td>\n",
       "      <td>-0.014812</td>\n",
       "      <td>zip_noun</td>\n",
       "      <td>code_noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10361</th>\n",
       "      <td>zum_noun zum_noun</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>-0.004080</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196133</td>\n",
       "      <td>0.194469</td>\n",
       "      <td>-0.261772</td>\n",
       "      <td>0.138026</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>0.067317</td>\n",
       "      <td>0.033805</td>\n",
       "      <td>0.050344</td>\n",
       "      <td>zum_noun</td>\n",
       "      <td>zum_noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10362 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              common         0         1         2         3  \\\n",
       "0               --_noun ernment_noun  0.013156  0.010049  0.042117  0.015222   \n",
       "1      .50-caliber_noun machine_noun  0.000255  0.000482  0.001424  0.003878   \n",
       "2             18-hole_noun golf_noun  0.002611  0.001083  0.005383  0.001914   \n",
       "3               <nul>_noun mead_noun  0.006032  0.013232  0.277146 -0.048300   \n",
       "4       <nul>_noun tuberculosis_noun  0.011637  0.008685  0.034091  0.022776   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "10357           zinc_noun oxide_noun  0.005456  0.004083  0.016491  0.013181   \n",
       "10358        zinc_noun sulphate_noun  0.030771  0.010413  0.052327  0.036359   \n",
       "10359            zintl_noun art_noun  0.001855  0.002240  0.016377  0.001576   \n",
       "10360             zip_noun code_noun  0.012933  0.010429  0.027632  0.037465   \n",
       "10361              zum_noun zum_noun  0.000232  0.000162  0.000710  0.000939   \n",
       "\n",
       "              4         5         6         7         8  ...       292  \\\n",
       "0      0.021992  0.035819  0.095712 -0.051622 -0.035909  ...  0.020727   \n",
       "1     -0.000756  0.000926  0.003635 -0.004018 -0.000624  ... -0.003629   \n",
       "2      0.002936  0.008797  0.029849 -0.021480 -0.024156  ... -0.002405   \n",
       "3     -0.016587 -0.050491 -0.082149  0.030528  0.030586  ... -0.001800   \n",
       "4      0.005681  0.032657  0.093642 -0.069827 -0.009551  ... -0.050107   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "10357  0.000993  0.018088  0.055689 -0.053783 -0.003219  ...  0.052466   \n",
       "10358  0.006845  0.043198  0.122054 -0.090039 -0.038553  ... -0.025569   \n",
       "10359  0.002928  0.022535  0.022752 -0.015936 -0.012259  ...  0.020603   \n",
       "10360 -0.002563  0.027326  0.089923 -0.075393 -0.013152  ... -0.009517   \n",
       "10361  0.000046  0.001337  0.004594 -0.004080 -0.002144  ... -0.196133   \n",
       "\n",
       "            293       294       295       296       297       298       299  \\\n",
       "0     -0.000598 -0.007909 -0.011186 -0.034584  0.010278 -0.018117 -0.017537   \n",
       "1     -0.000007  0.007167 -0.012708  0.004627 -0.009013  0.001364 -0.008112   \n",
       "2      0.012832 -0.023661  0.033115 -0.001968 -0.033928  0.003360  0.003674   \n",
       "3      0.032068 -0.054139  0.010141 -0.003791  0.032247 -0.050930  0.021734   \n",
       "4      0.138060  0.010479  0.021163  0.026493  0.013883  0.039912 -0.006302   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10357 -0.032312  0.027851  0.051536 -0.009092  0.001179 -0.021105  0.036009   \n",
       "10358  0.150223 -0.175859  0.007048 -0.157568  0.122526 -0.121641 -0.150570   \n",
       "10359 -0.042375  0.039904 -0.013654 -0.062860 -0.003009  0.023237  0.000342   \n",
       "10360  0.018017  0.034409  0.046129  0.036112 -0.043758  0.064175 -0.014812   \n",
       "10361  0.194469 -0.261772  0.138026  0.188535  0.067317  0.033805  0.050344   \n",
       "\n",
       "               modifier               head  \n",
       "0               --_noun       ernment_noun  \n",
       "1      .50-caliber_noun       machine_noun  \n",
       "2          18-hole_noun          golf_noun  \n",
       "3            <nul>_noun          mead_noun  \n",
       "4            <nul>_noun  tuberculosis_noun  \n",
       "...                 ...                ...  \n",
       "10357         zinc_noun         oxide_noun  \n",
       "10358         zinc_noun      sulphate_noun  \n",
       "10359        zintl_noun           art_noun  \n",
       "10360          zip_noun          code_noun  \n",
       "10361          zum_noun           zum_noun  \n",
       "\n",
       "[10362 rows x 303 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compounds_reduced[['modifier','head']]=compounds_reduced['common'].str.split(' ', n=1,expand=True).copy()\n",
    "compounds_reduced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
