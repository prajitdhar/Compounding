{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import fastparquet\n",
    "import argparse\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Program to run google compounder for a particular file and setting')\n",
    "\n",
    "parser.add_argument('--data', type=str,\n",
    "                    help='location of the parquet files')\n",
    "\n",
    "parser.add_argument('--word', action='store_true',\n",
    "                    help='Extracting context for words only?')\n",
    "\n",
    "parser.add_argument('--output', type=str,\n",
    "                    help='directory to save dataset in')\n",
    "\n",
    "\n",
    "args = parser.parse_args('--data /data/dharp/compounds/datasets/entire_df/ --output /data/dharp/compounds/datasets'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40215"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_file=pd.read_pickle('/data/dharp/compounds/Compounding/data/contexts.pkl')\n",
    "contexts=[context.split('_')[0] for context in context_file]\n",
    "contexts=list(set(contexts))\n",
    "len(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_side_parser(df): # N N _ _ _\n",
    "    cur_df=df.copy()\n",
    "\n",
    "    try:\n",
    "        cur_df[['modifier','head','w1','w2','w3']]=cur_df.lemma_sent.str.split(' ',expand=True)\n",
    "    except ValueError:\n",
    "        compound_df=pd.DataFrame()\n",
    "        modifier_df=pd.DataFrame()\n",
    "        head_df=pd.DataFrame()\n",
    "        return compound_df,modifier_df,head_df\n",
    "    \n",
    "    compound_df=pd.melt(cur_df,id_vars=['modifier','head','year','count'],value_vars=['w1','w2','w3'],value_name='context')\n",
    "    compound_df=compound_df.loc[compound_df.context.isin(contexts)]\n",
    "\n",
    "    modifier_df=pd.melt(cur_df,id_vars=['modifier','year','count'],value_vars=['head','w1','w2'],value_name='context')\n",
    "    modifier_df=modifier_df.loc[modifier_df.context.isin(contexts)]\n",
    "    \n",
    "    head_df=pd.melt(cur_df,id_vars=['head','year','count'],value_vars=['modifier','w1','w2','w3'],value_name='context')\n",
    "    head_df=head_df.loc[head_df.context.isin(contexts)]\n",
    "    \n",
    "    return compound_df,modifier_df,head_df\n",
    "\n",
    "def mid1_parser(df): # _ N N _ _\n",
    "    cur_df=df.copy()\n",
    "    try:\n",
    "        cur_df[['w1','modifier','head','w2','w3']]=cur_df.lemma_sent.str.split(' ',expand=True)\n",
    "    except ValueError:\n",
    "        compound_df=pd.DataFrame()\n",
    "        modifier_df=pd.DataFrame()\n",
    "        head_df=pd.DataFrame()\n",
    "        return compound_df,modifier_df,head_df\n",
    "    \n",
    "    compound_df=pd.melt(cur_df,id_vars=['modifier','head','year','count'],value_vars=['w1','w2','w3'],value_name='context')\n",
    "    compound_df=compound_df.loc[compound_df.context.isin(contexts)]\n",
    "\n",
    "    modifier_df=pd.melt(cur_df,id_vars=['modifier','year','count'],value_vars=['head','w1','w2','w3'],value_name='context')\n",
    "    modifier_df=modifier_df.loc[modifier_df.context.isin(contexts)]\n",
    "    \n",
    "    head_df=pd.melt(cur_df,id_vars=['head','year','count'],value_vars=['modifier','w1','w2','w3'],value_name='context')\n",
    "    head_df=head_df.loc[head_df.context.isin(contexts)]\n",
    "    \n",
    "    return compound_df,modifier_df,head_df\n",
    "\n",
    "def mid2_parser(df): # _ _ N N _\n",
    "    cur_df=df.copy()\n",
    "    try:\n",
    "        cur_df[['w1','w2','modifier','head','w3']]=cur_df.lemma_sent.str.split(' ',expand=True)\n",
    "    except ValueError:\n",
    "        compound_df=pd.DataFrame()\n",
    "        modifier_df=pd.DataFrame()\n",
    "        head_df=pd.DataFrame()\n",
    "        return compound_df,modifier_df,head_df\n",
    "       \n",
    "    compound_df=pd.melt(cur_df,id_vars=['modifier','head','year','count'],value_vars=['w1','w2','w3'],value_name='context')\n",
    "    compound_df=compound_df.loc[compound_df.context.isin(contexts)]\n",
    "\n",
    "    modifier_df=pd.melt(cur_df,id_vars=['modifier','year','count'],value_vars=['head','w1','w2','w3'],value_name='context')\n",
    "    modifier_df=modifier_df.loc[modifier_df.context.isin(contexts)]\n",
    "    \n",
    "    head_df=pd.melt(cur_df,id_vars=['head','year','count'],value_vars=['modifier','w1','w2','w3'],value_name='context')\n",
    "    head_df=head_df.loc[head_df.context.isin(contexts)]\n",
    "    \n",
    "    return compound_df,modifier_df,head_df\n",
    "\n",
    "def right_side_parser(df): # _ _ _ N N\n",
    "    cur_df=df.copy()\n",
    "    try:\n",
    "        cur_df[['w1','w2','w3','modifier','head']]=cur_df.lemma_sent.str.split(' ',expand=True)\n",
    "    except ValueError:\n",
    "        compound_df=pd.DataFrame()\n",
    "        modifier_df=pd.DataFrame()\n",
    "        head_df=pd.DataFrame()\n",
    "        return compound_df,modifier_df,head_df\n",
    "    \n",
    "    compound_df=pd.melt(cur_df,id_vars=['modifier','head','year','count'],value_vars=['w1','w2','w3'],value_name='context')\n",
    "    compound_df=compound_df.loc[compound_df.context.isin(contexts)]\n",
    "    \n",
    "    modifier_df=pd.melt(cur_df,id_vars=['modifier','year','count'],value_vars=['head','w1','w2','w3'],value_name='context')\n",
    "    modifier_df=modifier_df.loc[modifier_df.context.isin(contexts)]\n",
    "    \n",
    "    head_df=pd.melt(cur_df,id_vars=['head','year','count'],value_vars=['modifier','w2','w3'],value_name='context')\n",
    "    head_df=head_df.loc[head_df.context.isin(contexts)]\n",
    "    \n",
    "    return compound_df,modifier_df,head_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntactic_reducer(df):\n",
    "    pattern=df.iloc[0].comp_class\n",
    "    if pattern==1: # N N _ _ N N\n",
    "        compound_left_df,modifier_left_df,head_left_df=left_side_parser(df)\n",
    "        compound_right_df,modifier_right_df,head_right_df=right_side_parser(df)\n",
    "        \n",
    "        final_compound_df=pd.concat([compound_left_df,compound_right_df],ignore_index=True)\n",
    "        final_modifier_df=pd.concat([modifier_left_df,modifier_right_df],ignore_index=True)\n",
    "        final_head_df=pd.concat([head_left_df,head_right_df],ignore_index=True)\n",
    "           \n",
    "    elif pattern==2: # N N _ _ _\n",
    "        final_compound_df,final_modifier_df,final_head_df=left_side_parser(df)\n",
    "\n",
    "    elif pattern==3: # _ N N _ _\n",
    "        final_compound_df,final_modifier_df,final_head_df=mid1_parser(df)\n",
    "    \n",
    "    elif pattern==4: # _ _ N N _\n",
    "        final_compound_df,final_modifier_df,final_head_df=mid2_parser(df)\n",
    "        \n",
    "    elif pattern==5: # _ _ _ N N\n",
    "        final_compound_df,final_modifier_df,final_head_df=right_side_parser(df)\n",
    "\n",
    "    return final_compound_df,final_modifier_df,final_head_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_extracter(df):\n",
    "    if df.loc[df.comp_class==1].shape[0]!=0:\n",
    "        sides_comp_df,sides_mod_df,sides_head_df=syntactic_reducer(df.loc[df.comp_class==1])\n",
    "    else:\n",
    "        sides_comp_df=pd.DataFrame()\n",
    "        sides_mod_df=pd.DataFrame()\n",
    "        sides_head_df=pd.DataFrame()\n",
    "    \n",
    "    if df.loc[df.comp_class==2].shape[0]!=0:\n",
    "        left_comp_df,left_mod_df,left_head_df=syntactic_reducer(df.loc[df.comp_class==2])\n",
    "    else:\n",
    "        left_comp_df=pd.DataFrame()\n",
    "        left_mod_df=pd.DataFrame()\n",
    "        left_head_df=pd.DataFrame()       \n",
    "        \n",
    "    if df.loc[df.comp_class==3].shape[0]!=0:\n",
    "        mid1_comp_df,mid1_mod_df,mid1_head_df=syntactic_reducer(df.loc[df.comp_class==3])\n",
    "    else:\n",
    "        mid1_comp_df=pd.DataFrame()\n",
    "        mid1_mod_df=pd.DataFrame()\n",
    "        mid1_head_df=pd.DataFrame()\n",
    "        \n",
    "    if df.loc[df.comp_class==4].shape[0]!=0:\n",
    "        mid2_comp_df,mid2_mod_df,mid2_head_df=syntactic_reducer(df.loc[df.comp_class==4])\n",
    "    else:\n",
    "        mid2_comp_df=pd.DataFrame()\n",
    "        mid2_mod_df=pd.DataFrame()\n",
    "        mid2_head_df=pd.DataFrame()\n",
    "\n",
    "    if df.loc[df.comp_class==5].shape[0]!=0:\n",
    "        right_comp_df,right_mod_df,right_head_df=syntactic_reducer(df.loc[df.comp_class==5])\n",
    "        \n",
    "    else:\n",
    "        right_comp_df=pd.DataFrame()\n",
    "        right_mod_df=pd.DataFrame()\n",
    "        right_head_df=pd.DataFrame()\n",
    "\n",
    "    compounds=pd.concat([sides_comp_df,left_comp_df,mid1_comp_df,mid2_comp_df,right_comp_df],ignore_index=True,sort=False)\n",
    "    modifiers=pd.concat([sides_mod_df,left_mod_df,mid1_mod_df,mid2_mod_df,right_mod_df],ignore_index=True,sort=False)\n",
    "    heads=pd.concat([sides_head_df,left_head_df,mid1_head_df,mid2_head_df,right_head_df],ignore_index=True,sort=False)\n",
    "    \n",
    "    if len(compounds)==0:\n",
    "        return compounds,modifiers,heads\n",
    "    \n",
    "    compounds.dropna(inplace=True)\n",
    "    compounds=compounds.groupby(['modifier','head','context','year'])['count'].sum().to_frame()\n",
    "    compounds.reset_index(inplace=True)\n",
    "    \n",
    "    modifiers.dropna(inplace=True)\n",
    "    modifiers=modifiers.groupby(['modifier','context','year'])['count'].sum().to_frame()\n",
    "    modifiers.reset_index(inplace=True)\n",
    "    \n",
    "    heads.dropna(inplace=True)\n",
    "    heads=heads.groupby(['head','context','year'])['count'].sum().to_frame()\n",
    "    heads.reset_index(inplace=True)\n",
    "    \n",
    "    return compounds,modifiers,heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df,num_cores):\n",
    "    num_partitions = num_cores\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    print(\"Done splitting the datasets\")\n",
    "    pool = Pool(num_cores)\n",
    "\n",
    "    cur_time=time.time()\n",
    "    print(\"Starting parallelizing\")\n",
    "    if not args.word:\n",
    "\n",
    "        results=pool.map_async(compound_extracter,df_split)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        results=results.get()\n",
    "\n",
    "        \n",
    "        print(\"Done parallelizing\")\n",
    "        print(\"Total time taken\",round(time.time()-cur_time),\"secs\")\n",
    "        compound_list = [ result[0] for result in results]\n",
    "        compounds=pd.concat(compound_list,ignore_index=True)\n",
    "        compounds=compounds.groupby(['modifier','head','context','year'])['count'].sum().to_frame()\n",
    "        compounds.reset_index(inplace=True)\n",
    "        \n",
    "        #if not isfile(f'{args.output}/compounds.csv'):\n",
    "            #compounds.to_csv(f'{args.output}/compounds.csv',sep=\"\\t\",index=False)\n",
    "        #else:\n",
    "            #compounds.to_csv(f'{args.output}/compounds.csv', mode='a',sep=\"\\t\", header=False,index=False)\n",
    "        \n",
    "        \n",
    "        modifier_list = [ result[1] for result in results]\n",
    "        modifiers=pd.concat(modifier_list,ignore_index=True)\n",
    "        modifiers=modifiers.groupby(['modifier','context','year'])['count'].sum().to_frame()\n",
    "        modifiers.reset_index(inplace=True)\n",
    "\n",
    "        #if not isfile(f'{args.output}/modifiers.csv'):\n",
    "            #modifiers.to_csv(f'{args.output}/modifiers.csv',sep=\"\\t\",index=False)\n",
    "        #else:\n",
    "            #modifiers.to_csv(f'{args.output}/modifiers.csv', mode='a',sep=\"\\t\",header=False,index=False)\n",
    "        \n",
    "        head_list = [ result[2] for result in results]\n",
    "        heads=pd.concat(head_list,ignore_index=True)\n",
    "        heads=heads.groupby(['head','context','year'])['count'].sum().to_frame()\n",
    "        heads.reset_index(inplace=True)\n",
    "\n",
    "        return compounds,modifiers,heads\n",
    "        #if not isfile(f'{args.output}/heads.csv'):\n",
    "            #heads.to_csv(f'{args.output}/heads.csv',sep=\"\\t\",index=False)\n",
    "        #else:\n",
    "            #heads.to_csv(f'{args.output}/heads.csv', mode='a',sep=\"\\t\",header=False,index=False)\n",
    "            \n",
    "#        phrase_list = [ result[3] for result in results]\n",
    "#        phrases=pd.concat(phrase_list,ignore_index=True)\n",
    "#        phrases=phrases.groupby(['modifier','head','context','year'])['count'].sum().to_frame()\n",
    "#        phrases.reset_index(inplace=True)\n",
    "        \n",
    "#        if not isfile(f'{args.output}/phrases.csv'):\n",
    "#            phrases.to_csv(f'{args.output}/phrases.csv',sep=\"\\t\",index=False)\n",
    "#        else:\n",
    "#            phrases.to_csv(f'{args.output}/phrases.csv', mode='a',sep=\"\\t\",header=False,index=False)\n",
    "\n",
    "    else:\n",
    "        words_list=[]\n",
    "        results=pool.map_async(cdsm_word_reducer,df_split)\n",
    "  \n",
    "        \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(\"Done parallelizing\")\n",
    "        print(\"Total time taken\",round(time.time()-cur_time),\"secs\")\n",
    "        words_list=results.get()\n",
    "        words = pd.concat(words_list,ignore_index=True,sort=False)\n",
    "        words=words.groupby(['word','context','year'])['count'].sum().to_frame()\n",
    "        words.reset_index(inplace=True)\n",
    "        print(words.shape)\n",
    "                \n",
    "        if not isfile(f'{args.output}/words.csv'):\n",
    "            words.to_csv(f'{args.output}/words.csv',sep=\"\\t\",index=False,header=True)\n",
    "        else:\n",
    "            words.to_csv(f'{args.output}/words.csv', mode='a',sep=\"\\t\", header=False,index=False)\n",
    "        \n",
    "    print(\"Done concatenations \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_sent</th>\n",
       "      <th>year</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>comp_class</th>\n",
       "      <th>ner_sent</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1836</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1839</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1844</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1849</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1850</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362197</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2004</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362198</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2005</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362199</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2006</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362200</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2007</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362201</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2008</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537212 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                lemma_sent  year                  pos_sent  \\\n",
       "49           these preparation , mr. astor  1836  DET NOUN PUNCT NOUN NOUN   \n",
       "50           these preparation , mr. astor  1839  DET NOUN PUNCT NOUN NOUN   \n",
       "51           these preparation , mr. astor  1844  DET NOUN PUNCT NOUN NOUN   \n",
       "52           these preparation , mr. astor  1849  DET NOUN PUNCT NOUN NOUN   \n",
       "53           these preparation , mr. astor  1850  DET NOUN PUNCT NOUN NOUN   \n",
       "...                                    ...   ...                       ...   \n",
       "2362197  thyself well when thou digressest  2004   PRON INTJ ADV NOUN NOUN   \n",
       "2362198  thyself well when thou digressest  2005   PRON INTJ ADV NOUN NOUN   \n",
       "2362199  thyself well when thou digressest  2006   PRON INTJ ADV NOUN NOUN   \n",
       "2362200  thyself well when thou digressest  2007   PRON INTJ ADV NOUN NOUN   \n",
       "2362201  thyself well when thou digressest  2008   PRON INTJ ADV NOUN NOUN   \n",
       "\n",
       "         comp_class      ner_sent  count  \n",
       "49                5  25_30_PERSON      9  \n",
       "50                5  25_30_PERSON      1  \n",
       "51                5  25_30_PERSON      1  \n",
       "52                5  25_30_PERSON      6  \n",
       "53                5  25_30_PERSON      2  \n",
       "...             ...           ...    ...  \n",
       "2362197           5                    3  \n",
       "2362198           5                    7  \n",
       "2362199           5                    2  \n",
       "2362200           5                    4  \n",
       "2362201           5                    6  \n",
       "\n",
       "[537212 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def right_side_parser(df): # _ _ _ N N\n",
    "    cur_df=df.copy()\n",
    "    try:\n",
    "        cur_df[['w1','w2','w3','modifier','head']]=cur_df.lemma_sent.str.split(' ',expand=True)\n",
    "        cur_df[['p1','p2','p3']]=cur_df.pos_sent.str.split(' ',expand=True)[[0,1,2]]\n",
    "    except ValueError:\n",
    "        compound_df=pd.DataFrame()\n",
    "        modifier_df=pd.DataFrame()\n",
    "        head_df=pd.DataFrame()\n",
    "        return compound_df,modifier_df,head_df\n",
    "    \n",
    "    compound_df=pd.melt(cur_df,id_vars=['modifier','head','year','count'],value_vars=['w1','w2','w3'],value_name='context')\n",
    "    compound_df=compound_df.loc[compound_df.context.isin(contexts)]\n",
    "    \n",
    "    modifier_df=pd.melt(cur_df,id_vars=['modifier','year','count'],value_vars=['head','w1','w2','w3'],value_name='context')\n",
    "    modifier_df=modifier_df.loc[modifier_df.context.isin(contexts)]\n",
    "    \n",
    "    head_df=pd.melt(cur_df,id_vars=['head','year','count'],value_vars=['modifier','w2','w3'],value_name='context')\n",
    "    head_df=head_df.loc[head_df.context.isin(contexts)]\n",
    "    \n",
    "    return compound_df,modifier_df,head_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_sent</th>\n",
       "      <th>pos_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these present , doth grant</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>these present doth bargain sell</td>\n",
       "      <td>DET VERB ADJ NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these present in manner hereinafter</td>\n",
       "      <td>DET NOUN ADP NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>these principle by great britain</td>\n",
       "      <td>DET NOUN ADP NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16342</th>\n",
       "      <td>thyself into whatever shape thou</td>\n",
       "      <td>PRON ADP DET NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16343</th>\n",
       "      <td>thyself outgoing in thy noon</td>\n",
       "      <td>PRON ADJ ADP NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344</th>\n",
       "      <td>thyself that the great carbuncle</td>\n",
       "      <td>PRON SCONJ DET NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16345</th>\n",
       "      <td>thyself unweariedly till thou findest</td>\n",
       "      <td>PRON ADV SCONJ NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16346</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16347 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  lemma_sent                  pos_sent\n",
       "0              these preparation , mr. astor  DET NOUN PUNCT NOUN NOUN\n",
       "1                 these present , doth grant  DET NOUN PUNCT NOUN NOUN\n",
       "2            these present doth bargain sell    DET VERB ADJ NOUN NOUN\n",
       "3        these present in manner hereinafter    DET NOUN ADP NOUN NOUN\n",
       "4           these principle by great britain    DET NOUN ADP NOUN NOUN\n",
       "...                                      ...                       ...\n",
       "16342       thyself into whatever shape thou    PRON ADP DET NOUN NOUN\n",
       "16343           thyself outgoing in thy noon    PRON ADJ ADP NOUN NOUN\n",
       "16344       thyself that the great carbuncle  PRON SCONJ DET NOUN NOUN\n",
       "16345  thyself unweariedly till thou findest  PRON ADV SCONJ NOUN NOUN\n",
       "16346      thyself well when thou digressest   PRON INTJ ADV NOUN NOUN\n",
       "\n",
       "[16347 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwestie=cur_df.loc[cur_df.comp_class==5].copy()\n",
    "kwestie_index=kwestie.groupby(['lemma_sent','pos_sent']).size().to_frame().reset_index()\n",
    "kwestie_index.drop(0,axis=1,inplace=True)\n",
    "kwestie_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "third of the committee member       2\n",
       "through in - service program        2\n",
       "this year ' s budget                2\n",
       "third of the total national         2\n",
       "throw open -pron- chamber window    2\n",
       "                                   ..\n",
       "this type of roof covering          1\n",
       "think of the research process       1\n",
       "this kind to sir walter             1\n",
       "these small - scale enterprise      1\n",
       "those part of asia minor            1\n",
       "Name: lemma_sent, Length: 16315, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwestie_index.lemma_sent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_sent</th>\n",
       "      <th>year</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>comp_class</th>\n",
       "      <th>ner_sent</th>\n",
       "      <th>count</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1836</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>9</td>\n",
       "      <td>these</td>\n",
       "      <td>preparation</td>\n",
       "      <td>,</td>\n",
       "      <td>mr.</td>\n",
       "      <td>astor</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1839</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>1</td>\n",
       "      <td>these</td>\n",
       "      <td>preparation</td>\n",
       "      <td>,</td>\n",
       "      <td>mr.</td>\n",
       "      <td>astor</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1844</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>1</td>\n",
       "      <td>these</td>\n",
       "      <td>preparation</td>\n",
       "      <td>,</td>\n",
       "      <td>mr.</td>\n",
       "      <td>astor</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1849</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>6</td>\n",
       "      <td>these</td>\n",
       "      <td>preparation</td>\n",
       "      <td>,</td>\n",
       "      <td>mr.</td>\n",
       "      <td>astor</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>these preparation , mr. astor</td>\n",
       "      <td>1850</td>\n",
       "      <td>DET NOUN PUNCT NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>25_30_PERSON</td>\n",
       "      <td>2</td>\n",
       "      <td>these</td>\n",
       "      <td>preparation</td>\n",
       "      <td>,</td>\n",
       "      <td>mr.</td>\n",
       "      <td>astor</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362197</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2004</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>thyself</td>\n",
       "      <td>well</td>\n",
       "      <td>when</td>\n",
       "      <td>thou</td>\n",
       "      <td>digressest</td>\n",
       "      <td>PRON</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362198</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2005</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>thyself</td>\n",
       "      <td>well</td>\n",
       "      <td>when</td>\n",
       "      <td>thou</td>\n",
       "      <td>digressest</td>\n",
       "      <td>PRON</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362199</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2006</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>thyself</td>\n",
       "      <td>well</td>\n",
       "      <td>when</td>\n",
       "      <td>thou</td>\n",
       "      <td>digressest</td>\n",
       "      <td>PRON</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362200</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2007</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>thyself</td>\n",
       "      <td>well</td>\n",
       "      <td>when</td>\n",
       "      <td>thou</td>\n",
       "      <td>digressest</td>\n",
       "      <td>PRON</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362201</th>\n",
       "      <td>thyself well when thou digressest</td>\n",
       "      <td>2008</td>\n",
       "      <td>PRON INTJ ADV NOUN NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>thyself</td>\n",
       "      <td>well</td>\n",
       "      <td>when</td>\n",
       "      <td>thou</td>\n",
       "      <td>digressest</td>\n",
       "      <td>PRON</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537212 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                lemma_sent  year                  pos_sent  \\\n",
       "49           these preparation , mr. astor  1836  DET NOUN PUNCT NOUN NOUN   \n",
       "50           these preparation , mr. astor  1839  DET NOUN PUNCT NOUN NOUN   \n",
       "51           these preparation , mr. astor  1844  DET NOUN PUNCT NOUN NOUN   \n",
       "52           these preparation , mr. astor  1849  DET NOUN PUNCT NOUN NOUN   \n",
       "53           these preparation , mr. astor  1850  DET NOUN PUNCT NOUN NOUN   \n",
       "...                                    ...   ...                       ...   \n",
       "2362197  thyself well when thou digressest  2004   PRON INTJ ADV NOUN NOUN   \n",
       "2362198  thyself well when thou digressest  2005   PRON INTJ ADV NOUN NOUN   \n",
       "2362199  thyself well when thou digressest  2006   PRON INTJ ADV NOUN NOUN   \n",
       "2362200  thyself well when thou digressest  2007   PRON INTJ ADV NOUN NOUN   \n",
       "2362201  thyself well when thou digressest  2008   PRON INTJ ADV NOUN NOUN   \n",
       "\n",
       "         comp_class      ner_sent  count       w1           w2    w3 modifier  \\\n",
       "49                5  25_30_PERSON      9    these  preparation     ,      mr.   \n",
       "50                5  25_30_PERSON      1    these  preparation     ,      mr.   \n",
       "51                5  25_30_PERSON      1    these  preparation     ,      mr.   \n",
       "52                5  25_30_PERSON      6    these  preparation     ,      mr.   \n",
       "53                5  25_30_PERSON      2    these  preparation     ,      mr.   \n",
       "...             ...           ...    ...      ...          ...   ...      ...   \n",
       "2362197           5                    3  thyself         well  when     thou   \n",
       "2362198           5                    7  thyself         well  when     thou   \n",
       "2362199           5                    2  thyself         well  when     thou   \n",
       "2362200           5                    4  thyself         well  when     thou   \n",
       "2362201           5                    6  thyself         well  when     thou   \n",
       "\n",
       "               head    p1    p2     p3  \n",
       "49            astor   DET  NOUN  PUNCT  \n",
       "50            astor   DET  NOUN  PUNCT  \n",
       "51            astor   DET  NOUN  PUNCT  \n",
       "52            astor   DET  NOUN  PUNCT  \n",
       "53            astor   DET  NOUN  PUNCT  \n",
       "...             ...   ...   ...    ...  \n",
       "2362197  digressest  PRON  INTJ    ADV  \n",
       "2362198  digressest  PRON  INTJ    ADV  \n",
       "2362199  digressest  PRON  INTJ    ADV  \n",
       "2362200  digressest  PRON  INTJ    ADV  \n",
       "2362201  digressest  PRON  INTJ    ADV  \n",
       "\n",
       "[537212 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwestie[['w1','w2','w3','modifier','head']]=kwestie.lemma_sent.str.split(' ',expand=True)\n",
    "kwestie[['p1','p2','p3']]=kwestie.pos_sent.str.split(' ',expand=True)[[0,1,2]]\n",
    "kwestie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores=200\n",
    "df_path=args.data\n",
    "\n",
    "df_files=[]\n",
    "for filename in glob.glob(df_path+'*parq'):\n",
    "    df_files.append(filename)\n",
    "    \n",
    "#for f in df_files:\n",
    "#    parquet_processor(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parquet_processor(f):   \n",
    "    cur_fname=f.split('.')[0].split('/')[-1]\n",
    "    print(f'Current parquet file: {f}')\n",
    "    cur_parq=fastparquet.ParquetFile(f)\n",
    "    print(f'Number of partitions: {len(cur_parq.row_groups)}')\n",
    "    compounds_list=[]\n",
    "    modifiers_list=[]\n",
    "    heads_list=[]\n",
    "\n",
    "    for i,cur_df in enumerate(cur_parq.iter_row_groups()):\n",
    "        print(f'Partition {i+1} out of {len(cur_parq.row_groups)}')\n",
    "        cur_df.year=cur_df.year.astype(\"int32\")\n",
    "        cur_df=cur_df.loc[cur_df.comp_class!=0].reset_index(drop=True)\n",
    "        cur_compounds,cur_modifiers,cur_heads=parallelize_dataframe(cur_df,num_cores)\n",
    "        compounds_list.append(cur_compounds)\n",
    "        modifiers_list.append(cur_modifiers)\n",
    "        heads_list.append(cur_heads)\n",
    "\n",
    "        \n",
    "    compounds=pd.concat(compounds_list,ignore_index=True)\n",
    "    compounds=compounds.groupby(['modifier','head','context','year'])['count'].sum().to_frame()\n",
    "    compounds.reset_index(inplace=True)\n",
    "    \n",
    "    compounds.to_parquet(\n",
    "    path=f'{args.output}/compounds/{cur_fname}.parq', \n",
    "    engine='fastparquet',\n",
    "    compression='snappy')        \n",
    "        \n",
    "   \n",
    "    modifiers=pd.concat(modifiers_list,ignore_index=True)\n",
    "    modifiers=modifiers.groupby(['modifier','context','year'])['count'].sum().to_frame()\n",
    "    modifiers.reset_index(inplace=True)\n",
    "    \n",
    "    modifiers.to_parquet(\n",
    "    path=f'{args.output}/modifiers/{cur_fname}.parq', \n",
    "    engine='fastparquet',\n",
    "    compression='snappy')\n",
    "\n",
    "    \n",
    "    heads=pd.concat(heads_list,ignore_index=True)\n",
    "    heads=heads.groupby(['head','context','year'])['count'].sum().to_frame()\n",
    "    heads.reset_index(inplace=True)\n",
    "    \n",
    "    heads.to_parquet(\n",
    "    path=f'{args.output}/heads/{cur_fname}.parq', \n",
    "    engine='fastparquet',\n",
    "    compression='snappy')\n",
    "    \n",
    "    print(\"Done with file \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_sent</th>\n",
       "      <th>year</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>comp_class</th>\n",
       "      <th>ner_sent</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>these premise art conclude that</td>\n",
       "      <td>1856</td>\n",
       "      <td>DET NOUN NOUN VERB DET</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these premise art conclude that</td>\n",
       "      <td>1862</td>\n",
       "      <td>DET NOUN NOUN VERB DET</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>these premise art conclude that</td>\n",
       "      <td>1865</td>\n",
       "      <td>DET NOUN NOUN VERB DET</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these premise art conclude that</td>\n",
       "      <td>1868</td>\n",
       "      <td>DET NOUN NOUN VERB DET</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>these premise art conclude that</td>\n",
       "      <td>1872</td>\n",
       "      <td>DET NOUN NOUN VERB DET</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362285</th>\n",
       "      <td>thyssen - bornemisza collection ,</td>\n",
       "      <td>2004</td>\n",
       "      <td>NOUN PUNCT NOUN NOUN PUNCT</td>\n",
       "      <td>4</td>\n",
       "      <td>0_31_ORG</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362286</th>\n",
       "      <td>thyssen - bornemisza collection ,</td>\n",
       "      <td>2005</td>\n",
       "      <td>NOUN PUNCT NOUN NOUN PUNCT</td>\n",
       "      <td>4</td>\n",
       "      <td>0_31_ORG</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362287</th>\n",
       "      <td>thyssen - bornemisza collection ,</td>\n",
       "      <td>2006</td>\n",
       "      <td>NOUN PUNCT NOUN NOUN PUNCT</td>\n",
       "      <td>4</td>\n",
       "      <td>0_31_ORG</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362288</th>\n",
       "      <td>thyssen - bornemisza collection ,</td>\n",
       "      <td>2007</td>\n",
       "      <td>NOUN PUNCT NOUN NOUN PUNCT</td>\n",
       "      <td>4</td>\n",
       "      <td>0_31_ORG</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362289</th>\n",
       "      <td>thyssen - bornemisza collection ,</td>\n",
       "      <td>2008</td>\n",
       "      <td>NOUN PUNCT NOUN NOUN PUNCT</td>\n",
       "      <td>4</td>\n",
       "      <td>0_31_ORG</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2362290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                lemma_sent  year                    pos_sent  \\\n",
       "0          these premise art conclude that  1856      DET NOUN NOUN VERB DET   \n",
       "1          these premise art conclude that  1862      DET NOUN NOUN VERB DET   \n",
       "2          these premise art conclude that  1865      DET NOUN NOUN VERB DET   \n",
       "3          these premise art conclude that  1868      DET NOUN NOUN VERB DET   \n",
       "4          these premise art conclude that  1872      DET NOUN NOUN VERB DET   \n",
       "...                                    ...   ...                         ...   \n",
       "2362285  thyssen - bornemisza collection ,  2004  NOUN PUNCT NOUN NOUN PUNCT   \n",
       "2362286  thyssen - bornemisza collection ,  2005  NOUN PUNCT NOUN NOUN PUNCT   \n",
       "2362287  thyssen - bornemisza collection ,  2006  NOUN PUNCT NOUN NOUN PUNCT   \n",
       "2362288  thyssen - bornemisza collection ,  2007  NOUN PUNCT NOUN NOUN PUNCT   \n",
       "2362289  thyssen - bornemisza collection ,  2008  NOUN PUNCT NOUN NOUN PUNCT   \n",
       "\n",
       "         comp_class  ner_sent  count  \n",
       "0                 3                3  \n",
       "1                 3                1  \n",
       "2                 3                1  \n",
       "3                 3                1  \n",
       "4                 3                3  \n",
       "...             ...       ...    ...  \n",
       "2362285           4  0_31_ORG     34  \n",
       "2362286           4  0_31_ORG     14  \n",
       "2362287           4  0_31_ORG     43  \n",
       "2362288           4  0_31_ORG     15  \n",
       "2362289           4  0_31_ORG     35  \n",
       "\n",
       "[2362290 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_df.ner_sent.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
