{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "from scipy.interpolate import interp1d\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "def tf(x):\n",
    "    return(np.log10(x))\n",
    "\n",
    "def decader(x):\n",
    "    return(x -x%10)\n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import pickle as pkl\n",
    "import re\n",
    "def patternmaker(x):\n",
    "    x=np.array(x.notnull())\n",
    "    x=x.astype(int)\n",
    "    #print(x)\n",
    "    val = ''.join(map(str, x))\n",
    "    #print(val)\n",
    "    return val\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmamake(bigram):\n",
    "    t1=time.time()\n",
    "    \n",
    "    #bigram[['modifier','head']] = df.iloc[:,22:26].applymap(binary_values)\n",
    "    #bigram[['modifier','head']]=lemmamaker(bigram['modifier'].values, bigram['m_pos'].values,bigram['head'].values, bigram['h_pos'].values)\n",
    "    #=lemmamaker(bigram['head'].values, bigram['h_pos'].values)\n",
    "    #bigram=bigram.apply(lemmamaker,axis=1)\n",
    "    \n",
    "    \n",
    "    #bigram[\"modifier\"] = bigram[\"modifier\"].map(str) + '_' + bigram[\"m_pos\"]\n",
    "    #bigram[\"head\"] = bigram[\"head\"].map(str) + '_' + bigram[\"h_pos\"]\n",
    "    temp_mod=bigram[[\"modifier\",\"m_pos\"]].drop_duplicates()\n",
    "    t2=time.time()\n",
    "    print(t2-t1)\n",
    "    \n",
    "    #display(temp_mod)\n",
    "    temp_mod['lemma_mod']=lemmamaker_mod(temp_mod['modifier'].values,temp_mod['m_pos'].values)\n",
    "    t3=time.time()\n",
    "    print(t3-t2)\n",
    "    \n",
    "    temp_mod[\"lemma_mod\"]=temp_mod[\"lemma_mod\"].map(str) + '_' + temp_mod[\"m_pos\"]\n",
    "    t4=time.time()\n",
    "    print(t4-t3)\n",
    "    \n",
    "    temp_head=bigram[[\"head\",\"h_pos\"]].drop_duplicates()\n",
    "    t5=time.time()\n",
    "    print(t5-t4)\n",
    "    \n",
    "    temp_head['lemma_head']=lemmamaker_head(temp_head['head'].values,temp_head['h_pos'].values)\n",
    "    t6=time.time()\n",
    "    print(t6-t5)\n",
    "    \n",
    "    \n",
    "    temp_head[\"lemma_head\"]=temp_head[\"lemma_head\"].map(str) + '_' + temp_head[\"h_pos\"]\n",
    "    t7=time.time()\n",
    "    print(t7-t6)\n",
    "    \n",
    "    \n",
    "    lemma_replacements={'modifier':dict(zip(temp_mod.modifier.values,temp_mod.lemma_mod.values)),'head':dict(zip(temp_head['head'].values,temp_head.lemma_head.values))}\n",
    "    t8=time.time()\n",
    "    print(t8-t7)\n",
    "    \n",
    "    \n",
    "    bigram.replace(lemma_replacements,inplace=True)\n",
    "    t9=time.time()\n",
    "    print(t9-t8)\n",
    "    \n",
    "    \n",
    "    #print(type(word))\n",
    "    #word[\"modifier\"]=lemmatizer.lemmatize(word[\"modifier\"],word.m_pos)+\"_\"+word.m_pos\n",
    "    #word[\"head\"]=lemmatizer.lemmatize(word[\"head\"],word.h_pos)+\"_\"+word.h_pos\n",
    "    #word.drop([\"h_pos\",\"m_pos\"],axis=1,inplace=True)\n",
    "    return bigram\n",
    "\n",
    "\n",
    "def nayalemma_maker(bigram):\n",
    "    #t1=time.time()\n",
    "    bigram['modifier']=lemmamaker_mod(bigram['modifier'].values,bigram['m_pos'].values)\n",
    "    #t2=time.time()\n",
    "    #print(t2-t1)\n",
    "    \n",
    "    \n",
    "    bigram[\"modifier\"]=bigram[\"modifier\"].map(str) + '_' + bigram[\"m_pos\"]\n",
    "    #t3=time.time()\n",
    "    #print(t3-t2)\n",
    "    \n",
    "    bigram['head']=lemmamaker_mod(bigram['head'].values,bigram['h_pos'].values)\n",
    "    #t4=time.time()\n",
    "    #print(t4-t3)\n",
    "    \n",
    "    bigram[\"head\"]=bigram[\"head\"].map(str) + '_' + bigram[\"h_pos\"]\n",
    "    #t5=time.time()\n",
    "    #print(t5-t4)\n",
    "    return bigram\n",
    "    \n",
    "#def lemmamaker(word):\n",
    "    #word['modifer']=lemmatizer.lemmatize(word[\"modifier\"],word.m_pos)\n",
    "    #word['head']=lemmatizer.lemmatize(word[\"head\"],word.h_pos)\n",
    "    #return word\n",
    "\n",
    "def lemmamaker_mod(mod,mpos):\n",
    "    \n",
    "    return list(map(lemmatizer.lemmatize,mod,mpos)) #+\"_\"+word.m_pos\n",
    "\n",
    "\n",
    "def lemmamaker_head(hd,hpos):\n",
    "\n",
    "    return list(map(lemmatizer.lemmatize,hd,hpos)) #+\"_\"+word.h_pos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def string_operations(bigram):\n",
    "    \n",
    "    bigram=bigram.loc[bigram.bigram_pos.str.contains(\"^.*_(NOUN|VERB|ADJ) .*_(NOUN|VERB|ADJ)$\")]\n",
    "\n",
    "    bigram['modifier_pos'],bigram['head_pos']=bigram['bigram_pos'].str.split().str\n",
    "\n",
    "    bigram['modifier'], bigram['m_pos'] = bigram['modifier_pos'].str.split('_', 1).str\n",
    "\n",
    "    bigram['head'], bigram['h_pos'] = bigram['head_pos'].str.split('_', 1).str\n",
    "\n",
    "    bigram.drop([\"bigram_pos\",\"modifier_pos\",\"head_pos\"],axis=1,inplace=True)\n",
    "\n",
    "    return bigram\n",
    "\n",
    "import time\n",
    "    \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "decades=[2000, 1990, 1980, 1970, 1960, 1950, 1940, 1930, 1920, 1900, 1910,\n",
    "            1890, 1880, 1870, 1850, 1860, 1840, 1830, 1820, 1810, 1800]\n",
    "replacements={'h_pos':dict(zip([\"NOUN\",\"VERB\",\"ADJ\"],['n','v','a'])),'m_pos':dict(zip([\"NOUN\",\"VERB\",\"ADJ\"],['n','v','a']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generation of bigram files\n",
    "\n",
    "\n",
    "\n",
    "for letter in bigram_list:\n",
    "    if len(letter)>2:\n",
    "        #print(letter)\n",
    "        bigram_list.remove(letter)\n",
    "    #elif len(letter.strip(\"_\"))==1:\n",
    "        #print(letter)\n",
    "        #bigram_list.remove(letter)\n",
    "len(bigram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_extracter(letter):\n",
    "    #t1=time.time()\n",
    "    #Read Dataset\n",
    "    path_loc='http://storage.googleapis.com/books/ngrams/books/googlebooks-eng-all-2gram-20120701-'+letter+'.gz'\n",
    "    bigram   = pd.read_csv(path_loc, compression='gzip', header=None, sep=\"\\t\", quotechar='\"',usecols=[0,1,2])\n",
    "\n",
    "    bigram.columns=['bigram_pos','year','count']\n",
    "    #t2=time.time()\n",
    "    #print(\"End of reading dataset\",t2-t1)\n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "    \n",
    "    \n",
    "    #Converting years to decades\n",
    "    bigram['year']=decader(bigram.year.values)\n",
    "    #bigram.drop([\"year\"],axis=1,inplace=True)\n",
    "    #t3=time.time()\n",
    "    #print(\"End of Converting years to decades\",t3-t2)\n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "    \n",
    "        \n",
    "    #Select decades between 1800 and 2000\n",
    "    bigram=bigram.loc[bigram.year.isin(decades)]\n",
    "    #t4=time.time()\n",
    "    #print(\"End of Select decades between 1800 and 2000\",t4-t3)\n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Merging rows based on decades\n",
    "    bigram=bigram.groupby(['bigram_pos','year'])['count'].sum().to_frame()\n",
    "    bigram.reset_index(inplace=True)\n",
    "    #t5=time.time()\n",
    "    #print(\"End of Merging rows based on decades\",t5-t4) \n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "    \n",
    "    #all_df=[]\n",
    "    #cpu_count=30\n",
    "    #pool=mp.Pool(cpu_count)\n",
    "    #for temp_df in pool.imap_unordered(string_operations,bigram):\n",
    "        #all_df.append(temp_df)\n",
    "    #pool.close()\n",
    "    #pool.join()\n",
    "    #display(bigram['bigram_pos'].str.split(\" \",1))\n",
    "    #bigram=bigram.apply(string_operations)\n",
    "    #bigram['modifier_pos'],bigram['head_pos']=bigram['bigram_pos'].str.split(\" \",1).str\n",
    "    #bigram.drop([\"bigram_pos\"],axis=1,inplace=True)\n",
    "    #display(bigram['modifier_pos'].str.split('_', 1))\n",
    "    #bigram['modifier'], bigram['m_pos'] = bigram['modifier_pos'].str.split('_', 1).str\n",
    "    #bigram.drop([\"modifier_pos\"],axis=1,inplace=True)\n",
    "    #bigram['head'], bigram['h_pos'] = bigram['head_pos'].str.split('_', 1).str\n",
    "    #bigram.drop([\"bigram_pos\",\"modifier_pos\",\"head_pos\"],axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    #bigram['modifier_pos']=\"\"\n",
    "    #bigram['head_pos']=\"\"\n",
    "    #bigram['head']=\"\" \n",
    "    #bigram['h_pos']=\"\"\n",
    "    #bigram['modifier']=\"\" \n",
    "    #bigram['m_pos']=\"\"\n",
    "    #display(bigram)\n",
    "    bigram=string_operations(bigram)\n",
    "    #bigram=parallelize_dataframe(bigram,string_operations)\n",
    "    \n",
    "    \n",
    "    #t6=time.time()\n",
    "    #print(\"End of separating columns\",t6-t5)\n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "                \n",
    "    #Select only Nouns, Verbs and Adjectives\n",
    "    #bigram=bigram.loc[(bigram.m_pos.isin([\"NOUN\",\"VERB\",\"ADJ\"])) & (bigram.h_pos.isin([\"NOUN\",\"VERB\",\"ADJ\"]))]\n",
    "    #t7=time.time()\n",
    "    #print(\"End of selecting only Nouns, Verbs and Adjectives\",t7-t6)\n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #Removing non-english words and words containing non alphabetic characters\n",
    "    bigram=bigram.loc[(bigram.modifier.str.match('^[a-zA-Z]+$') & (bigram[\"head\"].str.match('^[a-zA-Z]+$')))]\n",
    "    #t8=time.time()\n",
    "    #print(\"End of Removing non-english words and words containing non alphabetic characters\",t8-t7)\n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "\n",
    "    \n",
    "    #Reducing all words to lowercase form\n",
    "    bigram.modifier=bigram.modifier.str.lower()\n",
    "    bigram[\"head\"]=bigram[\"head\"].str.lower()\n",
    "    #t9=time.time()\n",
    "    #print(\"End of Reducing all words to lowercase form\",t9-t8) \n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "\n",
    "    \n",
    "    #Converting POS tags to ones compliant with the WordNet lemmatizer\n",
    "    bigram.replace(replacements,inplace=True)\n",
    "    bigram=bigram.loc[(bigram.m_pos.isin([\"n\",\"v\",\"a\"])) & (bigram.h_pos.isin([\"n\",\"v\",\"a\"]))]\n",
    "    #t10=time.time()\n",
    "    #print(\"End of Converting POS tags to ones compliant with the WordNet lemmatizer\",t10-t9) \n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "\n",
    "    #return bigram\n",
    "    #Applying WordNet lemmatizer\n",
    "\n",
    "    #display(bigram)\n",
    "    #temp_mod=bigram[[\"modifier\",\"m_pos\"]].drop_duplicates()\n",
    "    #display(temp_mod)\n",
    "    #temp_mod['lemma_mod']=temp_mod.apply(lemmamaker_mod,axis=1)\n",
    "    \n",
    "    \n",
    "    #temp_head=bigram[[\"head\",\"h_pos\"]].drop_duplicates()\n",
    "    #temp_head['lemma_head']=temp_head.apply(lemmamaker_head,axis=1)\n",
    "    \n",
    "    \n",
    "    #lemma_replacements={'modifier':dict(zip(temp_mod.modifier,temp_mod.lemma_mod)),'head':dict(zip(temp_head['head'],temp_head.lemma_head))}\n",
    "\n",
    "    \n",
    "    #bigram.replace(lemma_replacements,inplace=True)\n",
    "    #bigram[['modifier_temp','head_temp']]=bigram.apply(lemmamaker)\n",
    "    #bigram.drop([\"modifer\",\"head\"],axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    #display(bigram)\n",
    "    bigram=nayalemma_maker(bigram)\n",
    "    #t11=time.time()\n",
    "    #print(\"End of Applying WordNet lemmatizer\",t11-t10) \n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "\n",
    "    \n",
    "    #Merging words with their pos tags\n",
    "    #bigram['head']=bigram['head_temp'].astype(str) + '_' + bigram['h_pos'].astype(str)\n",
    "    #bigram.drop([\"head_temp\",\"h_pos\"],axis=1,inplace=True)\n",
    "\n",
    "    #bigram['modifier']=bigram['modifier_temp'].astype(str) + '_' + bigram['m_pos'].astype(str)\n",
    "    #bigram.drop([\"modifier_temp\",\"m_pos\",\"head_temp\",\"h_pos\"],axis=1,inplace=True)\n",
    "    #t12=time.time()\n",
    "    #print(\"End of Merging words with their pos tags\",t12-t11) \n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "\n",
    "    \n",
    "    #Merging rows on lemmas\n",
    "    bigram=bigram.groupby(['modifier','head','year'])['count'].sum().to_frame()\n",
    "    #bigram=bigram.reset_index(level=['modifier','head','decade'])\n",
    "    #t12=time.time()\n",
    "    #print(\"End of Merging rows on lemmas\",t12-t11) \n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "\n",
    "    \n",
    "    #Selecting words on frequency cutoff of 3\n",
    "    bigram= bigram.query('count > 9')\n",
    "    bigram.reset_index(inplace=True)\n",
    "    #t13=time.time()\n",
    "    #print(\"End of Selecting words on frequency cutoff of 3\",t13-t12) \n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "    \n",
    "    #Pivoting the dataset, with the words as rows and the decades as columns\n",
    "    \n",
    "    #bigram=pd.pivot_table(bigram,index=['modifier','head'],columns='year',values='count',aggfunc=np.sum)\n",
    "    #bigram.columns=['1800s','1810s','1820s','1830s','1840s','1850s','1860s','1870s','1880s','1890s','1900s','1910s','1920s','1930s','1940s','1950s','1960s','1970s','1980s','1990s','2000s']\n",
    "    #display(bigram.info())\n",
    "    #display(unigram)\n",
    "    #bigram.reset_index(inplace=True)\n",
    "    #display(bigram)\n",
    "    #t14=time.time()\n",
    "    #print(\"End of Pivoting the dataset, with the words as rows and the decades as columns\",t14-t13)\n",
    "    #bigram.info(verbose=False,memory_usage=True)\n",
    "\n",
    "    #outfile_file='/fs/scratch/users/dharpt/bigrams/'+letter+'.csv'\n",
    "    #with open(outfile_file, 'w') as f:\n",
    "        #bigram.to_csv(f, sep=\"\\t\")\n",
    "    return(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_a</td>\n",
       "      <td>1930.000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_a</td>\n",
       "      <td>1940.000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_a</td>\n",
       "      <td>1950.000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_a</td>\n",
       "      <td>1960.000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_a</td>\n",
       "      <td>1970.000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_a</td>\n",
       "      <td>1980.000</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_a</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_a</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>1910.000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>1930.000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>1940.000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>1950.000</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>1960.000</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>1970.000</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>1980.000</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a_a</td>\n",
       "      <td>a_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a_a</td>\n",
       "      <td>ab_n</td>\n",
       "      <td>1950.000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a_a</td>\n",
       "      <td>ab_n</td>\n",
       "      <td>1960.000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a_a</td>\n",
       "      <td>ab_n</td>\n",
       "      <td>1970.000</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a_a</td>\n",
       "      <td>ab_n</td>\n",
       "      <td>1980.000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a_a</td>\n",
       "      <td>ab_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a_a</td>\n",
       "      <td>ab_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a_a</td>\n",
       "      <td>above_a</td>\n",
       "      <td>1940.000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>a_a</td>\n",
       "      <td>above_a</td>\n",
       "      <td>1950.000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a_a</td>\n",
       "      <td>above_a</td>\n",
       "      <td>1960.000</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a_a</td>\n",
       "      <td>above_a</td>\n",
       "      <td>1970.000</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a_a</td>\n",
       "      <td>above_a</td>\n",
       "      <td>1980.000</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>a_a</td>\n",
       "      <td>above_a</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a_a</td>\n",
       "      <td>above_a</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524676</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>have_v</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524677</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>image_v</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524678</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>power_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524679</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>pulse_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524680</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>pulse_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524681</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>pulse_v</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524682</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>pulse_v</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524683</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>radiation_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524684</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>radiation_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524685</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>range_n</td>\n",
       "      <td>1980.000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524686</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>range_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524687</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>range_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524688</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>regime_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524689</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>regime_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524690</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>region_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524691</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>region_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524692</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>signal_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524693</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>signal_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524694</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>source_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524695</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>spectral_a</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524696</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>spectrum_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524697</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>theologische_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524698</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>theologische_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524699</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>wave_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524700</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>wave_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524701</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>waveform_n</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524702</th>\n",
       "      <td>thz_n</td>\n",
       "      <td>waveform_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524703</th>\n",
       "      <td>thz_v</td>\n",
       "      <td>radiation_n</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524704</th>\n",
       "      <td>thzt_n</td>\n",
       "      <td>be_v</td>\n",
       "      <td>1990.000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524705</th>\n",
       "      <td>thzt_n</td>\n",
       "      <td>be_v</td>\n",
       "      <td>2000.000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227586886 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        modifier            head     year  count\n",
       "0            a_a             a_a 1930.000     12\n",
       "1            a_a             a_a 1940.000     14\n",
       "2            a_a             a_a 1950.000     18\n",
       "3            a_a             a_a 1960.000     16\n",
       "4            a_a             a_a 1970.000     11\n",
       "5            a_a             a_a 1980.000     43\n",
       "6            a_a             a_a 1990.000    100\n",
       "7            a_a             a_a 2000.000     74\n",
       "8            a_a             a_n 1910.000     11\n",
       "9            a_a             a_n 1930.000     17\n",
       "10           a_a             a_n 1940.000     29\n",
       "11           a_a             a_n 1950.000     49\n",
       "12           a_a             a_n 1960.000     66\n",
       "13           a_a             a_n 1970.000     99\n",
       "14           a_a             a_n 1980.000    165\n",
       "15           a_a             a_n 1990.000    205\n",
       "16           a_a             a_n 2000.000    204\n",
       "17           a_a            ab_n 1950.000     16\n",
       "18           a_a            ab_n 1960.000     33\n",
       "19           a_a            ab_n 1970.000     41\n",
       "20           a_a            ab_n 1980.000     20\n",
       "21           a_a            ab_n 1990.000     39\n",
       "22           a_a            ab_n 2000.000     86\n",
       "23           a_a         above_a 1940.000     12\n",
       "24           a_a         above_a 1950.000     28\n",
       "25           a_a         above_a 1960.000     48\n",
       "26           a_a         above_a 1970.000     52\n",
       "27           a_a         above_a 1980.000     74\n",
       "28           a_a         above_a 1990.000     66\n",
       "29           a_a         above_a 2000.000     69\n",
       "...          ...             ...      ...    ...\n",
       "1524676    thz_n          have_v 2000.000    111\n",
       "1524677    thz_n         image_v 2000.000     84\n",
       "1524678    thz_n         power_n 2000.000     97\n",
       "1524679    thz_n         pulse_n 1990.000    135\n",
       "1524680    thz_n         pulse_n 2000.000    903\n",
       "1524681    thz_n         pulse_v 1990.000     11\n",
       "1524682    thz_n         pulse_v 2000.000    119\n",
       "1524683    thz_n     radiation_n 1990.000    175\n",
       "1524684    thz_n     radiation_n 2000.000    796\n",
       "1524685    thz_n         range_n 1980.000     17\n",
       "1524686    thz_n         range_n 1990.000     51\n",
       "1524687    thz_n         range_n 2000.000    491\n",
       "1524688    thz_n        regime_n 1990.000     30\n",
       "1524689    thz_n        regime_n 2000.000    164\n",
       "1524690    thz_n        region_n 1990.000     27\n",
       "1524691    thz_n        region_n 2000.000    389\n",
       "1524692    thz_n        signal_n 1990.000     47\n",
       "1524693    thz_n        signal_n 2000.000    280\n",
       "1524694    thz_n        source_n 2000.000    119\n",
       "1524695    thz_n      spectral_a 2000.000     68\n",
       "1524696    thz_n      spectrum_n 2000.000    121\n",
       "1524697    thz_n  theologische_n 1990.000     19\n",
       "1524698    thz_n  theologische_n 2000.000     11\n",
       "1524699    thz_n          wave_n 1990.000     13\n",
       "1524700    thz_n          wave_n 2000.000    531\n",
       "1524701    thz_n      waveform_n 1990.000     18\n",
       "1524702    thz_n      waveform_n 2000.000    113\n",
       "1524703    thz_v     radiation_n 2000.000     69\n",
       "1524704   thzt_n            be_v 1990.000     12\n",
       "1524705   thzt_n            be_v 2000.000     10\n",
       "\n",
       "[227586886 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-10:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#def main():,chunksize=len(unigram_list)\n",
    "all_df=[]\n",
    "cpu_count=10\n",
    "pool=multiprocessing.Pool(cpu_count)\n",
    "for temp_df in pool.imap_unordered(bigram_extracter,bigram_list):\n",
    "    all_df.append(temp_df)\n",
    "\n",
    "pool.join()\n",
    "pool.close()\n",
    "#Concatenating all dataframes into 1\n",
    "bigram = pd.concat(all_df)\n",
    "#bigram=bigram.groupby([\"modifier\",\"head\"])['1800s','1810s','1820s','1830s','1840s','1850s','1860s','1870s','1880s','1890s','1900s','1910s','1920s','1930s','1940s','1950s','1960s','1970s','1980s','1990s','2000s'].sum()\n",
    "bigram=pd.pivot_table(bigram,index=['modifier','head'],columns='year',values='count',aggfunc=np.sum)\n",
    "bigram.columns=['1800s','1810s','1820s','1830s','1840s','1850s','1860s','1870s','1880s','1890s','1900s','1910s','1920s','1930s','1940s','1950s','1960s','1970s','1980s','1990s','2000s']\n",
    "bigram['cf']=np.log10(bigram.sum(axis=1))\n",
    "bigram['presence']=bigram.drop('cf',axis=1).count(axis=1)\n",
    "\n",
    "\n",
    "#unigram['presence']=unigram.count(axis=1)\n",
    "#unigram['idf']=np.log10(18/unigram['presence'])\n",
    "bigram['presence']=bigram[\"presence\"].astype('category')\n",
    "bigram[bigram.columns[:-2]]=bigram[bigram.columns[:-2]].apply(tf, axis=1)\n",
    "bigram['pattern']=bigram[bigram.columns[:-2]].apply(patternmaker,axis=1)\n",
    "display(bigram.head(10))\n",
    "bigram.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/fs/scratch/users/dharpt/bigrams/bigrams.csv', 'w') as f:\n",
    "    #bigram.to_csv(f, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'bigrams/bigrams.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2d3293de556a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbigram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bigrams/bigrams.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbigram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'bigrams/bigrams.csv' does not exist"
     ]
    }
   ],
   "source": [
    "bigram=pd.read_csv(\"\",sep=\"\\t\",index_col=[0,1])\n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/fs/scratch/users/dharpt/bigrams/bigrams.csv', 'w') as f:\n",
    "    #bigram.to_csv(f, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
