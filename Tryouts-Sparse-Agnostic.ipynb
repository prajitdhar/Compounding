{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import pickle as pkl\n",
    "\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", font_scale = 2.5)\n",
    "sns.set_context(rc={\"lines.markersize\": 17, \"lines.linewidth\": 2})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Compute features from sparse dataset for google version')\n",
    "\n",
    "parser.add_argument('--inputdir',type=str,\n",
    "                    help='Provide directory where features are located')\n",
    "parser.add_argument('--outputdir',type=str,\n",
    "                    help='Where should the output be stored?')\n",
    "parser.add_argument('--tag', action='store_true',\n",
    "                    help='Should the POS tag be kept?')\n",
    "parser.add_argument('--ppmi', action='store_true',\n",
    "                    help='Should co-occurence matrix be converted to PPMI values')\n",
    "parser.add_argument('--plot', action='store_true',\n",
    "                    help='Should plots be saved')\n",
    "parser.add_argument('--temporal',  type=int,\n",
    "                    help='Value to bin the temporal information: 10000 (remove temporal information), 1 (no binning), 10 (binning to decades), 20 (binning each 20 years) or 50 (binning each 50 years)')\n",
    "\n",
    "parser.add_argument('--cutoff', type=int, default=0,\n",
    "                    help='Cut-off frequency for each compound per time period : none (0), 20, 50 and 100')\n",
    "args = parser.parse_args('--inputdir /data/dharp/compounds/datasets/ --outputdir /data/dharp/compounds/datasets/features/ --temporal 100'.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "      <th>avgModifier</th>\n",
       "      <th>stdevModifier</th>\n",
       "      <th>avgHead</th>\n",
       "      <th>stdevHead</th>\n",
       "      <th>compositionality</th>\n",
       "      <th>stdevHeadModifier</th>\n",
       "      <th>is_adj</th>\n",
       "      <th>compound</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>end</td>\n",
       "      <td>user</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>1.117537</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>0.339935</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.871165</td>\n",
       "      <td>False</td>\n",
       "      <td>end_user</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>firing</td>\n",
       "      <td>line</td>\n",
       "      <td>1.607143</td>\n",
       "      <td>1.654848</td>\n",
       "      <td>1.892857</td>\n",
       "      <td>1.496169</td>\n",
       "      <td>1.703704</td>\n",
       "      <td>1.717337</td>\n",
       "      <td>False</td>\n",
       "      <td>firing_line</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>game</td>\n",
       "      <td>plan</td>\n",
       "      <td>2.821429</td>\n",
       "      <td>1.964935</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>3.827586</td>\n",
       "      <td>1.233693</td>\n",
       "      <td>False</td>\n",
       "      <td>game_plan</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>application</td>\n",
       "      <td>form</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>0.422953</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.476095</td>\n",
       "      <td>False</td>\n",
       "      <td>application_form</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snail</td>\n",
       "      <td>mail</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4.586207</td>\n",
       "      <td>1.099129</td>\n",
       "      <td>1.310345</td>\n",
       "      <td>1.020596</td>\n",
       "      <td>False</td>\n",
       "      <td>snail_mail</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>wedding</td>\n",
       "      <td>day</td>\n",
       "      <td>4.764700</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>4.058800</td>\n",
       "      <td>1.434900</td>\n",
       "      <td>4.941200</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>False</td>\n",
       "      <td>wedding_day</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>white</td>\n",
       "      <td>noise</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>1.112300</td>\n",
       "      <td>4.043500</td>\n",
       "      <td>1.429500</td>\n",
       "      <td>1.173900</td>\n",
       "      <td>1.230400</td>\n",
       "      <td>True</td>\n",
       "      <td>white_noise</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>white</td>\n",
       "      <td>spirit</td>\n",
       "      <td>1.538500</td>\n",
       "      <td>1.240300</td>\n",
       "      <td>2.038500</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.307700</td>\n",
       "      <td>1.257600</td>\n",
       "      <td>True</td>\n",
       "      <td>white_spirit</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>winter</td>\n",
       "      <td>solstice</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.681800</td>\n",
       "      <td>1.086100</td>\n",
       "      <td>4.545500</td>\n",
       "      <td>1.335500</td>\n",
       "      <td>False</td>\n",
       "      <td>winter_solstice</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>world</td>\n",
       "      <td>conference</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>1.361300</td>\n",
       "      <td>4.291700</td>\n",
       "      <td>1.267600</td>\n",
       "      <td>3.958300</td>\n",
       "      <td>1.366700</td>\n",
       "      <td>False</td>\n",
       "      <td>world_conference</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        modifier        head  avgModifier  stdevModifier   avgHead  stdevHead  \\\n",
       "0            end        user     3.866667       1.117537  4.866667   0.339935   \n",
       "1         firing        line     1.607143       1.654848  1.892857   1.496169   \n",
       "2           game        plan     2.821429       1.964935  4.862069   0.344828   \n",
       "3    application        form     4.766667       0.422953  4.862069   0.344828   \n",
       "4          snail        mail     0.600000       0.800000  4.586207   1.099129   \n",
       "..           ...         ...          ...            ...       ...        ...   \n",
       "97       wedding         day     4.764700       0.562300  4.058800   1.434900   \n",
       "98         white       noise     0.652200       1.112300  4.043500   1.429500   \n",
       "99         white      spirit     1.538500       1.240300  2.038500   1.949000   \n",
       "100       winter    solstice     5.000000       0.000000  4.681800   1.086100   \n",
       "101        world  conference     3.875000       1.361300  4.291700   1.267600   \n",
       "\n",
       "     compositionality  stdevHeadModifier  is_adj          compound  \\\n",
       "0            4.250000           0.871165   False          end_user   \n",
       "1            1.703704           1.717337   False       firing_line   \n",
       "2            3.827586           1.233693   False         game_plan   \n",
       "3            4.800000           0.476095   False  application_form   \n",
       "4            1.310345           1.020596   False        snail_mail   \n",
       "..                ...                ...     ...               ...   \n",
       "97           4.941200           0.242500   False       wedding_day   \n",
       "98           1.173900           1.230400    True       white_noise   \n",
       "99           1.307700           1.257600    True      white_spirit   \n",
       "100          4.545500           1.335500   False   winter_solstice   \n",
       "101          3.958300           1.366700   False  world_conference   \n",
       "\n",
       "          source  \n",
       "0          reddy  \n",
       "1          reddy  \n",
       "2          reddy  \n",
       "3          reddy  \n",
       "4          reddy  \n",
       "..           ...  \n",
       "97   cordeiro100  \n",
       "98   cordeiro100  \n",
       "99   cordeiro100  \n",
       "100  cordeiro100  \n",
       "101  cordeiro100  \n",
       "\n",
       "[287 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddy_df=pd.read_csv('data/reddy_90.txt',sep='\\t')\n",
    "reddy_df['source']='reddy'\n",
    "cordeiro90_df=pd.read_csv('data/cordeiro_90.txt',sep='\\t')\n",
    "cordeiro90_df['source']='cordeiro90'\n",
    "cordeiro100_df=pd.read_csv('data/cordeiro_100.txt',sep='\\t')\n",
    "cordeiro100_df['source']='cordeiro100'\n",
    "\n",
    "    \n",
    "comp_ratings_df=pd.concat([reddy_df,cordeiro90_df,cordeiro100_df])\n",
    "#comp_ratings_df.drop_duplicates(inplace=True)\n",
    "comp_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_decades_compound(dec_list,input_dir,ctype='compound'):\n",
    "\n",
    "    if os.path.exists(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\"):\n",
    "        print('Reading file')\n",
    "        complete_df=pd.read_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "    elif os.path.exists(f\"{input_dir}/{ctype}s/10_{dec_list[0]}_{tag_str}.pkl\") and args.temporal!=10000:\n",
    "        print(f'Reading decades file {ctype}s/10_{dec_list[0]}_{tag_str}.pkl')\n",
    "        complete_df=pd.read_pickle(f\"{input_dir}/{ctype}s/10_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "        print(f'Reducing to {args.temporal}')\n",
    "        complete_df['time']=complete_df['time']-complete_df['time']%args.temporal\n",
    "\n",
    "        complete_df=complete_df.groupby(['modifier','head','time','context'])['count'].sum().to_frame().reset_index()\n",
    "        \n",
    "        print(\"Saving file\")\n",
    "        complete_df.to_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        df_list=[]\n",
    "\n",
    "        for dec in dec_list:\n",
    "            print(dec)\n",
    "            cur_df=pd.read_pickle(f'{input_dir}/{ctype}s/{dec}.pkl')\n",
    "            \n",
    "            if not args.tag:\n",
    "                cur_df=compound_tag_remover(cur_df)\n",
    "            cur_df['time']=dec\n",
    "            cur_df['time']=cur_df['time']-cur_df['time']%args.temporal\n",
    "            df_list.append(cur_df)\n",
    "\n",
    "        print('Done reading compound dataframes')\n",
    "        complete_df=pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "        if args.temporal!=10:\n",
    "            complete_df=complete_df.groupby(['modifier','head','time','context'])['count'].sum().to_frame().reset_index()\n",
    "        \n",
    "        print(\"Saving file\")\n",
    "        complete_df.to_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "        \n",
    "    return complete_df\n",
    "\n",
    "\n",
    "def process_decades_constituent(dec_list,input_dir,ctype='word'):\n",
    "        \n",
    "    if os.path.exists(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\"):\n",
    "        print('Reading file')\n",
    "        complete_df=pd.read_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "    elif os.path.exists(f\"{input_dir}/{ctype}s/10_{dec_list[0]}_{tag_str}.pkl\") and args.temporal!=10000:\n",
    "        print(f'Reading decades file {ctype}s/10_{dec_list[0]}_{tag_str}.pkl')\n",
    "        complete_df=pd.read_pickle(f\"{input_dir}/{ctype}s/10_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "        print(f'Reducing to {args.temporal}')\n",
    "        complete_df['time']=complete_df['time']-complete_df['time']%args.temporal\n",
    "        complete_df=complete_df.groupby([ctype,'time','context'])['count'].sum().to_frame().reset_index()\n",
    "        \n",
    "        print(\"Saving file\")\n",
    "        complete_df.to_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        df_list=[]\n",
    "\n",
    "        for dec in dec_list:\n",
    "            cur_df=pd.read_pickle(f'{input_dir}/{ctype}s/{dec}.pkl')\n",
    "            if not args.tag:\n",
    "                cur_df=constituent_tag_remover(cur_df,ctype)\n",
    "            cur_df['time']=dec\n",
    "            cur_df['time']=cur_df['time']-cur_df['time']%args.temporal\n",
    "            df_list.append(cur_df)\n",
    "\n",
    "        print(f'Done reading {ctype} dataframes')\n",
    "        complete_df=pd.concat(df_list,ignore_index=True)\n",
    "        \n",
    "        if args.temporal!=10:\n",
    "            complete_df=complete_df.groupby([ctype,'time','context'])['count'].sum().to_frame().reset_index()\n",
    "        \n",
    "        print(\"Saving file\")\n",
    "        complete_df.to_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}.pkl\")\n",
    "\n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compound_tag_remover(compounds):\n",
    "    \n",
    "    print('Removing tags for compound dataset')\n",
    "    compounds['head']=compounds['head'].str.replace('_NOUN|_PROPN','',regex=True)\n",
    "    compounds.modifier=compounds.modifier.str.replace('_NOUN|_PROPN|_ADJ','',regex=True)\n",
    "    \n",
    "    compounds=compounds.groupby(['modifier','head','context'])['count'].sum().to_frame().reset_index()\n",
    "\n",
    "    return compounds\n",
    "\n",
    "\n",
    "def constituent_tag_remover(constituents,ctype='word'):\n",
    "    \n",
    "    print(f'Removing tags for {ctype} dataset')\n",
    "    constituents[ctype]=constituents[ctype].str.replace('_NOUN|_PROPN|_ADJ','',regex=True)\n",
    "    \n",
    "    constituents=constituents.groupby([ctype,'context'])['count'].sum().to_frame().reset_index()\n",
    "\n",
    "    return constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cutoff_compound(df):\n",
    "\n",
    "    df=df.loc[df.groupby(['modifier','head','time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def process_cutoff_constituent(df,ctype='word'):\n",
    "\n",
    "    df=df.loc[df.groupby([ctype,'time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ppmi(ppmi_df):\n",
    "    \n",
    "    ppmi_cols=ppmi_df.columns.tolist()\n",
    "    ppmi_cols=['XY' if 'count' in x else x for x in ppmi_cols]\n",
    "    ppmi_df.columns=ppmi_cols\n",
    "\n",
    "    Y_star=ppmi_df.groupby(['context'])['XY'].sum().to_frame()\n",
    "    Y_star.columns=['Y']\n",
    "\n",
    "    ppmi_df=pd.merge(ppmi_df,Y_star.reset_index(),on=['context'])\n",
    "\n",
    "    X_star=ppmi_df.groupby(ppmi_cols[:-2])['XY'].sum().to_frame()\n",
    "    X_star.columns=['X']\n",
    "\n",
    "    ppmi_df=pd.merge(ppmi_df,X_star.reset_index(),on=ppmi_cols[:-2])\n",
    "\n",
    "    numerator_count=ppmi_df.X.sum()\n",
    "\n",
    "    ppmi_df['count']=np.log2((ppmi_df['XY']*numerator_count+1)/(ppmi_df['X']*ppmi_df['Y']+1))\n",
    "    ppmi_df.loc[ppmi_df['count']<=0,'count']=0\n",
    "    ppmi_df.drop(['XY','X','Y'],axis=1,inplace=True)\n",
    "    \n",
    "    return ppmi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_compound_features(compounds,modifiers,heads,all_comps,not_found_compounds_df,not_found_modifiers_df,not_found_heads_df):\n",
    "    \n",
    "    mod_cols=modifiers.columns.tolist()\n",
    "    mod_cols=['count' if 'count' in x else x for x in mod_cols]\n",
    "    modifiers.columns=mod_cols\n",
    "\n",
    "    head_cols=heads.columns.tolist()\n",
    "    head_cols=['count' if 'count' in x else x for x in head_cols]\n",
    "    heads.columns=head_cols\n",
    "\n",
    "    comp_cols=compounds.columns.tolist()\n",
    "    comp_cols=['count' if 'count' in x else x for x in comp_cols]\n",
    "    compounds.columns=comp_cols\n",
    "\n",
    "    print('Calculating productivity features')\n",
    "    \n",
    "    compound_types=compounds.groupby(['time']).size().to_frame()\n",
    "    compound_types.columns=['comp_size']\n",
    "    \n",
    "    modifier_types=modifiers.groupby(['time']).size().to_frame()\n",
    "    modifier_types.columns=['mod_size']\n",
    "    \n",
    "    head_types=heads.groupby(['time']).size().to_frame()\n",
    "    head_types.columns=['head_size']\n",
    "\n",
    "    mod_prod=compounds.groupby(['modifier','time']).size().to_frame()\n",
    "    mod_prod.columns=['mod_prod']\n",
    "    mod_prod=pd.merge(mod_prod.reset_index(),compound_types.reset_index(),on=['time'])\n",
    "    mod_prod=pd.merge(mod_prod,modifier_types.reset_index(),on=['time'])\n",
    "\n",
    "    mod_prod['mod_family_size']=np.log2(mod_prod.mod_prod/mod_prod.comp_size)\n",
    "    mod_prod['mod_family_size_new']=np.log2(mod_prod.mod_prod/mod_prod.mod_size)\n",
    "\n",
    "\n",
    "    not_found_mod_prod=not_found_modifiers_df.copy()\n",
    "    not_found_mod_prod['mod_prod']=0\n",
    "    not_found_mod_prod=pd.merge(not_found_mod_prod,compound_types.reset_index(),on=['time'])\n",
    "    not_found_mod_prod=pd.merge(not_found_mod_prod,modifier_types.reset_index(),on=['time'])\n",
    "    not_found_mod_prod['mod_family_size']=0\n",
    "    not_found_mod_prod['mod_family_size_new']=0\n",
    "\n",
    "\n",
    "    head_prod=compounds.groupby(['head','time']).size().to_frame()\n",
    "    head_prod.columns=['head_prod']\n",
    "    head_prod=pd.merge(head_prod.reset_index(),compound_types.reset_index(),on=['time'])\n",
    "    head_prod=pd.merge(head_prod,head_types.reset_index(),on=['time'])\n",
    "\n",
    "    head_prod['head_family_size']=np.log2(head_prod.head_prod/head_prod.comp_size)\n",
    "    head_prod['head_family_size_new']=np.log2(head_prod.head_prod/head_prod.head_size)\n",
    "\n",
    "\n",
    "    not_found_head_prod=not_found_heads_df.copy()\n",
    "    not_found_head_prod['head_prod']=0\n",
    "    not_found_head_prod=pd.merge(not_found_head_prod,compound_types.reset_index(),on=['time'])\n",
    "    not_found_head_prod=pd.merge(not_found_head_prod,head_types.reset_index(),on=['time'])\n",
    "\n",
    "    not_found_head_prod['head_family_size']=0\n",
    "    not_found_head_prod['head_family_size_new']=0\n",
    "\n",
    "    \n",
    "    mod_prod=pd.concat([mod_prod,not_found_mod_prod],ignore_index=True)\n",
    "    head_prod=pd.concat([head_prod,not_found_head_prod],ignore_index=True)\n",
    "\n",
    "\n",
    "    prod1=pd.merge(mod_prod.drop(['mod_size','comp_size'],axis=1),all_comps,on=['modifier','time'])\n",
    "    productivity=pd.merge(head_prod.drop('head_size',axis=1),prod1,on=['head','time'])\n",
    "\n",
    "\n",
    "    print('Calculating information theory features')\n",
    "    \n",
    "    compound_time_counts=compounds.groupby('time')['count'].sum().to_frame()\n",
    "    \n",
    "    compound_time_counts.columns=['N']\n",
    "    XY=compounds.groupby(['modifier','head','time'])['count'].sum().to_frame()    \n",
    "\n",
    "    XY.columns=['a']\n",
    "    \n",
    "    not_found_XY=not_found_compounds_df.copy()\n",
    "    not_found_XY['count']=0\n",
    "    not_found_XY=not_found_XY.groupby(['modifier','head','time'])['count'].sum().to_frame()\n",
    "    not_found_XY.columns=['a']\n",
    "    \n",
    "    \n",
    "    X_star=compounds.groupby(['modifier','time'])['count'].sum().to_frame()\n",
    "    X_star.columns=['x_star']\n",
    "    \n",
    "    not_found_X_star=not_found_modifiers_df.copy()\n",
    "    not_found_X_star['count']=0\n",
    "    not_found_X_star=not_found_X_star.groupby(['modifier','time'])['count'].sum().to_frame()\n",
    "    not_found_X_star.columns=['x_star']\n",
    "\n",
    "    Y_star=compounds.groupby(['head','time'])['count'].sum().to_frame()\n",
    "    Y_star.columns=['star_y']\n",
    "\n",
    "    not_found_Y_star=not_found_heads_df.copy()\n",
    "    not_found_Y_star['count']=0    \n",
    "    not_found_Y_star=not_found_Y_star.groupby(['head','time'])['count'].sum().to_frame()\n",
    "    not_found_Y_star.columns=['star_y']\n",
    "\n",
    "    XY=pd.concat([XY,not_found_XY])\n",
    "    X_star=pd.concat([X_star,not_found_X_star])\n",
    "    Y_star=pd.concat([Y_star,not_found_Y_star])\n",
    "\n",
    "    merge1=pd.merge(XY.reset_index(),X_star.reset_index(),on=['modifier','time'])\n",
    "\n",
    "    information_feat=pd.merge(merge1,Y_star.reset_index(),on=['head','time'])    \n",
    "\n",
    "    information_feat['b']=information_feat['x_star']-information_feat['a']\n",
    "    information_feat['c']=information_feat['star_y']-information_feat['a']\n",
    "\n",
    "    information_feat=pd.merge(information_feat,compound_time_counts.reset_index(),on=['time'])\n",
    "\n",
    "    information_feat['d']=information_feat['N']-(information_feat['a']+information_feat['b']+information_feat['c'])\n",
    "    information_feat['x_bar_star']=information_feat['N']-information_feat['x_star']\n",
    "    information_feat['star_y_bar']=information_feat['N']-information_feat['star_y']\n",
    "    information_feat['overflow_check']=np.log2((information_feat['d']*information_feat['N']+1)/(information_feat['x_bar_star']*information_feat['star_y_bar']+1))\n",
    "    information_feat['overflow_check'] = information_feat['overflow_check'].fillna(0)\n",
    "    information_feat['log_ratio']=2*(\\\n",
    "    information_feat['a']*np.log2((information_feat['a']*information_feat['N']+1)/(information_feat['x_star']*information_feat['star_y']+1))+\\\n",
    "    information_feat['b']*np.log2((information_feat['b']*information_feat['N']+1)/(information_feat['x_star']*information_feat['star_y_bar']+1))+\\\n",
    "    information_feat['c']*np.log2((information_feat['c']*information_feat['N']+1)/(information_feat['x_bar_star']*information_feat['star_y']+1))+\\\n",
    "    information_feat['d']*information_feat['overflow_check'])\n",
    "    information_feat['ppmi']=np.log2((information_feat['a']*information_feat['N']+1)/(information_feat['x_star']*information_feat['star_y']+1))\n",
    "    information_feat['local_mi']=information_feat['a']*information_feat['ppmi']\n",
    "    information_feat.loc[information_feat.ppmi<=0,'ppmi']=0\n",
    "    information_feat.drop(['a','x_star','star_y','b','c','N','d','x_bar_star','star_y_bar','overflow_check'],axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    compound_features=pd.merge(productivity,information_feat,on=['modifier','head','time'])\n",
    "    \n",
    "    print('Frequency features')\n",
    "            \n",
    "    modifier_time_counts=modifiers.groupby(['time'])['count'].sum().to_frame()\n",
    "    modifier_time_counts.columns=['mod_time_count']\n",
    "    \n",
    "    head_time_counts=heads.groupby(['time'])['count'].sum().to_frame()\n",
    "    head_time_counts.columns=['head_time_count']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    frequency_feat=pd.merge(XY.reset_index(),X_star.reset_index(),on=['modifier','time'])\n",
    "    frequency_feat=frequency_feat.merge(Y_star.reset_index(),on=['head','time'])\n",
    "\n",
    "    frequency_feat=frequency_feat.merge(compound_time_counts.reset_index(),on='time')\n",
    "    frequency_feat=frequency_feat.merge(modifier_time_counts.reset_index(),on='time')\n",
    "    frequency_feat=frequency_feat.merge(compound_time_counts.reset_index(),on='time')\n",
    "\n",
    "    frequency_feat.set_index(['modifier','head','time'],inplace=True)\n",
    "    frequency_feat.columns=['comp_freq','mod_freq','head_freq','N','mod_time_count','head_time_count']\n",
    "    frequency_feat['comp_tf']=np.log2(1+frequency_feat.comp_freq)\n",
    "    \n",
    "    frequency_feat['log_comp_freq']=np.log2(frequency_feat.comp_freq/frequency_feat.N)\n",
    "\n",
    "    frequency_feat['mod_tf']=np.log2(1+frequency_feat.mod_freq)\n",
    "    frequency_feat['log_mod_freq']=np.log2(frequency_feat.mod_freq/frequency_feat.N)\n",
    "    frequency_feat['log_mod_freq_new']=np.log2(frequency_feat.mod_freq/frequency_feat.mod_time_count)\n",
    "\n",
    "    frequency_feat['head_tf']=np.log2(1+frequency_feat.head_freq)\n",
    "    frequency_feat['log_head_freq']=np.log2(frequency_feat.head_freq/frequency_feat.N)\n",
    "    frequency_feat['log_head_freq_new']=np.log2(frequency_feat.head_freq/frequency_feat.head_time_count)\n",
    "    frequency_feat.fillna(0,inplace=True)\n",
    "    frequency_feat.drop(['mod_time_count','head_time_count','N'],axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    compound_features=compound_features.merge(frequency_feat.reset_index(),on=['modifier','head','time'])\n",
    "    \n",
    "    return compound_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_cosine_features(compounds,modifiers,heads,not_found_compounds_df):\n",
    "    \n",
    "    mod_cols=modifiers.columns.tolist()\n",
    "    mod_cols=['count' if 'count' in x else x for x in mod_cols]\n",
    "    modifiers.columns=mod_cols\n",
    "\n",
    "    head_cols=heads.columns.tolist()\n",
    "    head_cols=['count' if 'count' in x else x for x in head_cols]\n",
    "    heads.columns=head_cols\n",
    "\n",
    "    comp_cols=compounds.columns.tolist()\n",
    "    comp_cols=['count' if 'count' in x else x for x in comp_cols]\n",
    "    compounds.columns=comp_cols\n",
    "        \n",
    "    compound_denom=compounds.copy()\n",
    "    compound_denom['count']=compound_denom['count']**2\n",
    "    compound_denom=compound_denom.groupby(['modifier','head','time'])['count'].sum().to_frame()\n",
    "    compound_denom['count']=np.sqrt(compound_denom['count'])\n",
    "    compound_denom.columns=['compound_denom']\n",
    "\n",
    "    modifier_denom=modifiers.copy()\n",
    "    modifier_denom['count']=modifier_denom['count']**2\n",
    "    modifier_denom=modifier_denom.groupby(['modifier','time'])['count'].sum().to_frame()\n",
    "    modifier_denom['count']=np.sqrt(modifier_denom['count'])\n",
    "    modifier_denom.columns=['modifier_denom']\n",
    "\n",
    "    head_denom=heads.copy()\n",
    "    head_denom['count']=head_denom['count']**2\n",
    "    head_denom=head_denom.groupby(['head','time'])['count'].sum().to_frame()\n",
    "    head_denom['count']=np.sqrt(head_denom['count'])\n",
    "    head_denom.columns=['head_denom']\n",
    "\n",
    "    mod_cols=modifiers.columns.tolist()\n",
    "    mod_cols=['mod_count' if 'count' in x else x for x in mod_cols]\n",
    "    modifiers.columns=mod_cols\n",
    "\n",
    "    head_cols=heads.columns.tolist()\n",
    "    head_cols=['head_count' if 'count' in x else x for x in head_cols]\n",
    "    heads.columns=head_cols\n",
    "\n",
    "    comp_cols=compounds.columns.tolist()\n",
    "    comp_cols=['comp_count' if 'count' in x else x for x in comp_cols]\n",
    "    compounds.columns=comp_cols\n",
    "    \n",
    "    print('Calculating cosine features')\n",
    "\n",
    "    print('compound_modifier_sim')\n",
    "    compound_modifier_sim=pd.merge(compounds,modifiers,on=[\"modifier\",\"context\",'time'])\n",
    "    compound_modifier_sim['numerator']=compound_modifier_sim['comp_count']*compound_modifier_sim['mod_count']\n",
    "    compound_modifier_sim=compound_modifier_sim.groupby(['modifier','head','time'])['numerator'].sum().to_frame()\n",
    "    compound_modifier_sim=pd.merge(compound_modifier_sim.reset_index(),compound_denom.reset_index(),on=[\"modifier\",\"head\",'time'])\n",
    "    compound_modifier_sim=pd.merge(compound_modifier_sim,modifier_denom.reset_index(),on=['modifier','time'])\n",
    "    compound_modifier_sim['sim_with_modifier']=compound_modifier_sim['numerator']/(compound_modifier_sim['compound_denom']*compound_modifier_sim['modifier_denom'])\n",
    "    compound_modifier_sim.drop(['numerator','compound_denom','modifier_denom'],axis=1,inplace=True)\n",
    "\n",
    "    print('compound_head_sim')\n",
    "    compound_head_sim=pd.merge(compounds,heads,on=[\"head\",\"context\",'time'])\n",
    "    compound_head_sim['numerator']=compound_head_sim['comp_count']*compound_head_sim['head_count']\n",
    "    compound_head_sim=compound_head_sim.groupby(['modifier','head','time'])['numerator'].sum().to_frame()\n",
    "    compound_head_sim=pd.merge(compound_head_sim.reset_index(),compound_denom.reset_index(),on=[\"modifier\",\"head\",'time'])\n",
    "    compound_head_sim=pd.merge(compound_head_sim,head_denom.reset_index(),on=['head','time'])\n",
    "    compound_head_sim['sim_with_head']=compound_head_sim['numerator']/(compound_head_sim['compound_denom']*compound_head_sim['head_denom'])\n",
    "    compound_head_sim.drop(['numerator','compound_denom','head_denom'],axis=1,inplace=True)\n",
    "    \n",
    "    cosine_sim_feat=pd.merge(compound_modifier_sim,compound_head_sim,on=['modifier','head','time'])\n",
    "    \n",
    "    print('constituent_sim')\n",
    "\n",
    "    constituent_sim=pd.merge(heads,compounds,on=[\"head\",\"context\",\"time\"])\n",
    "    #constituent_sim.drop('comp_count',axis=1,inplace=True)\n",
    "    constituent_sim=pd.merge(constituent_sim,modifiers,on=[\"modifier\",\"context\",\"time\"])\n",
    "    constituent_sim['numerator']=constituent_sim['head_count']*constituent_sim['mod_count']\n",
    "    constituent_sim=constituent_sim.groupby(['modifier','head','time'])['numerator'].sum().to_frame()\n",
    "    constituent_sim=pd.merge(constituent_sim.reset_index(),head_denom.reset_index(),on=[\"head\",\"time\"])\n",
    "    constituent_sim=pd.merge(constituent_sim,modifier_denom.reset_index(),on=[\"modifier\",\"time\"])\n",
    "    constituent_sim['sim_bw_constituents']=constituent_sim['numerator']/(constituent_sim['head_denom']*constituent_sim['modifier_denom'])\n",
    "    constituent_sim.drop(['numerator','modifier_denom','head_denom'],axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    not_found_constituent_sim=pd.merge(not_found_compounds_df,heads,on=[\"head\",'time'])\n",
    "    not_found_constituent_sim=pd.merge(not_found_constituent_sim,modifiers,on=[\"modifier\",'context','time'])\n",
    "    not_found_constituent_sim['numerator']=not_found_constituent_sim['head_count']*not_found_constituent_sim['mod_count']\n",
    "    not_found_constituent_sim=not_found_constituent_sim.groupby(['modifier','head','time'])['numerator'].sum().to_frame()\n",
    "    not_found_constituent_sim=pd.merge(not_found_constituent_sim.reset_index(),head_denom.reset_index(),on=[\"head\",'time'])\n",
    "    not_found_constituent_sim=pd.merge(not_found_constituent_sim,modifier_denom.reset_index(),on=[\"modifier\",'time'])\n",
    "    not_found_constituent_sim['sim_bw_constituents']=not_found_constituent_sim['numerator']/(not_found_constituent_sim['head_denom']*not_found_constituent_sim['modifier_denom'])\n",
    "    not_found_constituent_sim.drop(['numerator','modifier_denom','head_denom'],axis=1,inplace=True)\n",
    "    \n",
    "    constituent_sim=pd.concat([constituent_sim,not_found_constituent_sim])\n",
    "\n",
    "    \n",
    "    cosine_sim_feat=pd.merge(cosine_sim_feat,constituent_sim,on=['modifier','head','time'],how='right')\n",
    "    print('Cordeiro features')\n",
    "\n",
    "    cosine_sim_feat['beta']=(cosine_sim_feat['sim_with_modifier']-cosine_sim_feat['sim_with_head']*cosine_sim_feat['sim_bw_constituents'])/\\\n",
    "    ((cosine_sim_feat['sim_with_modifier']+cosine_sim_feat['sim_with_head'])*(1-cosine_sim_feat['sim_bw_constituents']))\n",
    "    cosine_sim_feat.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    na_values = {\"beta\": 0.5}\n",
    "    cosine_sim_feat.fillna(value=na_values,inplace=True)\n",
    "\n",
    "    cosine_sim_feat['geom_mean_sim']=np.sqrt(cosine_sim_feat['sim_with_modifier']*cosine_sim_feat['sim_with_head'])\n",
    "    cosine_sim_feat['arith_mean_sim']=cosine_sim_feat[['sim_with_modifier', 'sim_with_head']].mean(axis=1)\n",
    "    \n",
    "    cpf_head_df=pd.merge(heads,head_denom.reset_index(),on=[\"head\",'time'])\n",
    "    cpf_head_df['head_value']=cpf_head_df['head_count']/cpf_head_df['head_denom']\n",
    "    cpf_head_df.drop(['head_count','head_denom'],axis=1,inplace=True)\n",
    "\n",
    "    cpf_modifier_df=pd.merge(modifiers,modifier_denom.reset_index(),on=[\"modifier\",'time'])\n",
    "    cpf_modifier_df['modifier_value']=cpf_modifier_df['mod_count']/cpf_modifier_df['modifier_denom']\n",
    "    cpf_modifier_df.drop(['mod_count','modifier_denom'],axis=1,inplace=True)\n",
    "    \n",
    "    cpf_sim=pd.merge(cpf_head_df,compounds,on=[\"head\",\"context\",\"time\"])\n",
    "    cpf_sim=pd.merge(cpf_sim,cpf_modifier_df,on=[\"modifier\",\"context\",\"time\"])\n",
    "    cpf_sim=pd.merge(cpf_sim,cosine_sim_feat[['modifier','head','beta','time']],on=[\"modifier\",'head','time'])\n",
    "\n",
    "    beta=0.0\n",
    "    cpf_sim['cp_0']=(beta*(cpf_sim['head_value'])/((cpf_sim['head_value']**2).sum()))+((1-beta)*cpf_sim['modifier_value'])\n",
    "\n",
    "    beta=0.25\n",
    "    cpf_sim['cp_25']=(beta*cpf_sim['head_value'])+((1-beta)*cpf_sim['modifier_value'])\n",
    "\n",
    "    beta=0.5\n",
    "    cpf_sim['cp_50']=(beta*cpf_sim['head_value'])+((1-beta)*cpf_sim['modifier_value'])\n",
    "\n",
    "    beta=0.75\n",
    "    cpf_sim['cp_75']=(beta*cpf_sim['head_value'])+((1-beta)*cpf_sim['modifier_value'])\n",
    "\n",
    "    beta=1\n",
    "    cpf_sim['cp_100']=(beta*cpf_sim['head_value'])+((1-beta)*cpf_sim['modifier_value'])\n",
    "\n",
    "    cpf_sim['cp_beta']=(cpf_sim['beta']*cpf_sim['head_value'])+((1-cpf_sim['beta'])*cpf_sim['modifier_value'])\n",
    "\n",
    "    temp_cdf_df=cpf_sim[['modifier','head','time','cp_0','cp_25','cp_50','cp_75','cp_100','cp_beta']].copy()\n",
    "    temp_cdf_df['denom_cp_0']=temp_cdf_df['cp_0']**2\n",
    "    temp_cdf_df['denom_cp_25']=temp_cdf_df['cp_25']**2\n",
    "    temp_cdf_df['denom_cp_50']=temp_cdf_df['cp_50']**2\n",
    "    temp_cdf_df['denom_cp_75']=temp_cdf_df['cp_75']**2\n",
    "    temp_cdf_df['denom_cp_100']=temp_cdf_df['cp_100']**2\n",
    "    temp_cdf_df['denom_cp_beta']=temp_cdf_df['cp_beta']**2\n",
    "\n",
    "    cdf_denom=temp_cdf_df.groupby(['modifier','head','time'])[['denom_cp_0','denom_cp_25','denom_cp_50','denom_cp_75','denom_cp_100','denom_cp_beta']].sum()\n",
    "    cdf_denom['denom_cp_0']=np.sqrt(cdf_denom['denom_cp_0'])\n",
    "    cdf_denom['denom_cp_25']=np.sqrt(cdf_denom['denom_cp_25'])\n",
    "    cdf_denom['denom_cp_50']=np.sqrt(cdf_denom['denom_cp_50'])\n",
    "    cdf_denom['denom_cp_75']=np.sqrt(cdf_denom['denom_cp_75'])\n",
    "    cdf_denom['denom_cp_100']=np.sqrt(cdf_denom['denom_cp_100'])\n",
    "    cdf_denom['denom_cp_beta']=np.sqrt(cdf_denom['denom_cp_beta'])\n",
    "\n",
    "    cpf_sim['num_cp_0']=cpf_sim['comp_count']*cpf_sim['cp_0']\n",
    "    cpf_sim['num_cp_25']=cpf_sim['comp_count']*cpf_sim['cp_25']\n",
    "    cpf_sim['num_cp_50']=cpf_sim['comp_count']*cpf_sim['cp_50']\n",
    "    cpf_sim['num_cp_75']=cpf_sim['comp_count']*cpf_sim['cp_75']\n",
    "    cpf_sim['num_cp_100']=cpf_sim['comp_count']*cpf_sim['cp_100']\n",
    "    cpf_sim['num_cp_beta']=cpf_sim['comp_count']*cpf_sim['cp_beta']\n",
    "\n",
    "    cpf_sim=cpf_sim.groupby(['modifier','head','time'])[['num_cp_0','num_cp_25','num_cp_50','num_cp_75','num_cp_100','num_cp_beta']].sum()\n",
    "    cpf_sim=pd.merge(cpf_sim,cdf_denom,on=['modifier','head','time'])\n",
    "    cpf_sim=pd.merge(cpf_sim,compound_denom.reset_index(),on=[\"modifier\",\"head\",\"time\"])\n",
    "    cpf_sim['sim_cpf_0']=cpf_sim['num_cp_0']/(cpf_sim['denom_cp_0']*cpf_sim['compound_denom'])\n",
    "    cpf_sim['sim_cpf_25']=cpf_sim['num_cp_25']/(cpf_sim['denom_cp_25']*cpf_sim['compound_denom'])\n",
    "    cpf_sim['sim_cpf_50']=cpf_sim['num_cp_50']/(cpf_sim['denom_cp_50']*cpf_sim['compound_denom'])\n",
    "    cpf_sim['sim_cpf_75']=cpf_sim['num_cp_75']/(cpf_sim['denom_cp_75']*cpf_sim['compound_denom'])\n",
    "    cpf_sim['sim_cpf_100']=cpf_sim['num_cp_100']/(cpf_sim['denom_cp_100']*cpf_sim['compound_denom'])\n",
    "    cpf_sim['sim_cpf_beta']=cpf_sim['num_cp_beta']/(cpf_sim['denom_cp_beta']*cpf_sim['compound_denom'])\n",
    "\n",
    "    cpf_sim=cpf_sim[['modifier','head','time','sim_cpf_0','sim_cpf_25','sim_cpf_50','sim_cpf_75','sim_cpf_100','sim_cpf_beta']].copy()\n",
    "    \n",
    "    cosine_sim_feat=cosine_sim_feat.merge(cpf_sim,on=[\"modifier\",'head','time'],how='left')\n",
    "    \n",
    "    return cosine_sim_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_setting_similarity(compounds,modifiers,heads,compounds_agnostic,modifiers_agnostic,heads_agnostic,compound_list_df):\n",
    "    \n",
    "    \n",
    "    mod_cols=modifiers.columns.tolist()\n",
    "    mod_cols=['count' if 'count' in x else x for x in mod_cols]\n",
    "    modifiers.columns=mod_cols\n",
    "\n",
    "    head_cols=heads.columns.tolist()\n",
    "    head_cols=['count' if 'count' in x else x for x in head_cols]\n",
    "    heads.columns=head_cols\n",
    "\n",
    "    comp_cols=compounds.columns.tolist()\n",
    "    comp_cols=['count' if 'count' in x else x for x in comp_cols]\n",
    "    compounds.columns=comp_cols\n",
    "\n",
    "    \n",
    "    mod_agn_cols=modifiers_agnostic.columns.tolist()\n",
    "    mod_agn_cols=['count' if 'count' in x else x for x in mod_agn_cols]\n",
    "    modifiers_agnostic.columns=mod_agn_cols\n",
    "    \n",
    "    head_agn_cols=heads_agnostic.columns.tolist()\n",
    "    head_agn_cols=['count' if 'count' in x else x for x in head_agn_cols]\n",
    "    heads_agnostic.columns=head_agn_cols\n",
    "    \n",
    "    comp_agn_cols=compounds_agnostic.columns.tolist()\n",
    "    comp_agn_cols=['count' if 'count' in x else x for x in comp_agn_cols]\n",
    "    compounds_agnostic.columns=comp_agn_cols\n",
    "    \n",
    "    print('Calculating denominator values')\n",
    "\n",
    "    compound_denom=compounds.copy()\n",
    "    compound_denom['count']=compound_denom['count']**2\n",
    "    compound_denom=compound_denom.groupby(['modifier','head','time'])['count'].sum().to_frame()\n",
    "    compound_denom['count']=np.sqrt(compound_denom['count'])\n",
    "    compound_denom.columns=['compound_denom']\n",
    "    \n",
    "    compound_agnostic_denom=compounds_agnostic.copy()\n",
    "    compound_agnostic_denom['count']=compound_agnostic_denom['count']**2\n",
    "    compound_agnostic_denom=compound_agnostic_denom.groupby(['modifier','head','time'])['count'].sum().to_frame()\n",
    "    compound_agnostic_denom['count']=np.sqrt(compound_agnostic_denom['count'])\n",
    "    compound_agnostic_denom.columns=['compound_agn_denom']\n",
    "    \n",
    "\n",
    "    modifier_denom=modifiers.copy()\n",
    "    modifier_denom['count']=modifier_denom['count']**2\n",
    "    modifier_denom=modifier_denom.groupby(['modifier','time'])['count'].sum().to_frame()\n",
    "    modifier_denom['count']=np.sqrt(modifier_denom['count'])\n",
    "    modifier_denom.columns=['modifier_denom']\n",
    "    \n",
    "    modifier_agnostic_denom=modifiers_agnostic.copy()\n",
    "    modifier_agnostic_denom['count']=modifier_agnostic_denom['count']**2\n",
    "    modifier_agnostic_denom=modifier_agnostic_denom.groupby(['modifier','time'])['count'].sum().to_frame()\n",
    "    modifier_agnostic_denom['count']=np.sqrt(modifier_agnostic_denom['count'])\n",
    "    modifier_agnostic_denom.columns=['modifier_agn_denom']\n",
    "    \n",
    "    \n",
    "    head_denom=heads.copy()\n",
    "    head_denom['count']=head_denom['count']**2\n",
    "    head_denom=head_denom.groupby(['head','time'])['count'].sum().to_frame()\n",
    "    head_denom['count']=np.sqrt(head_denom['count'])\n",
    "    head_denom.columns=['head_denom']\n",
    "    \n",
    "    head_agnostic_denom=heads_agnostic.copy()\n",
    "    head_agnostic_denom['count']=head_agnostic_denom['count']**2\n",
    "    head_agnostic_denom=head_agnostic_denom.groupby(['head','time'])['count'].sum().to_frame()\n",
    "    head_agnostic_denom['count']=np.sqrt(head_agnostic_denom['count'])\n",
    "    head_agnostic_denom.columns=['head_agn_denom'] \n",
    "    \n",
    "    \n",
    "    mod_cols=modifiers.columns.tolist()\n",
    "    mod_cols=['mod_count' if 'count' in x else x for x in mod_cols]\n",
    "    modifiers.columns=mod_cols\n",
    "\n",
    "    head_cols=heads.columns.tolist()\n",
    "    head_cols=['head_count' if 'count' in x else x for x in head_cols]\n",
    "    heads.columns=head_cols\n",
    "\n",
    "    comp_cols=compounds.columns.tolist()\n",
    "    comp_cols=['comp_count' if 'count' in x else x for x in comp_cols]\n",
    "    compounds.columns=comp_cols\n",
    "\n",
    "    \n",
    "    mod_agn_cols=modifiers_agnostic.columns.tolist()\n",
    "    mod_agn_cols=['mod_agn_count' if 'count' in x else x for x in mod_agn_cols]\n",
    "    modifiers_agnostic.columns=mod_agn_cols\n",
    "    \n",
    "    head_agn_cols=heads_agnostic.columns.tolist()\n",
    "    head_agn_cols=['head_agn_count' if 'count' in x else x for x in head_agn_cols]\n",
    "    heads_agnostic.columns=head_agn_cols\n",
    "    \n",
    "    comp_agn_cols=compounds_agnostic.columns.tolist()\n",
    "    comp_agn_cols=['comp_agn_count' if 'count' in x else x for x in comp_agn_cols]\n",
    "    compounds_agnostic.columns=comp_agn_cols\n",
    "\n",
    "    print('Calculating cosine features')\n",
    "\n",
    "    compound_setting_sim=pd.merge(compounds,compounds_agnostic,on=[\"modifier\",'head',\"context\",'time'])\n",
    "    compound_setting_sim['numerator']=compound_setting_sim['comp_count']*compound_setting_sim['comp_agn_count']\n",
    "    compound_setting_sim=compound_setting_sim.groupby(['modifier','head','time'])['numerator'].sum().to_frame()\n",
    "\n",
    "    compound_setting_sim=pd.merge(compound_setting_sim.reset_index(),compound_denom.reset_index(),on=[\"modifier\",\"head\",'time'])\n",
    "    compound_setting_sim=pd.merge(compound_setting_sim,compound_agnostic_denom.reset_index(),on=[\"modifier\",\"head\",'time'])\n",
    "\n",
    "    compound_setting_sim['sim_bw_settings_comp']=compound_setting_sim['numerator']/(compound_setting_sim['compound_denom']*compound_setting_sim['compound_agn_denom'])\n",
    "    \n",
    "    compound_setting_sim=pd.merge(compound_setting_sim,compound_list_df,on=[\"modifier\",'head','time'],how='outer')\n",
    "\n",
    "    compound_setting_sim.set_index(['modifier','head','time'],inplace=True)\n",
    "    compound_setting_sim.drop(['numerator','compound_denom','compound_agn_denom'],axis=1,inplace=True)\n",
    "\n",
    "    head_setting_sim=pd.merge(heads,heads_agnostic,on=['head',\"context\",'time'])\n",
    "    head_setting_sim['numerator']=head_setting_sim['head_count']*head_setting_sim['head_agn_count']\n",
    "    head_setting_sim=head_setting_sim.groupby(['head','time'])['numerator'].sum().to_frame()\n",
    "\n",
    "    head_setting_sim=pd.merge(head_setting_sim.reset_index(),head_denom.reset_index(),on=[\"head\",'time'])\n",
    "    head_setting_sim=pd.merge(head_setting_sim,head_agnostic_denom.reset_index(),on=[\"head\",'time'])\n",
    "\n",
    "    head_setting_sim['sim_bw_settings_head']=head_setting_sim['numerator']/(head_setting_sim['head_denom']*head_setting_sim['head_agn_denom'])\n",
    "    head_setting_sim.set_index(['head','time'],inplace=True)\n",
    "    head_setting_sim.drop(['numerator','head_denom','head_agn_denom'],axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    compound_setting_sim=pd.merge(compound_setting_sim.reset_index(),head_setting_sim.reset_index(),on=[\"head\",'time'])\n",
    "\n",
    "\n",
    "    modifier_setting_sim=pd.merge(modifiers,modifiers_agnostic,on=['modifier',\"context\",'time'])\n",
    "    modifier_setting_sim['numerator']=modifier_setting_sim['mod_count']*modifier_setting_sim['mod_agn_count']\n",
    "    modifier_setting_sim=modifier_setting_sim.groupby(['modifier','time'])['numerator'].sum().to_frame()\n",
    "\n",
    "    modifier_setting_sim=pd.merge(modifier_setting_sim.reset_index(),modifier_denom.reset_index(),on=[\"modifier\",'time'])\n",
    "    modifier_setting_sim=pd.merge(modifier_setting_sim,modifier_agnostic_denom.reset_index(),on=[\"modifier\",'time'])\n",
    "\n",
    "    modifier_setting_sim['sim_bw_settings_modifier']=modifier_setting_sim['numerator']/(modifier_setting_sim['modifier_denom']*modifier_setting_sim['modifier_agn_denom'])\n",
    "    modifier_setting_sim.set_index(['modifier','time'],inplace=True)\n",
    "    modifier_setting_sim.drop(['numerator','modifier_denom','modifier_agn_denom'],axis=1,inplace=True)\n",
    "\n",
    "    compound_setting_sim=pd.merge(compound_setting_sim,modifier_setting_sim.reset_index(),on=[\"modifier\",'time'])\n",
    "    \n",
    "    return compound_setting_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_comp_ratings(features_df):\n",
    "\n",
    "    features_df=pd.pivot_table(features_df, index=['modifier','head'], columns=['time'])\n",
    "    features_df_columns_1=features_df.columns.get_level_values(0)\n",
    "    features_df_columns_2=features_df.columns.get_level_values(1)\n",
    "\n",
    "    cur_year=0\n",
    "    new_columns=[]\n",
    "    for year in features_df_columns_2:\n",
    "        new_columns.append(features_df_columns_1[cur_year]+\":\"+str(year))\n",
    "        cur_year+=1\n",
    "\n",
    "    features_df.columns=new_columns\n",
    "    cur_ratings_df_na=features_df.reset_index().merge(comp_ratings_df,on=['modifier','head'])\n",
    "\n",
    "\n",
    "    imputer= SimpleImputer(strategy=\"median\")\n",
    "    df_med=pd.DataFrame(imputer.fit_transform(features_df))\n",
    "    df_med.columns=features_df.columns\n",
    "    df_med.index=features_df.index\n",
    "\n",
    "    cur_ratings_df_med=df_med.reset_index().merge(comp_ratings_df,on=['modifier','head'])\n",
    "    \n",
    "    return cur_ratings_df_na,cur_ratings_df_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_extractor_dec(dec_list):\n",
    "    \n",
    "    print(f'Current dec list {dec_list}')\n",
    "    \n",
    "    compounds_agnostic=process_decades_compound(dec_list,f'{args.inputdir}',ctype=\"phrase\")\n",
    "\n",
    "    constituents=process_decades_constituent(dec_list,f'{args.inputdir}',ctype='word')\n",
    "    \n",
    "    \n",
    "    compounds_aware=process_decades_compound(dec_list,f'{args.inputdir}',ctype=\"compound\")\n",
    "\n",
    "    modifiers_aware=process_decades_constituent(dec_list,f'{args.inputdir}',ctype='modifier')\n",
    "\n",
    "    heads_aware=process_decades_constituent(dec_list,f'{args.inputdir}',ctype='head')\n",
    "    \n",
    "    \n",
    "    if args.cutoff==0:\n",
    "        print('No cut-off applied')          \n",
    "    else:\n",
    "        print(f'Cut-off: {args.cutoff}')\n",
    "        print(compounds_aware)\n",
    "\n",
    "        compounds_aware=process_cutoff_compound(compounds_aware)\n",
    "        \n",
    "        print(compounds_aware)\n",
    "\n",
    "        print(compounds_agnostic)\n",
    "\n",
    "        compounds_agnostic=process_cutoff_compound(compounds_agnostic)\n",
    "        \n",
    "        print(compounds_agnostic)\n",
    "\n",
    "        \n",
    "        constituents=process_cutoff_constituent(constituents,ctype='word')\n",
    "        modifiers_aware=process_cutoff_constituent(modifiers_aware,ctype='modifier')\n",
    "        heads_aware=process_cutoff_constituent(heads_aware,ctype='head')\n",
    "\n",
    "    if args.ppmi:\n",
    "        print('Applying PPMI')\n",
    "        compounds_aware=ppmi(compounds_aware)\n",
    "        modifiers_aware=ppmi(modifiers_aware)\n",
    "        heads_aware=ppmi(heads_aware)\n",
    "                        \n",
    "        compounds_agnostic=ppmi(compounds_agnostic)\n",
    "        constituents=ppmi(constituents)\n",
    "    print(compounds_aware)\n",
    "    timespan_list_aware_df=pd.DataFrame(compounds_aware.time.unique())\n",
    "    timespan_list_aware_df.columns=['time']\n",
    "\n",
    "    compound_list_aware_df=comp_ratings_df[['modifier','head']].copy()\n",
    "    compound_list_aware_df=compound_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "\n",
    "    modifier_list_aware_df=comp_ratings_df[['modifier']].drop_duplicates().copy()\n",
    "    modifier_list_aware_df=modifier_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "\n",
    "    head_list_aware_df=comp_ratings_df[['head']].drop_duplicates().copy()\n",
    "    head_list_aware_df=head_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "            \n",
    "    all_comps_aware=compounds_aware[['modifier','head','time']].copy()\n",
    "    all_comps_aware.drop_duplicates(inplace=True)\n",
    "           \n",
    "    all_mods_aware=compounds_aware[['modifier','time']].copy()\n",
    "    all_mods_aware.drop_duplicates(inplace=True)\n",
    "            \n",
    "    all_heads_aware=compounds_aware[['head','time']].copy()\n",
    "    all_heads_aware.drop_duplicates(inplace=True)\n",
    "            \n",
    "    not_found_compounds_aware_df=compound_list_aware_df.merge(all_comps_aware, on=['modifier','head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_compounds_aware_df=not_found_compounds_aware_df.loc[not_found_compounds_aware_df['_merge']=='left_only']\n",
    "    not_found_compounds_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "            \n",
    "    not_found_modifiers_aware_df=modifier_list_aware_df.merge(all_mods_aware, on=['modifier','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_modifiers_aware_df=not_found_modifiers_aware_df.loc[not_found_modifiers_aware_df['_merge']=='left_only']\n",
    "    not_found_modifiers_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "    not_found_heads_aware_df=head_list_aware_df.merge(all_heads_aware, on=['head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_heads_aware_df=not_found_heads_aware_df.loc[not_found_heads_aware_df['_merge']=='left_only']\n",
    "    not_found_heads_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    timespan_list_agnostic_df=pd.DataFrame(compounds_agnostic.time.unique())\n",
    "    timespan_list_agnostic_df.columns=['time']\n",
    "\n",
    "    compound_list_agnostic_df=comp_ratings_df[['modifier','head']].copy()\n",
    "    compound_list_agnostic_df=compound_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "\n",
    "    modifier_list_agnostic_df=comp_ratings_df[['modifier']].drop_duplicates().copy()\n",
    "    modifier_list_agnostic_df=modifier_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "\n",
    "    head_list_agnostic_df=comp_ratings_df[['head']].drop_duplicates().copy()\n",
    "    head_list_agnostic_df=head_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "            \n",
    "    all_comps_agnostic=compounds_agnostic[['modifier','head','time']].copy()\n",
    "    all_comps_agnostic.drop_duplicates(inplace=True)\n",
    "           \n",
    "    all_mods_agnostic=compounds_agnostic[['modifier','time']].copy()\n",
    "    all_mods_agnostic.drop_duplicates(inplace=True)\n",
    "            \n",
    "    all_heads_agnostic=compounds_agnostic[['head','time']].copy()\n",
    "    all_heads_agnostic.drop_duplicates(inplace=True)\n",
    "            \n",
    "    not_found_compounds_agnostic_df=compound_list_agnostic_df.merge(all_comps_agnostic, on=['modifier','head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_compounds_agnostic_df=not_found_compounds_agnostic_df.loc[not_found_compounds_agnostic_df['_merge']=='left_only']\n",
    "    not_found_compounds_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "                    \n",
    "    not_found_modifiers_agnostic_df=modifier_list_agnostic_df.merge(all_mods_agnostic, on=['modifier','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_modifiers_agnostic_df=not_found_modifiers_agnostic_df.loc[not_found_modifiers_agnostic_df['_merge']=='left_only']\n",
    "    not_found_modifiers_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "    not_found_heads_agnostic_df=head_list_agnostic_df.merge(all_heads_agnostic, on=['head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_heads_agnostic_df=not_found_heads_agnostic_df.loc[not_found_heads_agnostic_df['_merge']=='left_only']\n",
    "    not_found_heads_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    heads_agnostic=constituents.copy()\n",
    "    heads_agnostic_cols=heads_agnostic.columns\n",
    "    heads_agnostic_cols=['head' if 'word' in x else x for x in heads_agnostic_cols]\n",
    "    heads_agnostic.columns=heads_agnostic_cols\n",
    "\n",
    "    modifiers_agnostic=constituents.copy()\n",
    "    modifiers_agnostic_cols=modifiers_agnostic.columns\n",
    "    modifiers_agnostic_cols=['modifier' if 'word' in x else x for x in modifiers_agnostic_cols]\n",
    "    modifiers_agnostic.columns=modifiers_agnostic_cols\n",
    "\n",
    "    \n",
    "    print('Calculating features')\n",
    "    \n",
    "    unique_mod_list=comp_ratings_df[['modifier']].drop_duplicates()['modifier'].to_list()\n",
    "    unique_head_list=comp_ratings_df[['head']].drop_duplicates()['head'].to_list() \n",
    "    \n",
    "    print('CompoundAware features')\n",
    "    \n",
    "    \n",
    "    compound_features_aware=calculate_compound_features(compounds_aware,modifiers_aware,heads_aware,all_comps_aware,not_found_compounds_aware_df,not_found_modifiers_aware_df,not_found_heads_aware_df)\n",
    "    compound_features_aware=compound_features_aware.loc[(compound_features_aware.modifier.isin(unique_mod_list))&(compound_features_aware['head'].isin(unique_head_list))]\n",
    "    \n",
    "    reduced_compounds_aware=compounds_aware.loc[(compounds_aware.modifier.isin(unique_mod_list))&(compounds_aware['head'].isin(unique_head_list))]\n",
    "    reduced_modifiers_aware=modifiers_aware.loc[modifiers_aware.modifier.isin(unique_mod_list)]\n",
    "    reduced_heads_aware=heads_aware.loc[heads_aware['head'].isin(unique_head_list)]\n",
    "    \n",
    "    cosine_sim_feat_aware=calculate_cosine_features(reduced_compounds_aware,reduced_modifiers_aware,reduced_heads_aware,not_found_compounds_aware_df)\n",
    "  \n",
    "    \n",
    "    print('CompoundAgnostic features')\n",
    "\n",
    "    compound_features_agnostic=calculate_compound_features(compounds_agnostic,modifiers_agnostic,heads_agnostic,all_comps_agnostic,not_found_compounds_agnostic_df,not_found_modifiers_agnostic_df,not_found_heads_agnostic_df)\n",
    "    compound_features_agnostic=compound_features_agnostic.loc[(compound_features_agnostic.modifier.isin(unique_mod_list))&(compound_features_agnostic['head'].isin(unique_head_list))]\n",
    "\n",
    "    \n",
    "    reduced_compounds_agnostic=compounds_agnostic.loc[(compounds_agnostic.modifier.isin(unique_mod_list))&(compounds_agnostic['head'].isin(unique_head_list))]\n",
    "    reduced_modifiers_agnostic=modifiers_agnostic.loc[modifiers_agnostic.modifier.isin(unique_mod_list)]\n",
    "    reduced_heads_agnostic=heads_agnostic.loc[heads_agnostic['head'].isin(unique_head_list)]\n",
    "    \n",
    "    cosine_sim_feat_agnostic=calculate_cosine_features(reduced_compounds_agnostic,reduced_modifiers_agnostic,reduced_heads_agnostic,not_found_compounds_agnostic_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Combined cosine features')\n",
    "    compound_setting_sim=calculate_setting_similarity(reduced_compounds_aware,reduced_modifiers_aware,reduced_heads_aware,reduced_compounds_agnostic,reduced_modifiers_agnostic,reduced_heads_agnostic,compound_list_agnostic_df)\n",
    "    \n",
    "\n",
    "    print('Combining all compound aware features')\n",
    "    \n",
    "    features_aware_df=pd.merge(cosine_sim_feat_aware,compound_setting_sim,on=['modifier','head','time'],how='outer')\n",
    "    features_aware_df=features_aware_df.merge(compound_features_aware,on=['modifier','head','time'],how='left')\n",
    "\n",
    "    \n",
    "    print('Combining all compound agnostic features')\n",
    "    \n",
    "    features_agnostic_df=pd.merge(cosine_sim_feat_agnostic,compound_setting_sim,on=['modifier','head','time'],how='outer')\n",
    "    features_agnostic_df=features_agnostic_df.merge(compound_features_agnostic,on=['modifier','head','time'],how='left')   \n",
    "    \n",
    "    return features_aware_df,features_agnostic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_dec_list=[[1820,1830,1840,1850,1860,1870,1880,1890],[1900,1910,1920,1930,1940,1950,1960,1970,1980,1990],[2000,2010]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100_0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.temporal!=10000:\n",
    "    total_dec_list=[[1820,1830,1840,1850,1860,1870,1880,1890],[1900,1910,1920,1930,1940,1950,1960,1970,1980,1990],[2000,2010]]\n",
    "    \n",
    "else:\n",
    "    total_dec_list=[[1820,1830,1840,1850,1860,1870,1880,1890,1900,1910,1920,1930,1940,1950,1960,1970,1980,1990,2000,2010]]\n",
    "    \n",
    "    \n",
    "if args.ppmi:\n",
    "    ppmi_str=\"PPMI\"\n",
    "else:\n",
    "    ppmi_str=\"RAW\"\n",
    "    \n",
    "if args.tag:\n",
    "    tag_str='Tagged'\n",
    "else:\n",
    "    tag_str='UnTagged'\n",
    "    \n",
    "temp_cutoff_str=str(args.temporal)+'_'+str(args.cutoff)\n",
    "temp_cutoff_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_list=total_dec_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n"
     ]
    }
   ],
   "source": [
    "    compounds_agnostic=process_decades_compound(dec_list,f'{args.inputdir}',ctype=\"phrase\")\n",
    "\n",
    "    constituents=process_decades_constituent(dec_list,f'{args.inputdir}',ctype='word')\n",
    "    \n",
    "    \n",
    "    compounds_aware=process_decades_compound(dec_list,f'{args.inputdir}',ctype=\"compound\")\n",
    "\n",
    "    modifiers_aware=process_decades_constituent(dec_list,f'{args.inputdir}',ctype='modifier')\n",
    "\n",
    "    heads_aware=process_decades_constituent(dec_list,f'{args.inputdir}',ctype='head')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    timespan_list_aware_df=pd.DataFrame(compounds_aware.time.unique())\n",
    "    timespan_list_aware_df.columns=['time']\n",
    "\n",
    "    compound_list_aware_df=comp_ratings_df[['modifier','head']].copy()\n",
    "    compound_list_aware_df=compound_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "\n",
    "    modifier_list_aware_df=comp_ratings_df[['modifier']].drop_duplicates().copy()\n",
    "    modifier_list_aware_df=modifier_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "\n",
    "    head_list_aware_df=comp_ratings_df[['head']].drop_duplicates().copy()\n",
    "    head_list_aware_df=head_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "            \n",
    "    all_comps_aware=compounds_aware[['modifier','head','time']].copy()\n",
    "    all_comps_aware.drop_duplicates(inplace=True)\n",
    "           \n",
    "    all_mods_aware=compounds_aware[['modifier','time']].copy()\n",
    "    all_mods_aware.drop_duplicates(inplace=True)\n",
    "            \n",
    "    all_heads_aware=compounds_aware[['head','time']].copy()\n",
    "    all_heads_aware.drop_duplicates(inplace=True)\n",
    "            \n",
    "    not_found_compounds_aware_df=compound_list_aware_df.merge(all_comps_aware, on=['modifier','head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_compounds_aware_df=not_found_compounds_aware_df.loc[not_found_compounds_aware_df['_merge']=='left_only']\n",
    "    not_found_compounds_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "            \n",
    "    not_found_modifiers_aware_df=modifier_list_aware_df.merge(all_mods_aware, on=['modifier','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_modifiers_aware_df=not_found_modifiers_aware_df.loc[not_found_modifiers_aware_df['_merge']=='left_only']\n",
    "    not_found_modifiers_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "    not_found_heads_aware_df=head_list_aware_df.merge(all_heads_aware, on=['head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_heads_aware_df=not_found_heads_aware_df.loc[not_found_heads_aware_df['_merge']=='left_only']\n",
    "    not_found_heads_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    timespan_list_agnostic_df=pd.DataFrame(compounds_agnostic.time.unique())\n",
    "    timespan_list_agnostic_df.columns=['time']\n",
    "\n",
    "    compound_list_agnostic_df=comp_ratings_df[['modifier','head']].copy()\n",
    "    compound_list_agnostic_df=compound_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "\n",
    "    modifier_list_agnostic_df=comp_ratings_df[['modifier']].drop_duplicates().copy()\n",
    "    modifier_list_agnostic_df=modifier_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "\n",
    "    head_list_agnostic_df=comp_ratings_df[['head']].drop_duplicates().copy()\n",
    "    head_list_agnostic_df=head_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "            \n",
    "    all_comps_agnostic=compounds_agnostic[['modifier','head','time']].copy()\n",
    "    all_comps_agnostic.drop_duplicates(inplace=True)\n",
    "           \n",
    "    all_mods_agnostic=compounds_agnostic[['modifier','time']].copy()\n",
    "    all_mods_agnostic.drop_duplicates(inplace=True)\n",
    "            \n",
    "    all_heads_agnostic=compounds_agnostic[['head','time']].copy()\n",
    "    all_heads_agnostic.drop_duplicates(inplace=True)\n",
    "            \n",
    "    not_found_compounds_agnostic_df=compound_list_agnostic_df.merge(all_comps_agnostic, on=['modifier','head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_compounds_agnostic_df=not_found_compounds_agnostic_df.loc[not_found_compounds_agnostic_df['_merge']=='left_only']\n",
    "    not_found_compounds_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "                    \n",
    "    not_found_modifiers_agnostic_df=modifier_list_agnostic_df.merge(all_mods_agnostic, on=['modifier','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_modifiers_agnostic_df=not_found_modifiers_agnostic_df.loc[not_found_modifiers_agnostic_df['_merge']=='left_only']\n",
    "    not_found_modifiers_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "    not_found_heads_agnostic_df=head_list_agnostic_df.merge(all_heads_agnostic, on=['head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_heads_agnostic_df=not_found_heads_agnostic_df.loc[not_found_heads_agnostic_df['_merge']=='left_only']\n",
    "    not_found_heads_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    heads_agnostic=constituents.copy()\n",
    "    heads_agnostic_cols=heads_agnostic.columns\n",
    "    heads_agnostic_cols=['head' if 'word' in x else x for x in heads_agnostic_cols]\n",
    "    heads_agnostic.columns=heads_agnostic_cols\n",
    "\n",
    "    modifiers_agnostic=constituents.copy()\n",
    "    modifiers_agnostic_cols=modifiers_agnostic.columns\n",
    "    modifiers_agnostic_cols=['modifier' if 'word' in x else x for x in modifiers_agnostic_cols]\n",
    "    modifiers_agnostic.columns=modifiers_agnostic_cols\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating productivity features\n",
      "Calculating information theory features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "compound_features_aware=calculate_compound_features(compounds_aware,modifiers_aware,heads_aware,all_comps_aware,not_found_compounds_aware_df,not_found_modifiers_aware_df,not_found_heads_aware_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    unique_mod_list=comp_ratings_df[['modifier']].drop_duplicates()['modifier'].to_list()\n",
    "    unique_head_list=comp_ratings_df[['head']].drop_duplicates()['head'].to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    " compound_features_aware=compound_features_aware.loc[(compound_features_aware.modifier.isin(unique_mod_list))&(compound_features_aware['head'].isin(unique_head_list))]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['head_prod', 'comp_size', 'head_family_size', 'head_family_size_new',\n",
       "       'mod_prod', 'mod_family_size', 'mod_family_size_new', 'log_ratio',\n",
       "       'ppmi', 'local_mi', 'comp_freq', 'mod_freq', 'head_freq', 'comp_tf',\n",
       "       'log_comp_freq', 'mod_tf', 'log_mod_freq', 'log_mod_freq_new',\n",
       "       'head_tf', 'log_head_freq', 'log_head_freq_new'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_features_aware.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>head_prod</th>\n",
       "      <th>comp_size</th>\n",
       "      <th>head_family_size</th>\n",
       "      <th>head_family_size_new</th>\n",
       "      <th>mod_prod</th>\n",
       "      <th>mod_family_size</th>\n",
       "      <th>mod_family_size_new</th>\n",
       "      <th>log_ratio</th>\n",
       "      <th>ppmi</th>\n",
       "      <th>local_mi</th>\n",
       "      <th>...</th>\n",
       "      <th>mod_freq</th>\n",
       "      <th>head_freq</th>\n",
       "      <th>comp_tf</th>\n",
       "      <th>log_comp_freq</th>\n",
       "      <th>mod_tf</th>\n",
       "      <th>log_mod_freq</th>\n",
       "      <th>log_mod_freq_new</th>\n",
       "      <th>head_tf</th>\n",
       "      <th>log_head_freq</th>\n",
       "      <th>log_head_freq_new</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acid</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>15221</td>\n",
       "      <td>-12.188375</td>\n",
       "      <td>-10.320300</td>\n",
       "      <td>3.404699e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-743.059733</td>\n",
       "      <td>...</td>\n",
       "      <td>3582356</td>\n",
       "      <td>18262113</td>\n",
       "      <td>7.066089</td>\n",
       "      <td>-26.197347</td>\n",
       "      <td>21.772478</td>\n",
       "      <td>-11.480153</td>\n",
       "      <td>-12.762677</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ancient</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>123489</td>\n",
       "      <td>-9.168127</td>\n",
       "      <td>-7.300052</td>\n",
       "      <td>1.003015e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15839.005657</td>\n",
       "      <td>...</td>\n",
       "      <td>16738074</td>\n",
       "      <td>18262113</td>\n",
       "      <td>13.363450</td>\n",
       "      <td>-19.889316</td>\n",
       "      <td>23.996630</td>\n",
       "      <td>-9.256000</td>\n",
       "      <td>-10.538524</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>2810</td>\n",
       "      <td>-14.625796</td>\n",
       "      <td>-12.757721</td>\n",
       "      <td>1.770471e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-46.888012</td>\n",
       "      <td>...</td>\n",
       "      <td>186651</td>\n",
       "      <td>18262113</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>-30.082705</td>\n",
       "      <td>17.509991</td>\n",
       "      <td>-15.742646</td>\n",
       "      <td>-17.025171</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>90367</td>\n",
       "      <td>-9.618642</td>\n",
       "      <td>-7.750567</td>\n",
       "      <td>2.165728e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5542.970481</td>\n",
       "      <td>...</td>\n",
       "      <td>13651743</td>\n",
       "      <td>18262113</td>\n",
       "      <td>14.296988</td>\n",
       "      <td>-18.955714</td>\n",
       "      <td>23.702582</td>\n",
       "      <td>-9.550048</td>\n",
       "      <td>-10.832573</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>3245</td>\n",
       "      <td>-14.418148</td>\n",
       "      <td>-12.550072</td>\n",
       "      <td>-1.893634e+03</td>\n",
       "      <td>0.046969</td>\n",
       "      <td>53.450154</td>\n",
       "      <td>...</td>\n",
       "      <td>617293</td>\n",
       "      <td>18262113</td>\n",
       "      <td>10.153552</td>\n",
       "      <td>-23.100345</td>\n",
       "      <td>19.235598</td>\n",
       "      <td>-14.017034</td>\n",
       "      <td>-15.299559</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wet</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>16202</td>\n",
       "      <td>-12.098266</td>\n",
       "      <td>-10.230191</td>\n",
       "      <td>4.566636e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9016.666080</td>\n",
       "      <td>...</td>\n",
       "      <td>1577377</td>\n",
       "      <td>111374229</td>\n",
       "      <td>12.822969</td>\n",
       "      <td>-20.429860</td>\n",
       "      <td>20.589097</td>\n",
       "      <td>-12.663534</td>\n",
       "      <td>-13.946058</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>158452</td>\n",
       "      <td>-8.808464</td>\n",
       "      <td>-6.940389</td>\n",
       "      <td>1.175903e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5183.388470</td>\n",
       "      <td>...</td>\n",
       "      <td>23313086</td>\n",
       "      <td>111374229</td>\n",
       "      <td>9.214319</td>\n",
       "      <td>-24.040742</td>\n",
       "      <td>24.474637</td>\n",
       "      <td>-8.777993</td>\n",
       "      <td>-10.060518</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winter</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>27470</td>\n",
       "      <td>-11.336581</td>\n",
       "      <td>-9.468506</td>\n",
       "      <td>1.776914e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-587.996974</td>\n",
       "      <td>...</td>\n",
       "      <td>3428729</td>\n",
       "      <td>111374229</td>\n",
       "      <td>6.022368</td>\n",
       "      <td>-27.252630</td>\n",
       "      <td>21.709243</td>\n",
       "      <td>-11.543387</td>\n",
       "      <td>-12.825912</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>25870</td>\n",
       "      <td>-11.423158</td>\n",
       "      <td>-9.555083</td>\n",
       "      <td>7.753508e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2220.402761</td>\n",
       "      <td>...</td>\n",
       "      <td>1535631</td>\n",
       "      <td>111374229</td>\n",
       "      <td>8.707359</td>\n",
       "      <td>-24.548726</td>\n",
       "      <td>20.550401</td>\n",
       "      <td>-12.702230</td>\n",
       "      <td>-13.984754</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>17418</td>\n",
       "      <td>-11.993859</td>\n",
       "      <td>-10.125784</td>\n",
       "      <td>3.363154e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2441.850126</td>\n",
       "      <td>...</td>\n",
       "      <td>718952</td>\n",
       "      <td>111374229</td>\n",
       "      <td>9.457381</td>\n",
       "      <td>-23.797303</td>\n",
       "      <td>19.455538</td>\n",
       "      <td>-13.797094</td>\n",
       "      <td>-15.079619</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14748 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          head_prod  comp_size  head_family_size  \\\n",
       "modifier    head    time                                           \n",
       "acid        account 1800      86961   71041092         -9.674070   \n",
       "ancient     account 1800      86961   71041092         -9.674070   \n",
       "application account 1800      86961   71041092         -9.674070   \n",
       "bad         account 1800      86961   71041092         -9.674070   \n",
       "balance     account 1800      86961   71041092         -9.674070   \n",
       "...                             ...        ...               ...   \n",
       "wet         year    1800     180610   71041092         -8.619632   \n",
       "white       year    1800     180610   71041092         -8.619632   \n",
       "winter      year    1800     180610   71041092         -8.619632   \n",
       "word        year    1800     180610   71041092         -8.619632   \n",
       "world       year    1800     180610   71041092         -8.619632   \n",
       "\n",
       "                          head_family_size_new  mod_prod  mod_family_size  \\\n",
       "modifier    head    time                                                    \n",
       "acid        account 1800             -7.881875     15221       -12.188375   \n",
       "ancient     account 1800             -7.881875    123489        -9.168127   \n",
       "application account 1800             -7.881875      2810       -14.625796   \n",
       "bad         account 1800             -7.881875     90367        -9.618642   \n",
       "balance     account 1800             -7.881875      3245       -14.418148   \n",
       "...                                        ...       ...              ...   \n",
       "wet         year    1800             -6.827438     16202       -12.098266   \n",
       "white       year    1800             -6.827438    158452        -8.808464   \n",
       "winter      year    1800             -6.827438     27470       -11.336581   \n",
       "word        year    1800             -6.827438     25870       -11.423158   \n",
       "world       year    1800             -6.827438     17418       -11.993859   \n",
       "\n",
       "                          mod_family_size_new     log_ratio      ppmi  \\\n",
       "modifier    head    time                                                \n",
       "acid        account 1800           -10.320300  3.404699e+05  0.000000   \n",
       "ancient     account 1800            -7.300052  1.003015e+06  0.000000   \n",
       "application account 1800           -12.757721  1.770471e+04  0.000000   \n",
       "bad         account 1800            -7.750567  2.165728e+05  0.000000   \n",
       "balance     account 1800           -12.550072 -1.893634e+03  0.046969   \n",
       "...                                       ...           ...       ...   \n",
       "wet         year    1800           -10.230191  4.566636e+05  0.000000   \n",
       "white       year    1800            -6.940389  1.175903e+07  0.000000   \n",
       "winter      year    1800            -9.468506  1.776914e+06  0.000000   \n",
       "word        year    1800            -9.555083  7.753508e+05  0.000000   \n",
       "world       year    1800           -10.125784  3.363154e+05  0.000000   \n",
       "\n",
       "                              local_mi  ...  mod_freq  head_freq    comp_tf  \\\n",
       "modifier    head    time                ...                                   \n",
       "acid        account 1800   -743.059733  ...   3582356   18262113   7.066089   \n",
       "ancient     account 1800 -15839.005657  ...  16738074   18262113  13.363450   \n",
       "application account 1800    -46.888012  ...    186651   18262113   3.321928   \n",
       "bad         account 1800  -5542.970481  ...  13651743   18262113  14.296988   \n",
       "balance     account 1800     53.450154  ...    617293   18262113  10.153552   \n",
       "...                                ...  ...       ...        ...        ...   \n",
       "wet         year    1800  -9016.666080  ...   1577377  111374229  12.822969   \n",
       "white       year    1800  -5183.388470  ...  23313086  111374229   9.214319   \n",
       "winter      year    1800   -587.996974  ...   3428729  111374229   6.022368   \n",
       "word        year    1800  -2220.402761  ...   1535631  111374229   8.707359   \n",
       "world       year    1800  -2441.850126  ...    718952  111374229   9.457381   \n",
       "\n",
       "                          log_comp_freq     mod_tf  log_mod_freq  \\\n",
       "modifier    head    time                                           \n",
       "acid        account 1800     -26.197347  21.772478    -11.480153   \n",
       "ancient     account 1800     -19.889316  23.996630     -9.256000   \n",
       "application account 1800     -30.082705  17.509991    -15.742646   \n",
       "bad         account 1800     -18.955714  23.702582     -9.550048   \n",
       "balance     account 1800     -23.100345  19.235598    -14.017034   \n",
       "...                                 ...        ...           ...   \n",
       "wet         year    1800     -20.429860  20.589097    -12.663534   \n",
       "white       year    1800     -24.040742  24.474637     -8.777993   \n",
       "winter      year    1800     -27.252630  21.709243    -11.543387   \n",
       "word        year    1800     -24.548726  20.550401    -12.702230   \n",
       "world       year    1800     -23.797303  19.455538    -13.797094   \n",
       "\n",
       "                          log_mod_freq_new   head_tf  log_head_freq  \\\n",
       "modifier    head    time                                              \n",
       "acid        account 1800        -12.762677  24.12235       -9.13028   \n",
       "ancient     account 1800        -10.538524  24.12235       -9.13028   \n",
       "application account 1800        -17.025171  24.12235       -9.13028   \n",
       "bad         account 1800        -10.832573  24.12235       -9.13028   \n",
       "balance     account 1800        -15.299559  24.12235       -9.13028   \n",
       "...                                    ...       ...            ...   \n",
       "wet         year    1800        -13.946058  26.73084       -6.52179   \n",
       "white       year    1800        -10.060518  26.73084       -6.52179   \n",
       "winter      year    1800        -12.825912  26.73084       -6.52179   \n",
       "word        year    1800        -13.984754  26.73084       -6.52179   \n",
       "world       year    1800        -15.079619  26.73084       -6.52179   \n",
       "\n",
       "                          log_head_freq_new  \n",
       "modifier    head    time                     \n",
       "acid        account 1800           -9.13028  \n",
       "ancient     account 1800           -9.13028  \n",
       "application account 1800           -9.13028  \n",
       "bad         account 1800           -9.13028  \n",
       "balance     account 1800           -9.13028  \n",
       "...                                     ...  \n",
       "wet         year    1800           -6.52179  \n",
       "white       year    1800           -6.52179  \n",
       "winter      year    1800           -6.52179  \n",
       "word        year    1800           -6.52179  \n",
       "world       year    1800           -6.52179  \n",
       "\n",
       "[14748 rows x 21 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_features_aware.set_index(['modifier','head','time'],inplace=True)\n",
    "compound_features_aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>head_prod</th>\n",
       "      <th>comp_size</th>\n",
       "      <th>head_family_size</th>\n",
       "      <th>head_family_size_new</th>\n",
       "      <th>mod_prod</th>\n",
       "      <th>mod_family_size</th>\n",
       "      <th>mod_family_size_new</th>\n",
       "      <th>log_ratio</th>\n",
       "      <th>ppmi</th>\n",
       "      <th>local_mi</th>\n",
       "      <th>...</th>\n",
       "      <th>mod_freq</th>\n",
       "      <th>head_freq</th>\n",
       "      <th>comp_tf</th>\n",
       "      <th>log_comp_freq</th>\n",
       "      <th>mod_tf</th>\n",
       "      <th>log_mod_freq</th>\n",
       "      <th>log_mod_freq_new</th>\n",
       "      <th>head_tf</th>\n",
       "      <th>log_head_freq</th>\n",
       "      <th>log_head_freq_new</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acid</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>15221</td>\n",
       "      <td>-12.188375</td>\n",
       "      <td>-10.320300</td>\n",
       "      <td>3.404699e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-743.059733</td>\n",
       "      <td>...</td>\n",
       "      <td>3582356</td>\n",
       "      <td>18262113</td>\n",
       "      <td>7.066089</td>\n",
       "      <td>-26.197347</td>\n",
       "      <td>21.772478</td>\n",
       "      <td>-11.480153</td>\n",
       "      <td>-12.762677</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ancient</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>123489</td>\n",
       "      <td>-9.168127</td>\n",
       "      <td>-7.300052</td>\n",
       "      <td>1.003015e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15839.005657</td>\n",
       "      <td>...</td>\n",
       "      <td>16738074</td>\n",
       "      <td>18262113</td>\n",
       "      <td>13.363450</td>\n",
       "      <td>-19.889316</td>\n",
       "      <td>23.996630</td>\n",
       "      <td>-9.256000</td>\n",
       "      <td>-10.538524</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>2810</td>\n",
       "      <td>-14.625796</td>\n",
       "      <td>-12.757721</td>\n",
       "      <td>1.770471e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-46.888012</td>\n",
       "      <td>...</td>\n",
       "      <td>186651</td>\n",
       "      <td>18262113</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>-30.082705</td>\n",
       "      <td>17.509991</td>\n",
       "      <td>-15.742646</td>\n",
       "      <td>-17.025171</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>90367</td>\n",
       "      <td>-9.618642</td>\n",
       "      <td>-7.750567</td>\n",
       "      <td>2.165728e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5542.970481</td>\n",
       "      <td>...</td>\n",
       "      <td>13651743</td>\n",
       "      <td>18262113</td>\n",
       "      <td>14.296988</td>\n",
       "      <td>-18.955714</td>\n",
       "      <td>23.702582</td>\n",
       "      <td>-9.550048</td>\n",
       "      <td>-10.832573</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <th>account</th>\n",
       "      <th>1800</th>\n",
       "      <td>86961</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-9.674070</td>\n",
       "      <td>-7.881875</td>\n",
       "      <td>3245</td>\n",
       "      <td>-14.418148</td>\n",
       "      <td>-12.550072</td>\n",
       "      <td>-1.893634e+03</td>\n",
       "      <td>0.046969</td>\n",
       "      <td>53.450154</td>\n",
       "      <td>...</td>\n",
       "      <td>617293</td>\n",
       "      <td>18262113</td>\n",
       "      <td>10.153552</td>\n",
       "      <td>-23.100345</td>\n",
       "      <td>19.235598</td>\n",
       "      <td>-14.017034</td>\n",
       "      <td>-15.299559</td>\n",
       "      <td>24.12235</td>\n",
       "      <td>-9.13028</td>\n",
       "      <td>-9.13028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wet</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>16202</td>\n",
       "      <td>-12.098266</td>\n",
       "      <td>-10.230191</td>\n",
       "      <td>4.566636e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9016.666080</td>\n",
       "      <td>...</td>\n",
       "      <td>1577377</td>\n",
       "      <td>111374229</td>\n",
       "      <td>12.822969</td>\n",
       "      <td>-20.429860</td>\n",
       "      <td>20.589097</td>\n",
       "      <td>-12.663534</td>\n",
       "      <td>-13.946058</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>158452</td>\n",
       "      <td>-8.808464</td>\n",
       "      <td>-6.940389</td>\n",
       "      <td>1.175903e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5183.388470</td>\n",
       "      <td>...</td>\n",
       "      <td>23313086</td>\n",
       "      <td>111374229</td>\n",
       "      <td>9.214319</td>\n",
       "      <td>-24.040742</td>\n",
       "      <td>24.474637</td>\n",
       "      <td>-8.777993</td>\n",
       "      <td>-10.060518</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winter</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>27470</td>\n",
       "      <td>-11.336581</td>\n",
       "      <td>-9.468506</td>\n",
       "      <td>1.776914e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-587.996974</td>\n",
       "      <td>...</td>\n",
       "      <td>3428729</td>\n",
       "      <td>111374229</td>\n",
       "      <td>6.022368</td>\n",
       "      <td>-27.252630</td>\n",
       "      <td>21.709243</td>\n",
       "      <td>-11.543387</td>\n",
       "      <td>-12.825912</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>25870</td>\n",
       "      <td>-11.423158</td>\n",
       "      <td>-9.555083</td>\n",
       "      <td>7.753508e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2220.402761</td>\n",
       "      <td>...</td>\n",
       "      <td>1535631</td>\n",
       "      <td>111374229</td>\n",
       "      <td>8.707359</td>\n",
       "      <td>-24.548726</td>\n",
       "      <td>20.550401</td>\n",
       "      <td>-12.702230</td>\n",
       "      <td>-13.984754</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>1800</th>\n",
       "      <td>180610</td>\n",
       "      <td>71041092</td>\n",
       "      <td>-8.619632</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>17418</td>\n",
       "      <td>-11.993859</td>\n",
       "      <td>-10.125784</td>\n",
       "      <td>3.363154e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2441.850126</td>\n",
       "      <td>...</td>\n",
       "      <td>718952</td>\n",
       "      <td>111374229</td>\n",
       "      <td>9.457381</td>\n",
       "      <td>-23.797303</td>\n",
       "      <td>19.455538</td>\n",
       "      <td>-13.797094</td>\n",
       "      <td>-15.079619</td>\n",
       "      <td>26.73084</td>\n",
       "      <td>-6.52179</td>\n",
       "      <td>-6.52179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14748 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          head_prod  comp_size  head_family_size  \\\n",
       "modifier    head    time                                           \n",
       "acid        account 1800      86961   71041092         -9.674070   \n",
       "ancient     account 1800      86961   71041092         -9.674070   \n",
       "application account 1800      86961   71041092         -9.674070   \n",
       "bad         account 1800      86961   71041092         -9.674070   \n",
       "balance     account 1800      86961   71041092         -9.674070   \n",
       "...                             ...        ...               ...   \n",
       "wet         year    1800     180610   71041092         -8.619632   \n",
       "white       year    1800     180610   71041092         -8.619632   \n",
       "winter      year    1800     180610   71041092         -8.619632   \n",
       "word        year    1800     180610   71041092         -8.619632   \n",
       "world       year    1800     180610   71041092         -8.619632   \n",
       "\n",
       "                          head_family_size_new  mod_prod  mod_family_size  \\\n",
       "modifier    head    time                                                    \n",
       "acid        account 1800             -7.881875     15221       -12.188375   \n",
       "ancient     account 1800             -7.881875    123489        -9.168127   \n",
       "application account 1800             -7.881875      2810       -14.625796   \n",
       "bad         account 1800             -7.881875     90367        -9.618642   \n",
       "balance     account 1800             -7.881875      3245       -14.418148   \n",
       "...                                        ...       ...              ...   \n",
       "wet         year    1800             -6.827438     16202       -12.098266   \n",
       "white       year    1800             -6.827438    158452        -8.808464   \n",
       "winter      year    1800             -6.827438     27470       -11.336581   \n",
       "word        year    1800             -6.827438     25870       -11.423158   \n",
       "world       year    1800             -6.827438     17418       -11.993859   \n",
       "\n",
       "                          mod_family_size_new     log_ratio      ppmi  \\\n",
       "modifier    head    time                                                \n",
       "acid        account 1800           -10.320300  3.404699e+05  0.000000   \n",
       "ancient     account 1800            -7.300052  1.003015e+06  0.000000   \n",
       "application account 1800           -12.757721  1.770471e+04  0.000000   \n",
       "bad         account 1800            -7.750567  2.165728e+05  0.000000   \n",
       "balance     account 1800           -12.550072 -1.893634e+03  0.046969   \n",
       "...                                       ...           ...       ...   \n",
       "wet         year    1800           -10.230191  4.566636e+05  0.000000   \n",
       "white       year    1800            -6.940389  1.175903e+07  0.000000   \n",
       "winter      year    1800            -9.468506  1.776914e+06  0.000000   \n",
       "word        year    1800            -9.555083  7.753508e+05  0.000000   \n",
       "world       year    1800           -10.125784  3.363154e+05  0.000000   \n",
       "\n",
       "                              local_mi  ...  mod_freq  head_freq    comp_tf  \\\n",
       "modifier    head    time                ...                                   \n",
       "acid        account 1800   -743.059733  ...   3582356   18262113   7.066089   \n",
       "ancient     account 1800 -15839.005657  ...  16738074   18262113  13.363450   \n",
       "application account 1800    -46.888012  ...    186651   18262113   3.321928   \n",
       "bad         account 1800  -5542.970481  ...  13651743   18262113  14.296988   \n",
       "balance     account 1800     53.450154  ...    617293   18262113  10.153552   \n",
       "...                                ...  ...       ...        ...        ...   \n",
       "wet         year    1800  -9016.666080  ...   1577377  111374229  12.822969   \n",
       "white       year    1800  -5183.388470  ...  23313086  111374229   9.214319   \n",
       "winter      year    1800   -587.996974  ...   3428729  111374229   6.022368   \n",
       "word        year    1800  -2220.402761  ...   1535631  111374229   8.707359   \n",
       "world       year    1800  -2441.850126  ...    718952  111374229   9.457381   \n",
       "\n",
       "                          log_comp_freq     mod_tf  log_mod_freq  \\\n",
       "modifier    head    time                                           \n",
       "acid        account 1800     -26.197347  21.772478    -11.480153   \n",
       "ancient     account 1800     -19.889316  23.996630     -9.256000   \n",
       "application account 1800     -30.082705  17.509991    -15.742646   \n",
       "bad         account 1800     -18.955714  23.702582     -9.550048   \n",
       "balance     account 1800     -23.100345  19.235598    -14.017034   \n",
       "...                                 ...        ...           ...   \n",
       "wet         year    1800     -20.429860  20.589097    -12.663534   \n",
       "white       year    1800     -24.040742  24.474637     -8.777993   \n",
       "winter      year    1800     -27.252630  21.709243    -11.543387   \n",
       "word        year    1800     -24.548726  20.550401    -12.702230   \n",
       "world       year    1800     -23.797303  19.455538    -13.797094   \n",
       "\n",
       "                          log_mod_freq_new   head_tf  log_head_freq  \\\n",
       "modifier    head    time                                              \n",
       "acid        account 1800        -12.762677  24.12235       -9.13028   \n",
       "ancient     account 1800        -10.538524  24.12235       -9.13028   \n",
       "application account 1800        -17.025171  24.12235       -9.13028   \n",
       "bad         account 1800        -10.832573  24.12235       -9.13028   \n",
       "balance     account 1800        -15.299559  24.12235       -9.13028   \n",
       "...                                    ...       ...            ...   \n",
       "wet         year    1800        -13.946058  26.73084       -6.52179   \n",
       "white       year    1800        -10.060518  26.73084       -6.52179   \n",
       "winter      year    1800        -12.825912  26.73084       -6.52179   \n",
       "word        year    1800        -13.984754  26.73084       -6.52179   \n",
       "world       year    1800        -15.079619  26.73084       -6.52179   \n",
       "\n",
       "                          log_head_freq_new  \n",
       "modifier    head    time                     \n",
       "acid        account 1800           -9.13028  \n",
       "ancient     account 1800           -9.13028  \n",
       "application account 1800           -9.13028  \n",
       "bad         account 1800           -9.13028  \n",
       "balance     account 1800           -9.13028  \n",
       "...                                     ...  \n",
       "wet         year    1800           -6.52179  \n",
       "white       year    1800           -6.52179  \n",
       "winter      year    1800           -6.52179  \n",
       "word        year    1800           -6.52179  \n",
       "world       year    1800           -6.52179  \n",
       "\n",
       "[14748 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_features_aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cur_ratings_aware_df_na,cur_ratings_aware_df_med=merge_comp_ratings(features_aware_df)\n",
    "cur_ratings_agnostic_df_na,cur_ratings_agnostic_df_med=merge_comp_ratings(features_agnostic_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving feature datasets\n"
     ]
    }
   ],
   "source": [
    "cur_ratings_aware_df_na,cur_ratings_aware_df_med=merge_comp_ratings(features_aware_df)\n",
    "cur_ratings_agnostic_df_na,cur_ratings_agnostic_df_med=merge_comp_ratings(features_agnostic_df)\n",
    "\n",
    "print('Saving feature datasets')\n",
    "\n",
    "cur_ratings_aware_df_na.loc[:,~cur_ratings_aware_df_na.columns.str.contains('setting')].to_csv(f'{args.outputdir}/features_CompoundAware_woSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_na.csv',sep='\\t',index=False)\n",
    "cur_ratings_aware_df_med.loc[:,~cur_ratings_aware_df_med.columns.str.contains('setting')].to_csv(f'{args.outputdir}/features_CompoundAware_woSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_med.csv',sep='\\t',index=False)\n",
    "\n",
    "cur_ratings_agnostic_df_na.loc[:,~cur_ratings_agnostic_df_na.columns.str.contains('setting')].to_csv(f'{args.outputdir}/features_CompoundAgnostic_woSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_na.csv',sep='\\t',index=False)\n",
    "cur_ratings_agnostic_df_med.loc[:,~cur_ratings_agnostic_df_med.columns.str.contains('setting')].to_csv(f'{args.outputdir}/features_CompoundAgnostic_woSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_med.csv',sep='\\t',index=False)\n",
    "      \n",
    "\n",
    "cur_ratings_aware_df_na.to_csv(f'{args.outputdir}/features_CompoundAware_withSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_na.csv',sep='\\t',index=False)\n",
    "cur_ratings_aware_df_med.to_csv(f'{args.outputdir}/features_CompoundAware_withSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_med.csv',sep='\\t',index=False)\n",
    "\n",
    "cur_ratings_agnostic_df_na.to_csv(f'{args.outputdir}/features_CompoundAgnostic_withSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_na.csv',sep='\\t',index=False)\n",
    "cur_ratings_agnostic_df_med.to_csv(f'{args.outputdir}/features_CompoundAgnostic_withSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_med.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/dharp/compounds/datasets/features/'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.outputdir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
