{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression on ContextAware and DecadeAware system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "library(glmnet)\n",
    "library(dplyr)\n",
    "#library(psych) \n",
    "library(lme4)\n",
    "library(e1071)\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list<-c(1001,1111,1221,1331,1441,1551,1661,1771,1881,1991)\n",
    "cut_off<-c(20,50,100)\n",
    "time_off<-c(0)\n",
    "lambda <- 10^seq(-3, 3, length = 100)\n",
    "df_total <- matrix(ncol=6,nrow = length(seed_list)*length(cut_off)*length(time_off))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1\n",
      "[1] 2\n",
      "[1] 3\n",
      "[1] 4\n",
      "[1] 5\n",
      "[1] 6\n",
      "[1] 7\n",
      "[1] 8\n",
      "[1] 9\n",
      "[1] 10\n",
      "[1] 11\n",
      "[1] 12\n",
      "[1] 13\n",
      "[1] 14\n",
      "[1] 15\n",
      "[1] 16\n",
      "[1] 17\n",
      "[1] 18\n",
      "[1] 19\n",
      "[1] 20\n",
      "[1] 21\n",
      "[1] 22\n",
      "[1] 23\n",
      "[1] 24\n",
      "[1] 25\n",
      "[1] 26\n",
      "[1] 27\n",
      "[1] 28\n",
      "[1] 29\n",
      "[1] 30\n"
     ]
    }
   ],
   "source": [
    "k<-1\n",
    "for (s in seed_list) {\n",
    "    for (i in time_off) {\n",
    "        for (j in cut_off)  {\n",
    "            set.seed(s)\n",
    "            seeds <- vector(mode = \"list\", length = 11)\n",
    "            for(z in 1:10) seeds[[z]] <- sample.int(n=1000, 54)\n",
    "            #for the last model\n",
    "            seeds[[11]]<-sample.int(1000, 1)\n",
    "            df<-read.csv(paste0(\"../../datasets/features_CompoundAware_\",i,\"_\",j,\"_300.csv\"),sep = '\\t')\n",
    "            ridge <- train(\n",
    "              compound_mean ~. -modifier -head -modifier_mean -modifier_std -head_mean -head_std -compound_std, \n",
    "                data = df, method = \"glmnet\",\n",
    "                trControl = trainControl(\"cv\", number = 10,search=\"grid\",seeds=seeds),\n",
    "                tuneGrid = expand.grid(alpha = 0, lambda = lambda)\n",
    "            )\n",
    "\n",
    "            elastic <- train(\n",
    "              compound_mean ~. -modifier -head -modifier_mean -modifier_std -head_mean -head_std -compound_std,\n",
    "                data = df, method = \"glmnet\",\n",
    "              trControl = trainControl(\"cv\", number = 10,search=\"grid\",seeds=seeds),\n",
    "              tuneLength = 10\n",
    "              )\n",
    "\n",
    "            lasso <- train(\n",
    "              compound_mean ~. -modifier -head -modifier_mean -modifier_std -head_mean -head_std -compound_std,\n",
    "                data = df, method = \"glmnet\",\n",
    "                trControl = trainControl(\"cv\", number = 10,search=\"grid\",seeds=seeds),\n",
    "              tuneGrid = expand.grid(alpha = 1, lambda = lambda)\n",
    "              )\n",
    "\n",
    "            #print(round(getTrainPerf(elastic)[2],3))\n",
    "            print(k)\n",
    "            df_total[k,] <- c(s,i,j,as.numeric(getTrainPerf(elastic)[2]),as.numeric(getTrainPerf(lasso)[2]),as.numeric(getTrainPerf(ridge)[2]))\n",
    "            k<-k+1\n",
    "    \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total<-as.data.frame(df_total)\n",
    "colnames(df_total)<-c('seed','time','cutoff','elastic','lasso','ridge')\n",
    "#df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>time</th><th scope=col>cutoff</th><th scope=col>mean_e</th><th scope=col>sd_e</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0    </td><td> 20  </td><td>0.343</td><td>0.028</td></tr>\n",
       "\t<tr><td>0    </td><td> 50  </td><td>0.344</td><td>0.026</td></tr>\n",
       "\t<tr><td>0    </td><td>100  </td><td>0.337</td><td>0.035</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " time & cutoff & mean\\_e & sd\\_e\\\\\n",
       "\\hline\n",
       "\t 0     &  20   & 0.343 & 0.028\\\\\n",
       "\t 0     &  50   & 0.344 & 0.026\\\\\n",
       "\t 0     & 100   & 0.337 & 0.035\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "time | cutoff | mean_e | sd_e | \n",
       "|---|---|---|\n",
       "| 0     |  20   | 0.343 | 0.028 | \n",
       "| 0     |  50   | 0.344 | 0.026 | \n",
       "| 0     | 100   | 0.337 | 0.035 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  time cutoff mean_e sd_e \n",
       "1 0     20    0.343  0.028\n",
       "2 0     50    0.344  0.026\n",
       "3 0    100    0.337  0.035"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_total %>% group_by(time,cutoff) %>% summarise(mean_e=round(mean(elastic),3), sd_e=round(sd(elastic),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Ridge Regression to find a linear relationship between the features (PPMI, Local Mutual Information, Log Likelihood and the three similarity features) and compound_mean from the Reddy dataset for the 80 compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>cutoff</th><th scope=col>mean_e</th><th scope=col>sd_e</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 20  </td><td>0.343</td><td>0.028</td></tr>\n",
       "\t<tr><td> 50  </td><td>0.344</td><td>0.026</td></tr>\n",
       "\t<tr><td>100  </td><td>0.337</td><td>0.035</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " cutoff & mean\\_e & sd\\_e\\\\\n",
       "\\hline\n",
       "\t  20   & 0.343 & 0.028\\\\\n",
       "\t  50   & 0.344 & 0.026\\\\\n",
       "\t 100   & 0.337 & 0.035\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "cutoff | mean_e | sd_e | \n",
       "|---|---|---|\n",
       "|  20   | 0.343 | 0.028 | \n",
       "|  50   | 0.344 | 0.026 | \n",
       "| 100   | 0.337 | 0.035 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  cutoff mean_e sd_e \n",
       "1  20    0.343  0.028\n",
       "2  50    0.344  0.026\n",
       "3 100    0.337  0.035"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_total %>% group_by(cutoff) %>% summarise(mean_e=round(mean(elastic),3), sd_e=round(sd(elastic),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>time</th><th scope=col>mean_e</th><th scope=col>sd_e</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0    </td><td>0.341</td><td>0.029</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " time & mean\\_e & sd\\_e\\\\\n",
       "\\hline\n",
       "\t 0     & 0.341 & 0.029\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "time | mean_e | sd_e | \n",
       "|---|\n",
       "| 0     | 0.341 | 0.029 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  time mean_e sd_e \n",
       "1 0    0.341  0.029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_total %>% group_by(time) %>% summarise(mean_e=round(mean(elastic),3), sd_e=round(sd(elastic),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\""
     ]
    }
   ],
   "source": [
    "\n",
    "# Model coefficients\n",
    "#coef(ridge$finalModel, ridge$bestTune$lambda)\n",
    "# Make predictions\n",
    "#predictions <- ridge %>% predict(test.data)\n",
    "# Model prediction performance\n",
    "#data.frame(\n",
    "#  RMSE = RMSE(predictions, test.data$medv),\n",
    "#  Rsquare = R2(predictions, test.data$medv)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>TrainRsquared</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.193</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " TrainRsquared\\\\\n",
       "\\hline\n",
       "\t 0.193\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "TrainRsquared | \n",
       "|---|\n",
       "| 0.193 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  TrainRsquared\n",
       "1 0.193        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(getTrainPerf(lasso)[2],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.324194\t0.3610691\t1.1601\tglmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "summary.resamples(object = ., metric = \"RMSE\")\n",
       "\n",
       "Models: ridge, lasso, elastic \n",
       "Number of resamples: 10 \n",
       "\n",
       "RMSE \n",
       "             Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\n",
       "ridge   1.1327733 1.381881 1.486881 1.498544 1.560698 1.965494    0\n",
       "lasso   0.9580396 1.325377 1.467451 1.459236 1.601759 1.830630    0\n",
       "elastic 1.0045829 1.322360 1.451215 1.449042 1.599522 1.781900    0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models <- list(ridge = ridge, lasso = lasso, elastic = elastic)\n",
    "resamples(models) %>% summary( metric = \"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.new(width = 550, height = 900, unit = \"px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df<-read.csv(paste0(\"../../datasets/features_CompoundAware_\",20,\"_\",100,\"_300.csv\"),sep = '\\t')\n",
    "df$compound_rating<-''\n",
    "#colnames(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>high</dt>\n",
       "\t\t<dd>24</dd>\n",
       "\t<dt>low</dt>\n",
       "\t\t<dd>27</dd>\n",
       "\t<dt>med</dt>\n",
       "\t\t<dd>26</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[high] 24\n",
       "\\item[low] 27\n",
       "\\item[med] 26\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "high\n",
       ":   24low\n",
       ":   27med\n",
       ":   26\n",
       "\n"
      ],
      "text/plain": [
       "high  low  med \n",
       "  24   27   26 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df$compound_rating[df$compound_mean<2]<-'low'\n",
    "df$compound_rating[df$compound_mean>=4]<-'high'\n",
    "df$compound_rating[df$compound_mean>=2 & df$compound_mean<4]<-'med'\n",
    "\n",
    "summary(as.factor(df$compound_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TrainRsquared\n",
      "1         0.373\n"
     ]
    }
   ],
   "source": [
    "            df<-read.csv(paste0(\"../../datasets/features_CompoundAware_\",20,\"_\",100,\"_300.csv\"),sep = '\\t')\n",
    "\n",
    "            elastic <- train(\n",
    "              compound_mean ~. -modifier -head -modifier_mean -modifier_std -head_mean -head_std -compound_std,\n",
    "                data = df, method = \"glmnet\",\n",
    "              trControl = trainControl(\"cv\", number = 10,search=\"grid\",seeds=seeds),\n",
    "              tuneLength = 10\n",
    "              )\n",
    "\n",
    "\n",
    "            print(round(getTrainPerf(elastic)[2],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glmnet variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 66)\n",
       "\n",
       "                          Overall\n",
       "X1980_ppmi                    100\n",
       "X1920_sim_bw_constituents       0\n",
       "X1860_log_ratio                 0\n",
       "X1940_local_mi                  0\n",
       "X1980_sim_with_head             0\n",
       "X1960_sim_with_modifier         0\n",
       "X1920_sim_with_modifier         0\n",
       "X1960_sim_with_head             0\n",
       "X1800_local_mi                  0\n",
       "X1820_sim_bw_constituents       0\n",
       "X2000_sim_with_head             0\n",
       "X1940_log_ratio                 0\n",
       "X2000_local_mi                  0\n",
       "X1920_log_ratio                 0\n",
       "X1860_sim_bw_constituents       0\n",
       "X1880_sim_with_modifier         0\n",
       "X1940_sim_with_head             0\n",
       "X1800_ppmi                      0\n",
       "X1940_ppmi                      0\n",
       "X1920_local_mi                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "varImp(elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Importance is used to look at the importance of a feature in predicting compound_mean. We show the top 20 features out of the possible 126 (21 decades * 6 features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the features irrespective of the decade,\n",
    "\n",
    "log ratio is the most important and occupies 11/20 positions with local mutual information in the other 9. \n",
    "\n",
    "We do not see any of the similarity features being as important as the information theory based features. \n",
    "\n",
    "(This is good because previous studies only looked at similarity and frequencies, but never information theory features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is the distribution of the variables that were deemed important based on the decade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1800 : 1\n",
    "\n",
    "1830 : 2\n",
    "\n",
    "1840 : 2\n",
    "\n",
    "1850 : 2\n",
    "\n",
    "1860 : 2\n",
    "\n",
    "1870 : 2\n",
    "\n",
    "1880 : 2\n",
    "\n",
    "1890 : 2\n",
    "\n",
    "1900 : 2\n",
    "\n",
    "1910 : 2\n",
    "\n",
    "1920 : 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "( We need to figure out how and if the decade information makes any sense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compare this model with the non temporal model, we get better R squared values, so we can say that temporal information is helping us predict the compositionality score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
