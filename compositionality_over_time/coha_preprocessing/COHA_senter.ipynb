{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import fasttext\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = fasttext.load_model('/home/users0/pageljs/dh/repos/lid.176.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data - Original Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = \"/resources/corpora/COHA/text/\"\n",
    "#_dir = \"/resources/corpora/COHA/CCOHA/tagged/\"\n",
    "#_dir = \"/resources/corpora/COHA/CCOHA/tagged\"\n",
    "files_orig = sorted(os.listdir(_dir))[1:]\n",
    "print(len(files_orig))\n",
    "files_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_sentences(text,sent_segmenter):\n",
    "    doc = sent_segmenter(text)\n",
    "    return [str(sent).strip() for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_detect(sents):\n",
    "    new_sents=[]\n",
    "    for sent in sents:\n",
    "        labels,_=fmodel.predict(sent,k=-1)\n",
    "        if labels[0]=='__label__en':\n",
    "            new_sents.append(sent)\n",
    "    return new_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zfile in files_orig:\n",
    "    dec_time=time.time()\n",
    "    cur_decade=zfile.split('_')[1]\n",
    "    print(cur_decade)\n",
    "    if int(cur_decade.rstrip('s'))<int(start_decade.rstrip('s')):\n",
    "        continue\n",
    "\n",
    "    \n",
    "    df_list=[]\n",
    "    zip_file_orig    = zipfile.ZipFile(os.path.join(_dir, zfile))\n",
    "    zinfos_orig = zip_file_orig.infolist()\n",
    "    \n",
    "    names=[]\n",
    "    sizes=[]\n",
    "    ids=[]\n",
    "    for i,zfile in enumerate(zinfos_orig):\n",
    "        names.append(zfile.filename)\n",
    "        ids.append(i)\n",
    "        sizes.append(zfile.file_size)\n",
    "    zfile_df=pd.DataFrame({'fid':ids,'fname':names,'fsize':sizes})\n",
    "    zfile_df['fsize_perc']=zfile_df.fsize/zfile_df.fsize.sum()*100\n",
    "    zfile_df.sort_values(by=['fsize'],ascending=False,inplace=True,ignore_index=True)\n",
    "    zfile_df.fsize/=1024*1024\n",
    "    \n",
    "    file_list=zfile_df.fname.to_list()\n",
    "    \n",
    "    \n",
    "    sent_segmenter=spacy.load('en_core_web_sm')\n",
    "    sent_segmenter.disable_pipe(\"parser\")\n",
    "    sent_segmenter.enable_pipe(\"senter\")\n",
    "    sent_segmenter.add_pipe(\"doc_cleaner\")\n",
    "    sent_segmenter.max_length=10_000_000\n",
    "    \n",
    "    sent_dict={}\n",
    "    n_proc = mp.cpu_count()-1\n",
    "    for i,file_id in enumerate(file_list):\n",
    "        print(f'File {i+1} out of {len(file_list)}')\n",
    "        print(file_id)\n",
    "        items_file_orig  = zip_file_orig.open(file_id, 'r')\n",
    "        inp_text=io.TextIOWrapper(items_file_orig).read()\n",
    "\n",
    "        cur_year=int(file_id.split('_')[1])\n",
    "        inp_text=re.sub('\\\\|p[\\d]+', '', inp_text)\n",
    "        inp_text=re.sub('\\\\|', '', inp_text)\n",
    "        inp_text=re.sub('txt','',inp_text)\n",
    "        inp_text=inp_text.split('\\n\\n')[-1]\n",
    "        print(f'Number of characters {len(inp_text)}')\n",
    "        print(f\"Running sentence segmenter\")\n",
    "\n",
    "        sents=split_in_sentences(inp_text,sent_segmenter)\n",
    "\n",
    "        print(f'Number of sentences {len(sents)}')\n",
    "        print(f\"Running language identifier\")\n",
    "\n",
    "\n",
    "        sents=lang_detect(sents)\n",
    "        print(f'Number of sentences {len(sents)}')\n",
    "        sent_dict[file_id]=sents\n",
    "    \n",
    "\n",
    "    print(f\"Total time taken for decade {cur_decade} : {round(time.time()-dec_time)} secs\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
