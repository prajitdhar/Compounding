{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD for all. contemporary for the last decade - 2000's\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds=pd.read_pickle('/home/users0/pageljs/dh/repos/Compounding/datasets/compounds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds.context.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds=compounds.loc[(compounds.modifier.str.contains(\"^[a-zA-Z0-9_]*$\")) & (compounds['head'].str.contains(\"^[a-zA-Z0-9_]*$\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds=compounds.loc[~compounds.modifier.str.contains('^(?:of|the|-)_.+')]\n",
    "compounds=compounds.loc[~compounds['head'].str.contains('^(?:of|the|-)_.+')]\n",
    "compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_counts=compounds.groupby(['modifier','head','cat','year'])['count'].sum().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_counts.loc[(comp_counts.modifier==\"background_NOUN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_counts.cat.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_counts.query('modifier == stone and head == wall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data - Original Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = \"/home/users0/pageljs/dh/repos/coha_sents/\"\n",
    "#_dir = \"/resources/corpora/COHA/CCOHA/tagged/\"\n",
    "#_dir = \"/resources/corpora/COHA/CCOHA/tagged\"\n",
    "files_orig = sorted(os.listdir(_dir))#[1:]\n",
    "print(len(files_orig))\n",
    "files_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_processor(file_id,parser):\n",
    "    print(file_id)\n",
    "\n",
    "    cur_year=int(file_id.split('_')[1])\n",
    "    sents=cur_decade_pkl[file_id]\n",
    "    print(f'Number of sentences {len(sents)}')\n",
    "    print(\"Running parser\")\n",
    "    \n",
    "    docs = list(parser.pipe(sents))\n",
    "    print(\"Done running parser\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    tokens=[]\n",
    "    lemmas=[]\n",
    "    pos=[]\n",
    "    deps=[]\n",
    "    is_stop=[]\n",
    "    ner=[]\n",
    "    for doc in docs:\n",
    "        for token in doc:\n",
    "            tokens.append(token.text)\n",
    "            lemmas.append(token.lemma_)\n",
    "            pos.append(token.pos_)\n",
    "            deps.append(token.dep_)\n",
    "            is_stop.append(token.is_stop)\n",
    "            ner.append(token.ent_type_)\n",
    "\n",
    "    df_dicts={'token':tokens,'lemma':lemmas,'pos':pos,'dep':deps,'ner':ner,'year':cur_year}\n",
    "    cur_df=pd.DataFrame.from_dict(df_dicts)\n",
    "    if cur_df.shape[0]==0:\n",
    "        return None\n",
    "    cur_df=cur_df.loc[~(cur_df.pos==\"SPACE\")].reset_index(drop=True)\n",
    "    cur_df['lem_pos']=cur_df.lemma.str.lower()+\"_\"+cur_df.pos\n",
    "    cur_df['n_comp']=False\n",
    "    cur_df.loc[(cur_df.pos.isin(['PROPN','NOUN'])) & (cur_df.dep=='compound'),'n_comp']=True\n",
    "    cur_df['lemma_pos']=cur_df.lem_pos.shift(0)+ ' ' + cur_df.lem_pos.shift(-1)+ ' ' + cur_df.lem_pos.shift(-2)+ ' ' + cur_df.lem_pos.shift(-3)+ ' ' + cur_df.lem_pos.shift(-4)\n",
    "    cur_df['pos_sent']=cur_df.pos.shift(0)+ ' ' + cur_df.pos.shift(-1)+ ' ' + cur_df.pos.shift(-2)+ ' ' + cur_df.pos.shift(-3)+ ' ' + cur_df.pos.shift(-4)\n",
    "    cur_df['num_comp']=False\n",
    "    cur_df.loc[cur_df.n_comp.shift(0)|cur_df.n_comp.shift(-1)|cur_df.n_comp.shift(-2)|cur_df.n_comp.shift(-3)|cur_df.n_comp.shift(-4),'num_comp']=True\n",
    "    cur_df['tokens']=cur_df.token.shift(0)+ ' ' + cur_df.token.shift(-1)+ ' ' + cur_df.token.shift(-2)+ ' ' + cur_df.token.shift(-3)+ ' ' + cur_df.token.shift(-4)\n",
    "    cur_df['c_ner_sent']=\"\"\n",
    "    mask=(cur_df.ner!=\"\") & (cur_df.num_comp==True)\n",
    "    cur_df.loc[mask,'c_ner_sent']=cur_df.loc[mask,'ner']\n",
    "    cur_df['comp_ner_sent']=cur_df.c_ner_sent.shift(0)+ ' ' + cur_df.c_ner_sent.shift(-1)+ ' ' + cur_df.c_ner_sent.shift(-2)+ ' ' + cur_df.c_ner_sent.shift(-3)+ ' ' + cur_df.c_ner_sent.shift(-4)\n",
    "    cur_df.comp_ner_sent=cur_df.comp_ner_sent.str.strip()\n",
    "    cur_df.dropna(inplace=True)\n",
    "    cur_df['nX']=cur_df.lemma_pos.str.count('_X')-cur_df.lemma_pos.str.count('_AUX')\n",
    "    cur_df=cur_df.loc[cur_df.nX!=5]\n",
    "    cur_df['comp_class']=0\n",
    "    cur_df.loc[cur_df.pos_sent.str.contains(n1),'comp_class']=1\n",
    "    cur_df.loc[~(cur_df.pos_sent.str.contains(n1))& cur_df.pos_sent.str.contains(n2),'comp_class']=2\n",
    "    cur_df.loc[cur_df.pos_sent.str.contains(n3),'comp_class']=3\n",
    "    cur_df.loc[cur_df.pos_sent.str.contains(n4),'comp_class']=4\n",
    "    cur_df.loc[~(cur_df.pos_sent.str.contains(n1))& cur_df.pos_sent.str.contains(n5),'comp_class']=5\n",
    "    cur_df['count']=1\n",
    "    cur_df=cur_df.groupby(['lemma_pos','tokens','year','comp_class','num_comp','comp_ner_sent'])['count'].sum().to_frame().reset_index()\n",
    "    print(\"\\n\")\n",
    "    return cur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_processor(df,cur_decade):\n",
    "    file_list=df.fname.to_list()\n",
    "    cur_time=time.time()\n",
    "    parser = spacy.load('en_core_web_trf')\n",
    "    parser.add_pipe(\"doc_cleaner\")\n",
    "    parser.max_length=10_000_000\n",
    "    \n",
    "    \n",
    "    df_list=[]\n",
    "    \n",
    "    for i,cur_file in enumerate(file_list):\n",
    "        print(f'File {i+1} out of {len(file_list)}')\n",
    "        df_list.append(year_processor(cur_file,parser))\n",
    "    \n",
    "    del parser\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    cur_decade_df=pd.concat(df_list,ignore_index=True,sort=True)\n",
    "    print(f'Shape of dataframe before grouping :{cur_decade_df.shape}')\n",
    "    cur_decade_df=cur_decade_df.groupby(['lemma_pos','tokens','year','comp_class','num_comp','comp_ner_sent'])['count'].sum().to_frame().reset_index()\n",
    "\n",
    "    print(f'Shape of dataframe after grouping :{cur_decade_df.shape}')\n",
    "\n",
    "    print(f\"Done processing for decade {cur_decade}, group {df.iloc[0].fcat}\")\n",
    "    print(f\"Total time taken for decade {cur_decade} : {round(time.time()-cur_time)} secs\")\n",
    "    return cur_decade_df\n",
    "    #cur_decade_df.to_pickle(f'{args.output}/{cur_decade}.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_decade_pkl = pickle.load( open( \"/home/users0/pageljs/dh/repos/coha_sents/1970s.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cur_decade_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "sents=[]\n",
    "\n",
    "for key,val in cur_decade_pkl.items():\n",
    "    names.append(key)\n",
    "    sents.append(len(val))\n",
    "zfile_df=pd.DataFrame({'fname':names,'flen':sents})\n",
    "zfile_df=zfile_df.loc[zfile_df.flen>0]\n",
    "zfile_df.sort_values(by=['flen'],ascending=False,inplace=True,ignore_index=True)\n",
    "zfile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfile_df.flen.sum()/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxvalue = 300_000\n",
    "\n",
    "lastvalue = 0\n",
    "newcum = []\n",
    "labels=[]\n",
    "cur_label=1\n",
    "for row in zfile_df.itertuples():\n",
    "    thisvalue =  row.flen + lastvalue\n",
    "    if thisvalue > maxvalue:\n",
    "        thisvalue = 0\n",
    "        cur_label+=1\n",
    "    newcum.append(thisvalue)\n",
    "    labels.append(cur_label)\n",
    "    lastvalue = thisvalue\n",
    "zfile_df['fcat']=labels\n",
    "zfile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_decade='1970s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=part_processor(zfile_df.loc[zfile_df.fcat==1],cur_decade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cur_decade_df=zfile_df.groupby('fcat').apply(lambda x: part_processor(x,cur_decade))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
