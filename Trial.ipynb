{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob, os\n",
    "from os.path import isfile\n",
    "done_files=[]\n",
    "os.chdir(\"/data/dharp/compounds/datasets/stats/\")\n",
    "cur_dir='/data/dharp/compounds/datasets/stats/'\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    done_files.append(file.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[pd.read_csv(cur_dir+cur_file+'.txt',sep=\"\\t\",header=None) for cur_file in done_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8f93ffabc43e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/dharp/compounds/datasets/compounds.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dharp/packages/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dharp/packages/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dharp/packages/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/dharp/packages/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "tt=pd.read_csv('/data/dharp/compounds/datasets/compounds.csv',sep='\\t')\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modifier    head       \n",
       "common      prayer          470397\n",
       "capital     stock           472644\n",
       "catholic    university      476813\n",
       "central     committee       483908\n",
       "chief       justice         503431\n",
       "american    revolution      521674\n",
       "great       britain         536210\n",
       "air         force           546698\n",
       "central     government      571291\n",
       "balance     sheet           574158\n",
       "american    society         607238\n",
       "dining      room            608095\n",
       "east        coast           614320\n",
       "dorsal      surface         617137\n",
       "jesus       christ          627987\n",
       "indian      affairs         628365\n",
       "black       sea             645886\n",
       "cultural    revolution      670382\n",
       "dialog      box             689594\n",
       "end         result          690635\n",
       "common      pleas           693589\n",
       "cold        war             706250\n",
       "american    association     721372\n",
       "british     isles           724410\n",
       "            empire          918169\n",
       "cross       section         958416\n",
       "death       penalty         967603\n",
       "attorney    general         989582\n",
       "catholic    church         1010753\n",
       "new         york           1034464\n",
       "eighteenth  century        1082113\n",
       "british     government     1135669\n",
       "good        hope           1299998\n",
       "east        side           1380303\n",
       "communist   party          1381331\n",
       "per         cent           1541212\n",
       "civil       war            1614791\n",
       "district    court          1709555\n",
       "world       war            1952072\n",
       "united      states         5536728\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.groupby(['modifier','head'])['count'].sum().sort_values().tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path='/data/dharp/compounds/datasets/entire_df/'\n",
    "df_files=[]\n",
    "for filename in glob.glob(df_path+'*parq'):\n",
    "    #print(filename)\n",
    "    df_files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_lemma_reducer(sent):\n",
    "    ner_cat=None\n",
    "    lemma=[]\n",
    "    parsed_sent=nlp(sent)\n",
    "    for token in parsed_sent:\n",
    "        lemma.append(token.lemma_)\n",
    "    lemma_sent=' '.join(lemma)\n",
    "    \n",
    "    if parsed_sent.ents:\n",
    "        for e in parsed_sent.ents:\n",
    "            #print(e.text,e.label_)\n",
    "            if e.label_=='PERSON':\n",
    "                ner_cat='PERSON'\n",
    "    else:\n",
    "        ner_cat=None\n",
    "    #print(sent,ner_cat,lemma_sent)\n",
    "    return pd.Series([ner_cat,lemma_sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_to_us=pd.read_csv('data/spelling.csv',sep='\\t')\n",
    "br_to_us_dict=dict(zip(br_to_us.UK.tolist(),br_to_us.US.tolist()))\n",
    "\n",
    "\n",
    "spelling_replacement={'context':br_to_us_dict,'modifier':br_to_us_dict,'head':br_to_us_dict,'word':br_to_us_dict}\n",
    "\n",
    "\n",
    "any_word=r'.+_.+'\n",
    "any_noun=r'.+_noun'\n",
    "proper_noun=r'[a-z.-]+_noun'\n",
    "space=r'\\s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=fastparquet.ParquetFile('/data/dharp/compounds/datasets/entire_df/df_4.parq')\n",
    "current_df = next(iter(ff.iter_row_groups()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ff.row_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df.year=current_df.year.astype('int32')\n",
    "df=current_df.head(100000).copy()\n",
    "df=df.groupby(['fivegram_pos','year']).sum('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_index</th>\n",
       "      <th>l1_pos</th>\n",
       "      <th>word_pos</th>\n",
       "      <th>r1_pos</th>\n",
       "      <th>r2_pos</th>\n",
       "      <th>r3_pos</th>\n",
       "      <th>sent</th>\n",
       "      <th>pos</th>\n",
       "      <th>IS_PERSON</th>\n",
       "      <th>new_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he'th_adp a_det overtheer_noun and_conj makin_...</td>\n",
       "      <td>he'th_adp</td>\n",
       "      <td>a_det</td>\n",
       "      <td>overtheer_noun</td>\n",
       "      <td>and_conj</td>\n",
       "      <td>makin_verb</td>\n",
       "      <td>he'th a overtheer and makin</td>\n",
       "      <td>adp det noun conj verb</td>\n",
       "      <td>None</td>\n",
       "      <td>he'th a overtheer and makin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he_adj being_noun dead_pron yet_verb speaketh_...</td>\n",
       "      <td>he_adj</td>\n",
       "      <td>being_noun</td>\n",
       "      <td>dead_pron</td>\n",
       "      <td>yet_verb</td>\n",
       "      <td>speaketh_noun</td>\n",
       "      <td>he being dead yet speaketh</td>\n",
       "      <td>adj noun pron verb noun</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- be dead yet speaketh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he_adj has_noun taken_verb off_verb in_adp</td>\n",
       "      <td>he_adj</td>\n",
       "      <td>has_noun</td>\n",
       "      <td>taken_verb</td>\n",
       "      <td>off_verb</td>\n",
       "      <td>in_adp</td>\n",
       "      <td>he has taken off in</td>\n",
       "      <td>adj noun verb verb adp</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- have take off in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he_adj purpose_noun of_adp this_det book_noun</td>\n",
       "      <td>he_adj</td>\n",
       "      <td>purpose_noun</td>\n",
       "      <td>of_adp</td>\n",
       "      <td>this_det</td>\n",
       "      <td>book_noun</td>\n",
       "      <td>he purpose of this book</td>\n",
       "      <td>adj noun adp det noun</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- purpose of this book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he_pron '_. knows_verb '_pron that_adp</td>\n",
       "      <td>he_pron</td>\n",
       "      <td>'_.</td>\n",
       "      <td>knows_verb</td>\n",
       "      <td>'_pron</td>\n",
       "      <td>that_adp</td>\n",
       "      <td>he ' knows ' that</td>\n",
       "      <td>pron . verb pron adp</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- ' know ' that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>he_pron accepted_verb the_det office_noun of_adp</td>\n",
       "      <td>he_pron</td>\n",
       "      <td>accepted_verb</td>\n",
       "      <td>the_det</td>\n",
       "      <td>office_noun</td>\n",
       "      <td>of_adp</td>\n",
       "      <td>he accepted the office of</td>\n",
       "      <td>pron verb det noun adp</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- accept the office of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>he_pron accepted_verb the_det position_noun in...</td>\n",
       "      <td>he_pron</td>\n",
       "      <td>accepted_verb</td>\n",
       "      <td>the_det</td>\n",
       "      <td>position_noun</td>\n",
       "      <td>in_adp</td>\n",
       "      <td>he accepted the position in</td>\n",
       "      <td>pron verb det noun adp</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- accept the position in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>he_pron accepted_verb the_det post_noun at_adp</td>\n",
       "      <td>he_pron</td>\n",
       "      <td>accepted_verb</td>\n",
       "      <td>the_det</td>\n",
       "      <td>post_noun</td>\n",
       "      <td>at_adp</td>\n",
       "      <td>he accepted the post at</td>\n",
       "      <td>pron verb det noun adp</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- accept the post at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>he_pron accepted_verb the_det post_noun with_adp</td>\n",
       "      <td>he_pron</td>\n",
       "      <td>accepted_verb</td>\n",
       "      <td>the_det</td>\n",
       "      <td>post_noun</td>\n",
       "      <td>with_adp</td>\n",
       "      <td>he accepted the post with</td>\n",
       "      <td>pron verb det noun adp</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- accept the post with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>he_pron accepted_verb the_det principle_noun o...</td>\n",
       "      <td>he_pron</td>\n",
       "      <td>accepted_verb</td>\n",
       "      <td>the_det</td>\n",
       "      <td>principle_noun</td>\n",
       "      <td>of_adp</td>\n",
       "      <td>he accepted the principle of</td>\n",
       "      <td>pron verb det noun adp</td>\n",
       "      <td>None</td>\n",
       "      <td>-PRON- accept the principle of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2896 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              old_index     l1_pos  \\\n",
       "0     he'th_adp a_det overtheer_noun and_conj makin_...  he'th_adp   \n",
       "1     he_adj being_noun dead_pron yet_verb speaketh_...     he_adj   \n",
       "2            he_adj has_noun taken_verb off_verb in_adp     he_adj   \n",
       "3         he_adj purpose_noun of_adp this_det book_noun     he_adj   \n",
       "4                he_pron '_. knows_verb '_pron that_adp    he_pron   \n",
       "...                                                 ...        ...   \n",
       "2891   he_pron accepted_verb the_det office_noun of_adp    he_pron   \n",
       "2892  he_pron accepted_verb the_det position_noun in...    he_pron   \n",
       "2893     he_pron accepted_verb the_det post_noun at_adp    he_pron   \n",
       "2894   he_pron accepted_verb the_det post_noun with_adp    he_pron   \n",
       "2895  he_pron accepted_verb the_det principle_noun o...    he_pron   \n",
       "\n",
       "           word_pos          r1_pos          r2_pos         r3_pos  \\\n",
       "0             a_det  overtheer_noun        and_conj     makin_verb   \n",
       "1        being_noun       dead_pron        yet_verb  speaketh_noun   \n",
       "2          has_noun      taken_verb        off_verb         in_adp   \n",
       "3      purpose_noun          of_adp        this_det      book_noun   \n",
       "4               '_.      knows_verb          '_pron       that_adp   \n",
       "...             ...             ...             ...            ...   \n",
       "2891  accepted_verb         the_det     office_noun         of_adp   \n",
       "2892  accepted_verb         the_det   position_noun         in_adp   \n",
       "2893  accepted_verb         the_det       post_noun         at_adp   \n",
       "2894  accepted_verb         the_det       post_noun       with_adp   \n",
       "2895  accepted_verb         the_det  principle_noun         of_adp   \n",
       "\n",
       "                              sent                      pos IS_PERSON  \\\n",
       "0      he'th a overtheer and makin   adp det noun conj verb      None   \n",
       "1       he being dead yet speaketh  adj noun pron verb noun      None   \n",
       "2              he has taken off in   adj noun verb verb adp      None   \n",
       "3          he purpose of this book    adj noun adp det noun      None   \n",
       "4                he ' knows ' that     pron . verb pron adp      None   \n",
       "...                            ...                      ...       ...   \n",
       "2891     he accepted the office of   pron verb det noun adp      None   \n",
       "2892   he accepted the position in   pron verb det noun adp      None   \n",
       "2893       he accepted the post at   pron verb det noun adp      None   \n",
       "2894     he accepted the post with   pron verb det noun adp      None   \n",
       "2895  he accepted the principle of   pron verb det noun adp      None   \n",
       "\n",
       "                            new_sent  \n",
       "0        he'th a overtheer and makin  \n",
       "1        -PRON- be dead yet speaketh  \n",
       "2            -PRON- have take off in  \n",
       "3        -PRON- purpose of this book  \n",
       "4               -PRON- ' know ' that  \n",
       "...                              ...  \n",
       "2891     -PRON- accept the office of  \n",
       "2892   -PRON- accept the position in  \n",
       "2893       -PRON- accept the post at  \n",
       "2894     -PRON- accept the post with  \n",
       "2895  -PRON- accept the principle of  \n",
       "\n",
       "[2896 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df=pd.DataFrame(df.index.get_level_values('fivegram_pos').unique().tolist())\n",
    "new_df.columns=['old_index']\n",
    "new_df[['l1_pos','word_pos','r1_pos','r2_pos','r3_pos']]=new_df['old_index'].str.split(space,expand=True,n=5)\n",
    "new_df['sent']=new_df.l1_pos.str.split('_').str[0]+\" \"+new_df.word_pos.str.split('_').str[0]+\" \"+new_df.r1_pos.str.split('_').str[0]+\" \"+new_df.r2_pos.str.split('_').str[0]+\" \"+new_df.r3_pos.str.split('_').str[0]\n",
    "new_df['pos']=new_df.l1_pos.str.split('_').str[1]+\" \"+new_df.word_pos.str.split('_').str[1]+\" \"+new_df.r1_pos.str.split('_').str[1]+\" \"+new_df.r2_pos.str.split('_').str[1]+\" \"+new_df.r3_pos.str.split('_').str[1]\n",
    "#new_df=new_df[['old_index','sent','pos']]\n",
    "new_df[['IS_PERSON','new_sent']]=new_df['sent'].apply(ner_lemma_reducer)#,axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'l1_pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-73c811bc8244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ds/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5458\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5459\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5460\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'l1_pos'"
     ]
    }
   ],
   "source": [
    "new_df.l1_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       otheraotherdotherpother otherdothereothertothe...\n",
       "1       otheraotherdotherjother notherootheruothernoth...\n",
       "2       otheraotherdotherjother notherootheruothernoth...\n",
       "3       otheraotherdotherjother notherootheruothernoth...\n",
       "4       otherpotherrotheroothernother other.other othe...\n",
       "                              ...                        \n",
       "2891    otherpotherrotheroothernother othervothereothe...\n",
       "2892    otherpotherrotheroothernother othervothereothe...\n",
       "2893    otherpotherrotheroothernother othervothereothe...\n",
       "2894    otherpotherrotheroothernother othervothereothe...\n",
       "2895    otherpotherrotheroothernother othervothereothe...\n",
       "Name: pos, Length: 2896, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.pos.str.replace('(?!noun)',repl='other',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-97-7788f1f472b7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-97-7788f1f472b7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [^ ]\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[^ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: IS_PERSON, dtype: int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.IS_PERSON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he'th_adp PROPN compound\n",
      "a_det PROPN ROOT\n",
      "overtheer_noun PROPN ROOT\n",
      "and_conj PROPN compound\n",
      "makin_verb PROPN ROOT\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(current_df.iloc[10].fivegram_pos)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
