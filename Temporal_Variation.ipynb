{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import pickle as pkl\n",
    "\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", font_scale = 2.5)\n",
    "sns.set_context(rc={\"lines.markersize\": 17, \"lines.linewidth\": 2})\n",
    "\n",
    "import matplotlib.pyplot as plt      \n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Compute temporal variation features from sparse dataset for google version')\n",
    "\n",
    "parser.add_argument('--inputdir',type=str,\n",
    "                    help='Provide directory where features are located')\n",
    "parser.add_argument('--outputdir',type=str,\n",
    "                    help='Where should the output be stored?')\n",
    "parser.add_argument('--tag', action='store_true',\n",
    "                    help='Should the POS tag be kept?')\n",
    "parser.add_argument('--ppmi', action='store_true',\n",
    "                    help='Should co-occurence matrix be converted to PPMI values')\n",
    "parser.add_argument('--temporal',  type=int,\n",
    "                    help='Value to bin the temporal information: 10000 (remove temporal information), 1 (no binning), 10 (binning to decades), 20 (binning each 20 years) or 50 (binning each 50 years)')\n",
    "parser.add_argument('--cutoff', type=int, default=0,\n",
    "                    help='Cut-off frequency for each compound per time period : none (0), 20, 50 and 100')\n",
    "args = parser.parse_args('--inputdir /datanaco/dharp/compounds/datasets/ --outputdir /data/dharp/compounds/datasets/google/ --temporal 10'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddy_df=pd.read_csv('data/reddy_90.txt',sep='\\t')\n",
    "reddy_df['source']='reddy'\n",
    "cordeiro90_df=pd.read_csv('data/cordeiro_90.txt',sep='\\t')\n",
    "cordeiro90_df['source']='cordeiro90'\n",
    "cordeiro100_df=pd.read_csv('data/cordeiro_100.txt',sep='\\t')\n",
    "cordeiro100_df['source']='cordeiro100'\n",
    "\n",
    "    \n",
    "comp_ratings_df=pd.concat([reddy_df,cordeiro90_df,cordeiro100_df])\n",
    "#comp_ratings_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testset_tagger(df):\n",
    "\n",
    "    #### NOUN NOUN\n",
    "    \n",
    "    copy_df_1=df.copy()\n",
    "    copy_df_1.modifier=copy_df_1.modifier+'_NOUN'\n",
    "    copy_df_1['head']=copy_df_1['head']+'_NOUN'\n",
    "\n",
    "    ### PROPN NOUN\n",
    "\n",
    "    copy_df_2=df.copy()\n",
    "    copy_df_2.modifier=copy_df_2.modifier+'_PROPN'\n",
    "    copy_df_2['head']=copy_df_2['head']+'_NOUN'\n",
    "    \n",
    "    ### NOUN PROPN\n",
    "\n",
    "    copy_df_3=df.copy()\n",
    "    copy_df_3.modifier=copy_df_3.modifier+'_NOUN'\n",
    "    copy_df_3['head']=copy_df_3['head']+'_PROPN'\n",
    "    \n",
    "    ### PROPN PROPN    \n",
    "\n",
    "    copy_df_4=df.copy()\n",
    "    copy_df_4.modifier=copy_df_4.modifier+'_PROPN'\n",
    "    copy_df_4['head']=copy_df_4['head']+'_PROPN'\n",
    "    \n",
    "   \n",
    "    ### ADJ/NOUN NOUN\n",
    "    \n",
    "    copy_df_5=df.copy()\n",
    "    \n",
    "    copy_df_5.loc[copy_df_5.is_adj==True,\"modifier\"]+=\"_ADJ\"\n",
    "    copy_df_5.loc[copy_df_5.is_adj==False,\"modifier\"]+=\"_NOUN\"\n",
    "    copy_df_5['head']=copy_df_5['head']+'_NOUN'   \n",
    "    \n",
    "    \n",
    "    ### ADJ/NOUN PROPN\n",
    "    \n",
    "    copy_df_6=df.copy()\n",
    "    copy_df_6.loc[copy_df_6.is_adj==True,\"modifier\"]+=\"_ADJ\"\n",
    "    copy_df_6.loc[copy_df_6.is_adj==False,\"modifier\"]+=\"_NOUN\"\n",
    "    copy_df_6['head']=copy_df_6['head']+'_PROPN'  \n",
    "\n",
    "    \n",
    "    #### ADJ/PROPN NOUN\n",
    "    \n",
    "    copy_df_7=df.copy()\n",
    "    copy_df_7.loc[copy_df_7.is_adj==True,\"modifier\"]+=\"_ADJ\"\n",
    "    copy_df_7.loc[copy_df_7.is_adj==False,\"modifier\"]+=\"_PROPN\"\n",
    "    copy_df_7['head']=copy_df_7['head']+'_NOUN' \n",
    "    \n",
    "    \n",
    "    #### ADJ/PROPN PROPN\n",
    "    \n",
    "    copy_df_8=df.copy()\n",
    "    copy_df_8.loc[copy_df_8.is_adj==True,\"modifier\"]+=\"_ADJ\"\n",
    "    copy_df_8.loc[copy_df_8.is_adj==False,\"modifier\"]+=\"_PROPN\"\n",
    "    copy_df_8['head']=copy_df_8['head']+'_PROPN' \n",
    "    \n",
    "    \n",
    "    complete_df=pd.concat([copy_df_1,copy_df_2,copy_df_3,copy_df_4,copy_df_5,copy_df_6,copy_df_7,copy_df_8],ignore_index=True)\n",
    "                           \n",
    "    return complete_df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "      <th>avgModifier</th>\n",
       "      <th>stdevModifier</th>\n",
       "      <th>avgHead</th>\n",
       "      <th>stdevHead</th>\n",
       "      <th>compositionality</th>\n",
       "      <th>stdevHeadModifier</th>\n",
       "      <th>is_adj</th>\n",
       "      <th>compound</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>end</td>\n",
       "      <td>user</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>1.117537</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>0.339935</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.871165</td>\n",
       "      <td>False</td>\n",
       "      <td>end_user</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>firing</td>\n",
       "      <td>line</td>\n",
       "      <td>1.607143</td>\n",
       "      <td>1.654848</td>\n",
       "      <td>1.892857</td>\n",
       "      <td>1.496169</td>\n",
       "      <td>1.703704</td>\n",
       "      <td>1.717337</td>\n",
       "      <td>False</td>\n",
       "      <td>firing_line</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>game</td>\n",
       "      <td>plan</td>\n",
       "      <td>2.821429</td>\n",
       "      <td>1.964935</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>3.827586</td>\n",
       "      <td>1.233693</td>\n",
       "      <td>False</td>\n",
       "      <td>game_plan</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>application</td>\n",
       "      <td>form</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>0.422953</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.476095</td>\n",
       "      <td>False</td>\n",
       "      <td>application_form</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snail</td>\n",
       "      <td>mail</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4.586207</td>\n",
       "      <td>1.099129</td>\n",
       "      <td>1.310345</td>\n",
       "      <td>1.020596</td>\n",
       "      <td>False</td>\n",
       "      <td>snail_mail</td>\n",
       "      <td>reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>wedding</td>\n",
       "      <td>day</td>\n",
       "      <td>4.764700</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>4.058800</td>\n",
       "      <td>1.434900</td>\n",
       "      <td>4.941200</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>False</td>\n",
       "      <td>wedding_day</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>white</td>\n",
       "      <td>noise</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>1.112300</td>\n",
       "      <td>4.043500</td>\n",
       "      <td>1.429500</td>\n",
       "      <td>1.173900</td>\n",
       "      <td>1.230400</td>\n",
       "      <td>True</td>\n",
       "      <td>white_noise</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>white</td>\n",
       "      <td>spirit</td>\n",
       "      <td>1.538500</td>\n",
       "      <td>1.240300</td>\n",
       "      <td>2.038500</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.307700</td>\n",
       "      <td>1.257600</td>\n",
       "      <td>True</td>\n",
       "      <td>white_spirit</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>winter</td>\n",
       "      <td>solstice</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.681800</td>\n",
       "      <td>1.086100</td>\n",
       "      <td>4.545500</td>\n",
       "      <td>1.335500</td>\n",
       "      <td>False</td>\n",
       "      <td>winter_solstice</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>world</td>\n",
       "      <td>conference</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>1.361300</td>\n",
       "      <td>4.291700</td>\n",
       "      <td>1.267600</td>\n",
       "      <td>3.958300</td>\n",
       "      <td>1.366700</td>\n",
       "      <td>False</td>\n",
       "      <td>world_conference</td>\n",
       "      <td>cordeiro100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        modifier        head  avgModifier  stdevModifier   avgHead  stdevHead  \\\n",
       "0            end        user     3.866667       1.117537  4.866667   0.339935   \n",
       "1         firing        line     1.607143       1.654848  1.892857   1.496169   \n",
       "2           game        plan     2.821429       1.964935  4.862069   0.344828   \n",
       "3    application        form     4.766667       0.422953  4.862069   0.344828   \n",
       "4          snail        mail     0.600000       0.800000  4.586207   1.099129   \n",
       "..           ...         ...          ...            ...       ...        ...   \n",
       "97       wedding         day     4.764700       0.562300  4.058800   1.434900   \n",
       "98         white       noise     0.652200       1.112300  4.043500   1.429500   \n",
       "99         white      spirit     1.538500       1.240300  2.038500   1.949000   \n",
       "100       winter    solstice     5.000000       0.000000  4.681800   1.086100   \n",
       "101        world  conference     3.875000       1.361300  4.291700   1.267600   \n",
       "\n",
       "     compositionality  stdevHeadModifier  is_adj          compound  \\\n",
       "0            4.250000           0.871165   False          end_user   \n",
       "1            1.703704           1.717337   False       firing_line   \n",
       "2            3.827586           1.233693   False         game_plan   \n",
       "3            4.800000           0.476095   False  application_form   \n",
       "4            1.310345           1.020596   False        snail_mail   \n",
       "..                ...                ...     ...               ...   \n",
       "97           4.941200           0.242500   False       wedding_day   \n",
       "98           1.173900           1.230400    True       white_noise   \n",
       "99           1.307700           1.257600    True      white_spirit   \n",
       "100          4.545500           1.335500   False   winter_solstice   \n",
       "101          3.958300           1.366700   False  world_conference   \n",
       "\n",
       "          source  \n",
       "0          reddy  \n",
       "1          reddy  \n",
       "2          reddy  \n",
       "3          reddy  \n",
       "4          reddy  \n",
       "..           ...  \n",
       "97   cordeiro100  \n",
       "98   cordeiro100  \n",
       "99   cordeiro100  \n",
       "100  cordeiro100  \n",
       "101  cordeiro100  \n",
       "\n",
       "[287 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if args.tag:\n",
    "    comp_ratings_df=testset_tagger(comp_ratings_df)\n",
    "comp_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_decades_compound(dec_list,input_dir,unique_mod_list,unique_head_list,ctype='compound'):\n",
    "\n",
    "    if os.path.exists(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\"):\n",
    "        print('Reading file')\n",
    "        complete_df=pd.read_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "    elif os.path.exists(f\"{input_dir}/{ctype}s/10_{dec_list[0]}_{tag_str}.pkl\") and args.temporal!=10000:\n",
    "        print(f'Reading decades file {ctype}s/10_{dec_list[0]}_{tag_str}.pkl')\n",
    "        complete_df=pd.read_pickle(f\"{input_dir}/{ctype}s/10_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "        print(f'Reducing to {args.temporal}')\n",
    "        complete_df['time']=complete_df['time']-complete_df['time']%args.temporal\n",
    "\n",
    "        complete_df=complete_df.groupby(['modifier','head','time','context'])['count'].sum().to_frame().reset_index()\n",
    "        \n",
    "        print(\"Saving file\")\n",
    "        complete_df.to_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        df_list=[]\n",
    "\n",
    "        for dec in dec_list:\n",
    "            print(dec)\n",
    "            cur_df=pd.read_pickle(f'{input_dir}/{ctype}s/{dec}.pkl')\n",
    "            \n",
    "            if not args.tag:\n",
    "                cur_df=compound_tag_remover(cur_df)\n",
    "            cur_df['time']=dec\n",
    "            cur_df['time']=cur_df['time']-cur_df['time']%args.temporal\n",
    "            df_list.append(cur_df)\n",
    "\n",
    "        print('Done reading compound dataframes')\n",
    "        complete_df=pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "        if args.temporal!=10:\n",
    "            complete_df=complete_df.groupby(['modifier','head','time','context'])['count'].sum().to_frame().reset_index()\n",
    "        \n",
    "        print(\"Saving file\")\n",
    "        complete_df.to_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "    \n",
    "    reduced_complete_df=complete_df.loc[(complete_df.modifier.isin(unique_mod_list))&(complete_df['head'].isin(unique_head_list))]            \n",
    "    return reduced_complete_df\n",
    "\n",
    "\n",
    "def process_decades_constituent(dec_list,input_dir,unique_constituent_list,ctype='word'):\n",
    "        \n",
    "    if os.path.exists(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\"):\n",
    "        print('Reading file')\n",
    "        complete_df=pd.read_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "    elif os.path.exists(f\"{input_dir}/{ctype}s/10_{dec_list[0]}_{tag_str}.pkl\") and args.temporal!=10000:\n",
    "        print(f'Reading decades file {ctype}s/10_{dec_list[0]}_{tag_str}.pkl')\n",
    "        complete_df=pd.read_pickle(f\"{input_dir}/{ctype}s/10_{dec_list[0]}_{tag_str}.pkl\")\n",
    "        \n",
    "        print(f'Reducing to {args.temporal}')\n",
    "        complete_df['time']=complete_df['time']-complete_df['time']%args.temporal\n",
    "        complete_df=complete_df.groupby([ctype,'time','context'])['count'].sum().to_frame().reset_index()\n",
    "        \n",
    "        print(\"Saving file\")\n",
    "        complete_df.to_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        df_list=[]\n",
    "\n",
    "        for dec in dec_list:\n",
    "            cur_df=pd.read_pickle(f'{input_dir}/{ctype}s/{dec}.pkl')\n",
    "            if not args.tag:\n",
    "                cur_df=constituent_tag_remover(cur_df,ctype)\n",
    "            cur_df['time']=dec\n",
    "            cur_df['time']=cur_df['time']-cur_df['time']%args.temporal\n",
    "            df_list.append(cur_df)\n",
    "\n",
    "        print(f'Done reading {ctype} dataframes')\n",
    "        complete_df=pd.concat(df_list,ignore_index=True)\n",
    "        \n",
    "        if args.temporal!=10:\n",
    "            complete_df=complete_df.groupby([ctype,'time','context'])['count'].sum().to_frame().reset_index()\n",
    "        \n",
    "        print(\"Saving file\")\n",
    "        complete_df.to_pickle(f\"{input_dir}/{ctype}s/{args.temporal}_{dec_list[0]}_{tag_str}.pkl\")\n",
    "\n",
    "    if ctype=='modifier':\n",
    "        reduced_complete_df=complete_df.loc[complete_df.modifier.isin(unique_constituent_list)]\n",
    "    elif ctype=='head':\n",
    "        reduced_complete_df=complete_df.loc[complete_df['head'].isin(unique_constituent_list)]\n",
    "    else:\n",
    "        reduced_complete_df=complete_df.loc[complete_df.word.isin(unique_constituent_list)]\n",
    "\n",
    "    return reduced_complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compound_tag_remover(compounds):\n",
    "    \n",
    "    print('Removing tags for compound dataset')\n",
    "    compounds['head']=compounds['head'].str.replace('_NOUN|_PROPN','',regex=True)\n",
    "    compounds.modifier=compounds.modifier.str.replace('_NOUN|_PROPN|_ADJ','',regex=True)\n",
    "    \n",
    "    compounds=compounds.groupby(['modifier','head','context'])['count'].sum().to_frame().reset_index()\n",
    "\n",
    "    return compounds\n",
    "\n",
    "\n",
    "def constituent_tag_remover(constituents,ctype='word'):\n",
    "    \n",
    "    print(f'Removing tags for {ctype} dataset')\n",
    "    constituents[ctype]=constituents[ctype].str.replace('_NOUN|_PROPN|_ADJ','',regex=True)\n",
    "    \n",
    "    constituents=constituents.groupby([ctype,'context'])['count'].sum().to_frame().reset_index()\n",
    "\n",
    "    return constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cutoff_compound(df):\n",
    "\n",
    "    df=df.loc[df.groupby(['modifier','head','time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def process_cutoff_constituent(df,ctype='word'):\n",
    "\n",
    "    df=df.loc[df.groupby([ctype,'time'])['count'].transform('sum').gt(args.cutoff)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ppmi(ppmi_df):\n",
    "    \n",
    "    ppmi_cols=ppmi_df.columns.tolist()\n",
    "    ppmi_cols=['XY' if 'count' in x else x for x in ppmi_cols]\n",
    "    ppmi_df.columns=ppmi_cols\n",
    "\n",
    "    ppmi_time_counts=ppmi_df.groupby('time')['XY'].sum().to_frame()\n",
    "    ppmi_time_counts.columns=['N']\n",
    "\n",
    "\n",
    "    Y_star=ppmi_df.groupby(['context','time'])['XY'].sum().to_frame()\n",
    "    Y_star.columns=['Y']\n",
    "\n",
    "    ppmi_df=pd.merge(ppmi_df,Y_star.reset_index(),on=['context','time'])\n",
    "    \n",
    "    X_cols=[x for x in ppmi_cols if x not in ['context','XY'] ]\n",
    "\n",
    "\n",
    "    X_star=ppmi_df.groupby(X_cols)['XY'].sum().to_frame()\n",
    "    X_star.columns=['X']\n",
    "\n",
    "    ppmi_df=pd.merge(ppmi_df,X_star.reset_index(),on=X_cols)\n",
    "    ppmi_df=pd.merge(ppmi_df,ppmi_time_counts.reset_index(),on=['time'])\n",
    "    ppmi_df['count']=np.log2((ppmi_df['XY']*ppmi_df['N'])/(ppmi_df['X']*ppmi_df['Y']))\n",
    "    ppmi_df=ppmi_df.loc[ppmi_df['count']>=0]\n",
    "    ppmi_df.drop(['XY','X','Y','N'],axis=1,inplace=True)\n",
    "    \n",
    "    return ppmi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_comp_ratings(features_df):\n",
    "\n",
    "    features_df=pd.pivot_table(features_df, index=['modifier','head'], columns=['time'])\n",
    "    features_df_columns_1=features_df.columns.get_level_values(0)\n",
    "    features_df_columns_2=features_df.columns.get_level_values(1)\n",
    "\n",
    "    cur_year=0\n",
    "    new_columns=[]\n",
    "    for year in features_df_columns_2:\n",
    "        new_columns.append(features_df_columns_1[cur_year]+\":\"+str(year))\n",
    "        cur_year+=1\n",
    "\n",
    "    features_df.columns=new_columns\n",
    "    cur_ratings_df_na=features_df.reset_index().merge(comp_ratings_df,on=['modifier','head'])\n",
    "\n",
    "\n",
    "    imputer= SimpleImputer(strategy=\"median\")\n",
    "    df_med=pd.DataFrame(imputer.fit_transform(features_df))\n",
    "    df_med.columns=features_df.columns\n",
    "    df_med.index=features_df.index\n",
    "\n",
    "    cur_ratings_df_med=df_med.reset_index().merge(comp_ratings_df,on=['modifier','head'])\n",
    "    \n",
    "    return cur_ratings_df_na,cur_ratings_df_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10_0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dec_list=[[1820,1830,1840,1850,1860,1870,1880,1890],[1900,1910,1920,1930,1940,1950,1960,1970,1980,1990],[2000,2010]]\n",
    "    \n",
    "    \n",
    "if args.ppmi:\n",
    "    ppmi_str=\"PPMI\"\n",
    "else:\n",
    "    ppmi_str=\"RAW\"\n",
    "    \n",
    "if args.tag:\n",
    "    tag_str='Tagged'\n",
    "else:\n",
    "    tag_str='UnTagged'\n",
    "    \n",
    "temp_cutoff_str=str(args.temporal)+'_'+str(args.cutoff)\n",
    "temp_cutoff_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    unique_mod_list=comp_ratings_df[['modifier']].drop_duplicates()['modifier'].to_list()\n",
    "    unique_head_list=comp_ratings_df[['head']].drop_duplicates()['head'].to_list() \n",
    "    unique_constituent_list=list(set(unique_mod_list+unique_head_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dec list [1820, 1830, 1840, 1850, 1860, 1870, 1880, 1890]\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Current dec list [1900, 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990]\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Current dec list [2000, 2010]\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n",
      "Reading file\n"
     ]
    }
   ],
   "source": [
    "compounds_agnostic_list=[]\n",
    "constituents_list=[]\n",
    "compounds_aware_list=[]\n",
    "modifiers_aware_list=[]\n",
    "heads_aware_list=[]\n",
    "for dec_list in total_dec_list:\n",
    "    \n",
    "    print(f'Current dec list {dec_list}')\n",
    "    \n",
    "    cur_compounds_agnostic=process_decades_compound(dec_list,f'{args.inputdir}',unique_mod_list,unique_head_list,ctype=\"phrase\")\n",
    "    cur_constituents=process_decades_constituent(dec_list,f'{args.inputdir}',unique_constituent_list,ctype='word')\n",
    "    \n",
    "    cur_compounds_aware=process_decades_compound(dec_list,f'{args.inputdir}',unique_mod_list,unique_head_list,ctype=\"compound\")\n",
    "\n",
    "    cur_modifiers_aware=process_decades_constituent(dec_list,f'{args.inputdir}',unique_mod_list,ctype='modifier')\n",
    "\n",
    "    cur_heads_aware=process_decades_constituent(dec_list,f'{args.inputdir}',unique_head_list,ctype='head')\n",
    "    \n",
    "    compounds_agnostic_list.append(cur_compounds_agnostic)\n",
    "    constituents_list.append(cur_constituents)\n",
    "    \n",
    "    compounds_aware_list.append(cur_compounds_aware)\n",
    "    modifiers_aware_list.append(cur_modifiers_aware)\n",
    "    heads_aware_list.append(cur_heads_aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds_agnostic=pd.concat(compounds_agnostic_list,ignore_index=True)\n",
    "constituents=pd.concat(constituents_list,ignore_index=True)\n",
    "\n",
    "compounds_aware=pd.concat(compounds_aware_list,ignore_index=True)\n",
    "modifiers_aware=pd.concat(modifiers_aware_list,ignore_index=True)\n",
    "heads_aware=pd.concat(heads_aware_list,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cut-off applied\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    if args.cutoff==0:\n",
    "        print('No cut-off applied')          \n",
    "    else:\n",
    "        print(f'Cut-off: {args.cutoff}')\n",
    "        print(compounds_aware)\n",
    "\n",
    "        compounds_aware=process_cutoff_compound(compounds_aware)\n",
    "        \n",
    "        print(compounds_aware)\n",
    "\n",
    "        print(compounds_agnostic)\n",
    "\n",
    "        compounds_agnostic=process_cutoff_compound(compounds_agnostic)\n",
    "        \n",
    "        print(compounds_agnostic)\n",
    "\n",
    "        \n",
    "        constituents=process_cutoff_constituent(constituents,ctype='word')\n",
    "        modifiers_aware=process_cutoff_constituent(modifiers_aware,ctype='modifier')\n",
    "        heads_aware=process_cutoff_constituent(heads_aware,ctype='head')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating features\n",
      "CompoundAware features\n"
     ]
    }
   ],
   "source": [
    "    if args.ppmi:\n",
    "        print('Applying PPMI')\n",
    "        compounds_aware=ppmi(compounds_aware)\n",
    "        modifiers_aware=ppmi(modifiers_aware)\n",
    "        heads_aware=ppmi(heads_aware)\n",
    "                        \n",
    "        compounds_agnostic=ppmi(compounds_agnostic)\n",
    "        constituents=ppmi(constituents)\n",
    "    timespan_list_aware_df=pd.DataFrame(compounds_aware.time.unique())\n",
    "    timespan_list_aware_df.columns=['time']\n",
    "\n",
    "    compound_list_aware_df=comp_ratings_df[['modifier','head']].copy()\n",
    "    compound_list_aware_df=compound_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "\n",
    "    modifier_list_aware_df=comp_ratings_df[['modifier']].drop_duplicates().copy()\n",
    "    modifier_list_aware_df=modifier_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "\n",
    "    head_list_aware_df=comp_ratings_df[['head']].drop_duplicates().copy()\n",
    "    head_list_aware_df=head_list_aware_df.merge(timespan_list_aware_df,how='cross')\n",
    "            \n",
    "    all_comps_aware=compounds_aware[['modifier','head','time']].copy()\n",
    "    all_comps_aware.drop_duplicates(inplace=True)\n",
    "           \n",
    "    all_mods_aware=compounds_aware[['modifier','time']].copy()\n",
    "    all_mods_aware.drop_duplicates(inplace=True)\n",
    "            \n",
    "    all_heads_aware=compounds_aware[['head','time']].copy()\n",
    "    all_heads_aware.drop_duplicates(inplace=True)\n",
    "            \n",
    "    not_found_compounds_aware_df=compound_list_aware_df.merge(all_comps_aware, on=['modifier','head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_compounds_aware_df=not_found_compounds_aware_df.loc[not_found_compounds_aware_df['_merge']=='left_only']\n",
    "    not_found_compounds_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "            \n",
    "    not_found_modifiers_aware_df=modifier_list_aware_df.merge(all_mods_aware, on=['modifier','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_modifiers_aware_df=not_found_modifiers_aware_df.loc[not_found_modifiers_aware_df['_merge']=='left_only']\n",
    "    not_found_modifiers_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "    not_found_heads_aware_df=head_list_aware_df.merge(all_heads_aware, on=['head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_heads_aware_df=not_found_heads_aware_df.loc[not_found_heads_aware_df['_merge']=='left_only']\n",
    "    not_found_heads_aware_df.drop('_merge',axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    timespan_list_agnostic_df=pd.DataFrame(compounds_agnostic.time.unique())\n",
    "    timespan_list_agnostic_df.columns=['time']\n",
    "\n",
    "    compound_list_agnostic_df=comp_ratings_df[['modifier','head']].copy()\n",
    "    compound_list_agnostic_df=compound_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "\n",
    "    modifier_list_agnostic_df=comp_ratings_df[['modifier']].drop_duplicates().copy()\n",
    "    modifier_list_agnostic_df=modifier_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "\n",
    "    head_list_agnostic_df=comp_ratings_df[['head']].drop_duplicates().copy()\n",
    "    head_list_agnostic_df=head_list_agnostic_df.merge(timespan_list_agnostic_df,how='cross')\n",
    "            \n",
    "    all_comps_agnostic=compounds_agnostic[['modifier','head','time']].copy()\n",
    "    all_comps_agnostic.drop_duplicates(inplace=True)\n",
    "           \n",
    "    all_mods_agnostic=compounds_agnostic[['modifier','time']].copy()\n",
    "    all_mods_agnostic.drop_duplicates(inplace=True)\n",
    "            \n",
    "    all_heads_agnostic=compounds_agnostic[['head','time']].copy()\n",
    "    all_heads_agnostic.drop_duplicates(inplace=True)\n",
    "            \n",
    "    not_found_compounds_agnostic_df=compound_list_agnostic_df.merge(all_comps_agnostic, on=['modifier','head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_compounds_agnostic_df=not_found_compounds_agnostic_df.loc[not_found_compounds_agnostic_df['_merge']=='left_only']\n",
    "    not_found_compounds_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "                    \n",
    "    not_found_modifiers_agnostic_df=modifier_list_agnostic_df.merge(all_mods_agnostic, on=['modifier','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_modifiers_agnostic_df=not_found_modifiers_agnostic_df.loc[not_found_modifiers_agnostic_df['_merge']=='left_only']\n",
    "    not_found_modifiers_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "            \n",
    "    not_found_heads_agnostic_df=head_list_agnostic_df.merge(all_heads_agnostic, on=['head','time'], how='outer', suffixes=['', '_'], indicator=True)\n",
    "    not_found_heads_agnostic_df=not_found_heads_agnostic_df.loc[not_found_heads_agnostic_df['_merge']=='left_only']\n",
    "    not_found_heads_agnostic_df.drop('_merge',axis=1,inplace=True)\n",
    "    \n",
    "    compounds_aware=compounds_aware.merge(comp_ratings_df[['modifier','head']],on=['modifier','head'])\n",
    "\n",
    "    compounds_agnostic=compounds_agnostic.merge(comp_ratings_df[['modifier','head']],on=['modifier','head'])\n",
    "\n",
    "    heads_agnostic=constituents.copy()\n",
    "    heads_agnostic_cols=heads_agnostic.columns\n",
    "    heads_agnostic_cols=['head' if 'word' in x else x for x in heads_agnostic_cols]\n",
    "    heads_agnostic.columns=heads_agnostic_cols\n",
    "    heads_agnostic=heads_agnostic.loc[heads_agnostic['head'].isin(unique_head_list)]\n",
    "\n",
    "\n",
    "    modifiers_agnostic=constituents.copy()\n",
    "    modifiers_agnostic_cols=modifiers_agnostic.columns\n",
    "    modifiers_agnostic_cols=['modifier' if 'word' in x else x for x in modifiers_agnostic_cols]\n",
    "    modifiers_agnostic.columns=modifiers_agnostic_cols\n",
    "    modifiers_agnostic=modifiers_agnostic.loc[modifiers_agnostic.modifier.isin(unique_mod_list)]\n",
    "    \n",
    "    print('Calculating features')\n",
    "    \n",
    "\n",
    "    \n",
    "    print('CompoundAware features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_bw_rows(df):\n",
    "    df_orig=df.copy()\n",
    "    df_shifted=df.shift().copy()\n",
    "    denom_df_orig=(df_orig**2).sum(axis=1)\n",
    "    denom_df_shifted=(df_shifted**2).sum(axis=1)\n",
    "    denominator=np.sqrt(denom_df_orig*denom_df_shifted)\n",
    "    numerator=(df_orig*df_shifted).sum(axis=1)\n",
    "    if df.index.nlevels==3:\n",
    "        cosine_sim_df=(numerator/denominator).reset_index(level=[0,1],drop=True)\n",
    "    else:\n",
    "        cosine_sim_df=(numerator/denominator).reset_index(level=[0],drop=True)        \n",
    "    cosine_sim_df.dropna(inplace=True)\n",
    "    cosine_sim_df=cosine_sim_df.to_frame()\n",
    "    return cosine_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_features(compounds,modifiers,heads,compound_list_df):\n",
    "    \n",
    "    compounds_pivot=pd.pivot_table(compounds, values='count', index=['modifier','head', 'time'],\n",
    "                       columns=['context'], aggfunc=\"sum\",fill_value=0)\n",
    "    modifiers_pivot=pd.pivot_table(modifiers, values='count', index=['modifier','time'],\n",
    "                       columns=['context'], aggfunc=\"sum\",fill_value=0)\n",
    "    heads_pivot=pd.pivot_table(heads, values='count', index=['head','time'],\n",
    "                       columns=['context'], aggfunc=\"sum\",fill_value=0)\n",
    "    \n",
    "    change_compounds_df=compounds_pivot.groupby(level=[0,1]).apply(cosine_bw_rows)\n",
    "    change_compounds_df.columns=['change_comp']\n",
    "\n",
    "    change_modifiers_df=modifiers_pivot.groupby(level=[0]).apply(cosine_bw_rows)\n",
    "    change_modifiers_df.columns=['change_mod']\n",
    "    change_heads_df=heads_pivot.groupby(level=[0]).apply(cosine_bw_rows)\n",
    "    change_heads_df.columns=['change_head']\n",
    "    \n",
    "    \n",
    "    changed_df=pd.merge(change_compounds_df.reset_index(),compound_list_df,on=['modifier','head','time'],how='right')\n",
    "    changed_df=pd.merge(changed_df,change_modifiers_df.reset_index(),on=['modifier','time'],how='right')\n",
    "    \n",
    "    changed_df=pd.merge(changed_df,change_heads_df.reset_index(),on=['head','time'])\n",
    "    return changed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifier</th>\n",
       "      <th>time</th>\n",
       "      <th>perc_token_modifier</th>\n",
       "      <th>perc_type_modifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy</td>\n",
       "      <td>1820</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.034500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academy</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.041901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academy</td>\n",
       "      <td>1840</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.052464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academy</td>\n",
       "      <td>1850</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.073388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy</td>\n",
       "      <td>1860</td>\n",
       "      <td>0.015582</td>\n",
       "      <td>0.086483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>zebra</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.244970</td>\n",
       "      <td>0.297218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>zebra</td>\n",
       "      <td>1980</td>\n",
       "      <td>0.449932</td>\n",
       "      <td>0.419554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>zebra</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.607710</td>\n",
       "      <td>0.491024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>zebra</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.502937</td>\n",
       "      <td>0.453294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>zebra</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.369851</td>\n",
       "      <td>0.446516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4837 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     modifier  time  perc_token_modifier  perc_type_modifier\n",
       "0     academy  1820             0.003118            0.034500\n",
       "1     academy  1830             0.003979            0.041901\n",
       "2     academy  1840             0.005512            0.052464\n",
       "3     academy  1850             0.010834            0.073388\n",
       "4     academy  1860             0.015582            0.086483\n",
       "...       ...   ...                  ...                 ...\n",
       "4832    zebra  1970             0.244970            0.297218\n",
       "4833    zebra  1980             0.449932            0.419554\n",
       "4834    zebra  1990             0.607710            0.491024\n",
       "4835    zebra  2000             0.502937            0.453294\n",
       "4836    zebra  2010             0.369851            0.446516\n",
       "\n",
       "[4837 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_modifiers_features_df=(modifiers_aware.groupby(['modifier','time'])['count'].agg(perc_token_modifier='sum', perc_type_modifier='size')/modifiers_agnostic.groupby(['modifier','time'])['count'].agg(perc_token_modifier='sum', perc_type_modifier='size')).reset_index()\n",
    "num_modifiers_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>time</th>\n",
       "      <th>perc_token_head</th>\n",
       "      <th>perc_type_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>account</td>\n",
       "      <td>1820</td>\n",
       "      <td>0.273542</td>\n",
       "      <td>0.301059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>account</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.267762</td>\n",
       "      <td>0.317516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account</td>\n",
       "      <td>1840</td>\n",
       "      <td>0.272242</td>\n",
       "      <td>0.319656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>account</td>\n",
       "      <td>1850</td>\n",
       "      <td>0.267778</td>\n",
       "      <td>0.329674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>account</td>\n",
       "      <td>1860</td>\n",
       "      <td>0.269994</td>\n",
       "      <td>0.329282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>year</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.399238</td>\n",
       "      <td>0.639785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>year</td>\n",
       "      <td>1980</td>\n",
       "      <td>0.381366</td>\n",
       "      <td>0.635348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>year</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.363366</td>\n",
       "      <td>0.634835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>year</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.351876</td>\n",
       "      <td>0.637860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>year</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.313654</td>\n",
       "      <td>0.636292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4894 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         head  time  perc_token_head  perc_type_head\n",
       "0     account  1820         0.273542        0.301059\n",
       "1     account  1830         0.267762        0.317516\n",
       "2     account  1840         0.272242        0.319656\n",
       "3     account  1850         0.267778        0.329674\n",
       "4     account  1860         0.269994        0.329282\n",
       "...       ...   ...              ...             ...\n",
       "4889     year  1970         0.399238        0.639785\n",
       "4890     year  1980         0.381366        0.635348\n",
       "4891     year  1990         0.363366        0.634835\n",
       "4892     year  2000         0.351876        0.637860\n",
       "4893     year  2010         0.313654        0.636292\n",
       "\n",
       "[4894 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads_features_df=(heads_aware.groupby(['head','time'])['count'].agg(perc_token_head='sum', perc_type_head='size')/heads_agnostic.groupby(['head','time'])['count'].agg(perc_token_head='sum', perc_type_head='size')).reset_index()\n",
    "num_heads_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        modifier        head  perc_token_comp:1820  perc_token_comp:1830  \\\n",
       " 0        academy       award                   NaN              0.515152   \n",
       " 1           acid        test              1.000000              0.909091   \n",
       " 2          agony        aunt                   NaN                   NaN   \n",
       " 3        ancient     history              0.997131              0.994727   \n",
       " 4    application        form              1.000000              0.926680   \n",
       " ..           ...         ...                   ...                   ...   \n",
       " 278        white      spirit              0.946360              0.834395   \n",
       " 279       winter    solstice              1.000000              1.000000   \n",
       " 280         word    painting                   NaN                   NaN   \n",
       " 281        world  conference              1.000000                   NaN   \n",
       " 282        zebra    crossing                   NaN                   NaN   \n",
       " \n",
       "      perc_token_comp:1840  perc_token_comp:1850  perc_token_comp:1860  \\\n",
       " 0                     NaN                   NaN                   NaN   \n",
       " 1                0.557823              0.843658              0.735714   \n",
       " 2                     NaN                   NaN                   NaN   \n",
       " 3                0.993532              0.994004              0.991248   \n",
       " 4                0.943396              0.975845              0.989336   \n",
       " ..                    ...                   ...                   ...   \n",
       " 278              0.957655              0.956989              0.923387   \n",
       " 279              1.000000              1.000000              0.999359   \n",
       " 280              1.000000              1.000000              1.000000   \n",
       " 281              1.000000              0.666667              0.666667   \n",
       " 282                   NaN                   NaN                   NaN   \n",
       " \n",
       "      perc_token_comp:1870  perc_token_comp:1880  perc_token_comp:1890  ...  \\\n",
       " 0                0.791667              1.000000              1.000000  ...   \n",
       " 1                0.501795              0.465191              0.595886  ...   \n",
       " 2                     NaN                   NaN                   NaN  ...   \n",
       " 3                0.990481              0.990166              0.990183  ...   \n",
       " 4                0.993808              0.979484              0.968750  ...   \n",
       " ..                    ...                   ...                   ...  ...   \n",
       " 278              0.835000              0.925072              0.926554  ...   \n",
       " 279              1.000000              0.993035              0.977762  ...   \n",
       " 280              1.000000              1.000000              1.000000  ...   \n",
       " 281              1.000000              0.971429              1.000000  ...   \n",
       " 282                   NaN                   NaN                   NaN  ...   \n",
       " \n",
       "      perc_type_modifier:2010  avgModifier  stdevModifier   avgHead  stdevHead  \\\n",
       " 0                   0.170736     3.130400       1.632200  4.695700   0.764800   \n",
       " 1                   0.555842     0.714286       1.097307  3.896552   1.241379   \n",
       " 2                   0.044977     1.862069       1.224017  0.433333   0.558768   \n",
       " 3                   0.819059     2.000000       1.527500  2.842100   2.115100   \n",
       " 4                   0.178305     4.766667       0.422953  4.862069   0.344828   \n",
       " ..                       ...          ...            ...       ...        ...   \n",
       " 278                 0.813871     1.538500       1.240300  2.038500   1.949000   \n",
       " 279                 0.587605     5.000000       0.000000  4.681800   1.086100   \n",
       " 280                 0.302789     3.187500       1.558600  0.437500   0.727400   \n",
       " 281                 0.404139     3.875000       1.361300  4.291700   1.267600   \n",
       " 282                 0.446516     0.758621       0.624509  4.607143   0.859372   \n",
       " \n",
       "      compositionality  stdevHeadModifier  is_adj          compound  \\\n",
       " 0            3.521700           1.473100   False     academy_award   \n",
       " 1            1.222222           1.257079   False         acid_test   \n",
       " 2            0.758621           0.857228   False        agony_aunt   \n",
       " 3            1.947400           1.580200    True   ancient_history   \n",
       " 4            4.800000           0.476095   False  application_form   \n",
       " ..                ...                ...     ...               ...   \n",
       " 278          1.307700           1.257600    True      white_spirit   \n",
       " 279          4.545500           1.335500   False   winter_solstice   \n",
       " 280          1.625000           1.310200   False     word_painting   \n",
       " 281          3.958300           1.366700   False  world_conference   \n",
       " 282          1.250000           1.022078   False    zebra_crossing   \n",
       " \n",
       "           source  \n",
       " 0    cordeiro100  \n",
       " 1          reddy  \n",
       " 2          reddy  \n",
       " 3     cordeiro90  \n",
       " 4          reddy  \n",
       " ..           ...  \n",
       " 278  cordeiro100  \n",
       " 279  cordeiro100  \n",
       " 280   cordeiro90  \n",
       " 281  cordeiro100  \n",
       " 282        reddy  \n",
       " \n",
       " [283 rows x 131 columns],\n",
       "         modifier        head  perc_token_comp:1820  perc_token_comp:1830  \\\n",
       " 0        academy       award              1.000000              0.515152   \n",
       " 1           acid        test              1.000000              0.909091   \n",
       " 2          agony        aunt              1.000000              0.994238   \n",
       " 3        ancient     history              0.997131              0.994727   \n",
       " 4    application        form              1.000000              0.926680   \n",
       " ..           ...         ...                   ...                   ...   \n",
       " 278        white      spirit              0.946360              0.834395   \n",
       " 279       winter    solstice              1.000000              1.000000   \n",
       " 280         word    painting              1.000000              0.994238   \n",
       " 281        world  conference              1.000000              0.994238   \n",
       " 282        zebra    crossing              1.000000              0.994238   \n",
       " \n",
       "      perc_token_comp:1840  perc_token_comp:1850  perc_token_comp:1860  \\\n",
       " 0                0.994959              0.996805              0.994069   \n",
       " 1                0.557823              0.843658              0.735714   \n",
       " 2                0.994959              0.996805              0.994069   \n",
       " 3                0.993532              0.994004              0.991248   \n",
       " 4                0.943396              0.975845              0.989336   \n",
       " ..                    ...                   ...                   ...   \n",
       " 278              0.957655              0.956989              0.923387   \n",
       " 279              1.000000              1.000000              0.999359   \n",
       " 280              1.000000              1.000000              1.000000   \n",
       " 281              1.000000              0.666667              0.666667   \n",
       " 282              0.994959              0.996805              0.994069   \n",
       " \n",
       "      perc_token_comp:1870  perc_token_comp:1880  perc_token_comp:1890  ...  \\\n",
       " 0                0.791667              1.000000              1.000000  ...   \n",
       " 1                0.501795              0.465191              0.595886  ...   \n",
       " 2                0.993247              0.992490              0.988544  ...   \n",
       " 3                0.990481              0.990166              0.990183  ...   \n",
       " 4                0.993808              0.979484              0.968750  ...   \n",
       " ..                    ...                   ...                   ...  ...   \n",
       " 278              0.835000              0.925072              0.926554  ...   \n",
       " 279              1.000000              0.993035              0.977762  ...   \n",
       " 280              1.000000              1.000000              1.000000  ...   \n",
       " 281              1.000000              0.971429              1.000000  ...   \n",
       " 282              0.993247              0.992490              0.988544  ...   \n",
       " \n",
       "      perc_type_modifier:2010  avgModifier  stdevModifier   avgHead  stdevHead  \\\n",
       " 0                   0.170736     3.130400       1.632200  4.695700   0.764800   \n",
       " 1                   0.555842     0.714286       1.097307  3.896552   1.241379   \n",
       " 2                   0.044977     1.862069       1.224017  0.433333   0.558768   \n",
       " 3                   0.819059     2.000000       1.527500  2.842100   2.115100   \n",
       " 4                   0.178305     4.766667       0.422953  4.862069   0.344828   \n",
       " ..                       ...          ...            ...       ...        ...   \n",
       " 278                 0.813871     1.538500       1.240300  2.038500   1.949000   \n",
       " 279                 0.587605     5.000000       0.000000  4.681800   1.086100   \n",
       " 280                 0.302789     3.187500       1.558600  0.437500   0.727400   \n",
       " 281                 0.404139     3.875000       1.361300  4.291700   1.267600   \n",
       " 282                 0.446516     0.758621       0.624509  4.607143   0.859372   \n",
       " \n",
       "      compositionality  stdevHeadModifier  is_adj          compound  \\\n",
       " 0            3.521700           1.473100   False     academy_award   \n",
       " 1            1.222222           1.257079   False         acid_test   \n",
       " 2            0.758621           0.857228   False        agony_aunt   \n",
       " 3            1.947400           1.580200    True   ancient_history   \n",
       " 4            4.800000           0.476095   False  application_form   \n",
       " ..                ...                ...     ...               ...   \n",
       " 278          1.307700           1.257600    True      white_spirit   \n",
       " 279          4.545500           1.335500   False   winter_solstice   \n",
       " 280          1.625000           1.310200   False     word_painting   \n",
       " 281          3.958300           1.366700   False  world_conference   \n",
       " 282          1.250000           1.022078   False    zebra_crossing   \n",
       " \n",
       "           source  \n",
       " 0    cordeiro100  \n",
       " 1          reddy  \n",
       " 2          reddy  \n",
       " 3     cordeiro90  \n",
       " 4          reddy  \n",
       " ..           ...  \n",
       " 278  cordeiro100  \n",
       " 279  cordeiro100  \n",
       " 280   cordeiro90  \n",
       " 281  cordeiro100  \n",
       " 282        reddy  \n",
       " \n",
       " [283 rows x 131 columns])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_compounds_features_df=(compounds_aware.groupby(['modifier','head','time'])['count'].agg(perc_token_comp='sum', perc_type_comp='size')/compounds_agnostic.groupby(['modifier','head','time'])['count'].agg(perc_token_comp='sum', perc_type_comp='size')).reset_index()\n",
    "num_compounds_features_df=pd.merge(num_compounds_features_df,num_modifiers_features_df,on=['modifier','time'])\n",
    "num_compounds_features_df=pd.merge(num_compounds_features_df,num_heads_features_df,on=['head','time'])\n",
    "merge_comp_ratings(num_compounds_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       modifier     head  time  change_comp  change_mod\n",
      "0       academy    award  1830          NaN    0.310599\n",
      "1       academy     land  1830          NaN    0.310599\n",
      "2       academy      lot  1830          NaN    0.310599\n",
      "3       academy  picture  1830          NaN    0.310599\n",
      "4       academy     room  1830          NaN    0.310599\n",
      "...         ...      ...   ...          ...         ...\n",
      "283569    zebra    horse  2010          NaN    0.960327\n",
      "283570    zebra     line  2010          NaN    0.960327\n",
      "283571    zebra    print  2010          NaN    0.960327\n",
      "283572    zebra    shark  2010          NaN    0.960327\n",
      "283573    zebra    study  2010          NaN    0.960327\n",
      "\n",
      "[283574 rows x 5 columns]\n",
      "          modifier      head  time  change_comp  change_mod  change_head\n",
      "0          academy     award  1830          NaN    0.310599     0.918114\n",
      "1            blind     award  1830          NaN    0.995921     0.918114\n",
      "2             case     award  1830          NaN    0.848085     0.918114\n",
      "3             cash     award  1830          NaN    0.907187     0.918114\n",
      "4       disability     award  1830          NaN    0.349618     0.918114\n",
      "...            ...       ...   ...          ...         ...          ...\n",
      "279397      winter  solstice  1900     0.970616    0.995596     0.999839\n",
      "279398        word  solstice  1900          NaN    0.960697     0.999839\n",
      "279399      winter  solstice  1910     0.983041    0.985240     0.999717\n",
      "279400        word  solstice  1910          NaN    0.940345     0.999717\n",
      "279401        word     phone  1850          NaN    0.981061     0.910776\n",
      "\n",
      "[279402 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "      <th>time</th>\n",
       "      <th>change_comp</th>\n",
       "      <th>change_mod</th>\n",
       "      <th>change_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310599</td>\n",
       "      <td>0.918114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blind</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995921</td>\n",
       "      <td>0.918114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848085</td>\n",
       "      <td>0.918114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cash</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907187</td>\n",
       "      <td>0.918114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disability</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.349618</td>\n",
       "      <td>0.918114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279397</th>\n",
       "      <td>winter</td>\n",
       "      <td>solstice</td>\n",
       "      <td>1900</td>\n",
       "      <td>0.970616</td>\n",
       "      <td>0.995596</td>\n",
       "      <td>0.999839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279398</th>\n",
       "      <td>word</td>\n",
       "      <td>solstice</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960697</td>\n",
       "      <td>0.999839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279399</th>\n",
       "      <td>winter</td>\n",
       "      <td>solstice</td>\n",
       "      <td>1910</td>\n",
       "      <td>0.983041</td>\n",
       "      <td>0.985240</td>\n",
       "      <td>0.999717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279400</th>\n",
       "      <td>word</td>\n",
       "      <td>solstice</td>\n",
       "      <td>1910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.940345</td>\n",
       "      <td>0.999717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279401</th>\n",
       "      <td>word</td>\n",
       "      <td>phone</td>\n",
       "      <td>1850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>0.910776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279402 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          modifier      head  time  change_comp  change_mod  change_head\n",
       "0          academy     award  1830          NaN    0.310599     0.918114\n",
       "1            blind     award  1830          NaN    0.995921     0.918114\n",
       "2             case     award  1830          NaN    0.848085     0.918114\n",
       "3             cash     award  1830          NaN    0.907187     0.918114\n",
       "4       disability     award  1830          NaN    0.349618     0.918114\n",
       "...            ...       ...   ...          ...         ...          ...\n",
       "279397      winter  solstice  1900     0.970616    0.995596     0.999839\n",
       "279398        word  solstice  1900          NaN    0.960697     0.999839\n",
       "279399      winter  solstice  1910     0.983041    0.985240     0.999717\n",
       "279400        word  solstice  1910          NaN    0.940345     0.999717\n",
       "279401        word     phone  1850          NaN    0.981061     0.910776\n",
       "\n",
       "[279402 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_aware_df=temporal_features(compounds_aware,modifiers_aware,heads_aware,all_comps_aware)\n",
    "change_aware_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       modifier     head  time  change_comp  change_mod\n",
      "0       academy    award  1830          NaN    0.910445\n",
      "1       academy     land  1830          NaN    0.910445\n",
      "2       academy      lot  1830          NaN    0.910445\n",
      "3       academy  picture  1830          NaN    0.910445\n",
      "4       academy     room  1830          NaN    0.910445\n",
      "...         ...      ...   ...          ...         ...\n",
      "290853    zebra    horse  2010          NaN    0.949693\n",
      "290854    zebra     line  2010          NaN    0.949693\n",
      "290855    zebra    print  2010          NaN    0.949693\n",
      "290856    zebra    shark  2010          NaN    0.949693\n",
      "290857    zebra    study  2010          NaN    0.949693\n",
      "\n",
      "[290858 rows x 5 columns]\n",
      "          modifier      head  time  change_comp  change_mod  change_head\n",
      "0          academy     award  1830          NaN    0.910445     0.981156\n",
      "1            blind     award  1830          NaN    0.993280     0.981156\n",
      "2             case     award  1830          NaN    0.993940     0.981156\n",
      "3             cash     award  1830          NaN    0.821940     0.981156\n",
      "4       disability     award  1830          NaN    0.903540     0.981156\n",
      "...            ...       ...   ...          ...         ...          ...\n",
      "290781      winter  solstice  1900     0.969173    0.993283     0.999591\n",
      "290782        word  solstice  1900          NaN    0.991863     0.999591\n",
      "290783      winter  solstice  1910     0.976609    0.981344     0.999290\n",
      "290784        word  solstice  1910          NaN    0.982114     0.999290\n",
      "290785        word     phone  1850          NaN    0.997557     0.986283\n",
      "\n",
      "[290786 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifier</th>\n",
       "      <th>head</th>\n",
       "      <th>time</th>\n",
       "      <th>change_comp</th>\n",
       "      <th>change_mod</th>\n",
       "      <th>change_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academy</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910445</td>\n",
       "      <td>0.981156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blind</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993280</td>\n",
       "      <td>0.981156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993940</td>\n",
       "      <td>0.981156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cash</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.821940</td>\n",
       "      <td>0.981156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disability</td>\n",
       "      <td>award</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903540</td>\n",
       "      <td>0.981156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290781</th>\n",
       "      <td>winter</td>\n",
       "      <td>solstice</td>\n",
       "      <td>1900</td>\n",
       "      <td>0.969173</td>\n",
       "      <td>0.993283</td>\n",
       "      <td>0.999591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290782</th>\n",
       "      <td>word</td>\n",
       "      <td>solstice</td>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991863</td>\n",
       "      <td>0.999591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290783</th>\n",
       "      <td>winter</td>\n",
       "      <td>solstice</td>\n",
       "      <td>1910</td>\n",
       "      <td>0.976609</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>0.999290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290784</th>\n",
       "      <td>word</td>\n",
       "      <td>solstice</td>\n",
       "      <td>1910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982114</td>\n",
       "      <td>0.999290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290785</th>\n",
       "      <td>word</td>\n",
       "      <td>phone</td>\n",
       "      <td>1850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997557</td>\n",
       "      <td>0.986283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290786 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          modifier      head  time  change_comp  change_mod  change_head\n",
       "0          academy     award  1830          NaN    0.910445     0.981156\n",
       "1            blind     award  1830          NaN    0.993280     0.981156\n",
       "2             case     award  1830          NaN    0.993940     0.981156\n",
       "3             cash     award  1830          NaN    0.821940     0.981156\n",
       "4       disability     award  1830          NaN    0.903540     0.981156\n",
       "...            ...       ...   ...          ...         ...          ...\n",
       "290781      winter  solstice  1900     0.969173    0.993283     0.999591\n",
       "290782        word  solstice  1900          NaN    0.991863     0.999591\n",
       "290783      winter  solstice  1910     0.976609    0.981344     0.999290\n",
       "290784        word  solstice  1910          NaN    0.982114     0.999290\n",
       "290785        word     phone  1850          NaN    0.997557     0.986283\n",
       "\n",
       "[290786 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_agnostic_df=temporal_features(compounds_agnostic,modifiers_agnostic,heads_agnostic,all_comps_agnostic)\n",
    "change_agnostic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/data/dharp/packages/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "cur_ratings_aware_df_na,cur_ratings_aware_df_med=merge_comp_ratings(change_aware_df)\n",
    "cur_ratings_agnostic_df_na,cur_ratings_agnostic_df_med=merge_comp_ratings(change_agnostic_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving feature datasets\n"
     ]
    }
   ],
   "source": [
    "print('Saving feature datasets')\n",
    "\n",
    "\n",
    "cur_ratings_aware_df_na.to_csv(f'{args.outputdir}/temporal_CompoundAware_withSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_na.csv',sep='\\t',index=False)\n",
    "cur_ratings_aware_df_med.to_csv(f'{args.outputdir}/temporal_CompoundAware_withSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_med.csv',sep='\\t',index=False)\n",
    "\n",
    "cur_ratings_agnostic_df_na.to_csv(f'{args.outputdir}/temporal_CompoundAgnostic_withSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_na.csv',sep='\\t',index=False)\n",
    "cur_ratings_agnostic_df_med.to_csv(f'{args.outputdir}/temporal_CompoundAgnostic_withSetting_{ppmi_str}_{tag_str}_{temp_cutoff_str}_med.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/dharp/compounds/datasets/features/'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.outputdir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
