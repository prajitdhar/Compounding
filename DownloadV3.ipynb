{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gentle-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "import fastparquet\n",
    "import spacy\n",
    "import glob, os\n",
    "import re\n",
    "from os.path import isfile\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b36748b5-c74d-46de-b826-808227df3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save_path='/data/dharp/compounds/datasets/'\n",
    "keep_string=r\"(.+_(NOUN|ADV|VERB|ADJ|X|PRT|CONJ|PRON|DET|ADP|NUM|\\.)|_END_)\\s*\"\n",
    "nn='(?!(?:NOUN|PROPN)).*'\n",
    "comp='(?:ADJ|NOUN|PROPN)\\s(?:NOUN|PROPN)'\n",
    "word='.*'\n",
    "ner_cats=['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']\n",
    "n1=f'^{comp}\\s{nn}\\s{comp}$'\n",
    "n2=f'^{comp}\\s{nn}\\s{word}\\s{word}$'\n",
    "n3=f'^{nn}\\s{comp}\\s{nn}\\s{word}$'\n",
    "n4=f'^{word}\\s{nn}\\s{comp}\\s{nn}$'\n",
    "n5=f'^{word}\\s{word}\\s{nn}\\s{comp}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c949e60-8094-4d40-baf8-0a4626abd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = fasttext.load_model('/data/dharp/packages/lid.176.bin')\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e29b5e-3d66-445b-908c-5bd032967ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delist_lang(lst):\n",
    "    lang_lst=[]\n",
    "    for i,lang in enumerate(lst):\n",
    "        if not lang:\n",
    "            lang_lst.append(None)\n",
    "        else:\n",
    "            lang_lst.append(lang[0])\n",
    "    return lang_lst\n",
    "\n",
    "\n",
    "def significance(lst):\n",
    "    significance_list=[]\n",
    "    for l in lst:\n",
    "        if len(l)>1:\n",
    "            significance_list.append(abs(l[0]-l[1])/np.mean(l[0]+l[1])>0.1)\n",
    "            #print(f'{conf[0]} {conf[1]} {abs(conf[0]-conf[1])/np.mean(conf[0]+conf[1])>0.1}')\n",
    "        else:\n",
    "            significance_list.append(True)\n",
    "    return significance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46acc648-edeb-4fb7-a395-a37d20221498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_maker(sent_lst):\n",
    "    ret_sents=[]\n",
    "    g_pos=[]\n",
    "    for sent in sent_lst:\n",
    "        cur_words=[]\n",
    "        pos_sent=[]\n",
    "        sent=sent.replace('_END_','@@@_.')\n",
    "        for word_pos in sent.split(' '):\n",
    "            word,pos=word_pos.rsplit('_',1)\n",
    "            cur_words.append(word)\n",
    "            pos_sent.append(pos)\n",
    "            cur_sent=' '.join(cur_words)\n",
    "            cur_pos=' '.join(pos_sent)\n",
    "        ret_sents.append(cur_sent)\n",
    "        g_pos.append(cur_pos)\n",
    "    return ret_sents,g_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a2701d-072f-45e0-9a17-a59d195c7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_lemma_reducer(sent):\n",
    "    ner_sent=[]\n",
    "    lemma=[]\n",
    "    pos=[]\n",
    "    #parse=[]\n",
    "    is_comp=False\n",
    "    ner_token=[]\n",
    "    ner_length=[]\n",
    "    ner=[]\n",
    "    parsed_sent=nlp(sent)\n",
    "    for token in parsed_sent:\n",
    "        #parse.append(token.text)\n",
    "        lemma.append(token.lemma_)\n",
    "        pos.append(token.pos_)\n",
    "        if token.ent_type_==\"\":\n",
    "            to_add=\"NONNER\"\n",
    "        else:\n",
    "            to_add=token.ent_type_\n",
    "        ner_token.append(to_add)\n",
    "        if token.dep_==\"compound\":\n",
    "            is_comp=True\n",
    "    #print(parse)\n",
    "    #parse_sent=' '.join(parse)\n",
    "    lemma_sent=' '.join(lemma)\n",
    "    pos_sent=' '.join(pos)\n",
    "    ner_token_sent=' '.join(ner_token)\n",
    "    #dep_sent=' '.join(dep)\n",
    "    ner_length=0\n",
    "    if parsed_sent.ents:\n",
    "        for ent in parsed_sent.ents:\n",
    "            #cur_ner=\n",
    "            #cur_ner='_'.join([str(ent.start_char), str(ent.end_char), ent.label_])\n",
    "            ner_length+=ent.end_char-ent.start_char\n",
    "            #ner.append(cur_ner)\n",
    "    #else:\n",
    "        #ner.append(\"\")\n",
    "    ner_sent=' '.join(ner)\n",
    "    \n",
    "    return ner_token_sent,ner_length,lemma_sent,pos_sent,is_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "126db617-df83-47e9-a228-405ee25700b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_tagger(parsed_sent):\n",
    "    labels,confs=fmodel.predict(parsed_sent,k=-1,threshold=0.1)\n",
    "    lang_list=delist_lang(labels)    \n",
    "    significance_list=significance(confs)\n",
    "    assert len(lang_list)==len(significance_list)\n",
    "    return lang_list,significance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d53b63-07d5-43dd-8536-e06ce4fc3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_processor(df):\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    ret_lst=sent_maker(df.old_index)\n",
    "    \n",
    "    df['sent']=ret_lst[0]\n",
    "    df['g_pos']=ret_lst[1]\n",
    "    \n",
    "    results=np.vectorize(ner_lemma_reducer)(df.sent.values)\n",
    "    results_df=pd.DataFrame(results)\n",
    "    results_df=results_df.transpose()\n",
    "    #results_df.columns=ner_token_sent,ner_length,lemma_sent,pos_sent,is_comp\n",
    "    results_df.columns=['ner_token_sent','ner_length','lemma_sent','pos_sent','is_comp']\n",
    "\n",
    "    results_df=results_df.loc[~results_df.ner_token_sent.str.contains(\"PERSON PERSON\")]\n",
    "\n",
    "    index_df=pd.concat([df,results_df],axis=1,ignore_index=False)\n",
    "\n",
    "    lang_list,significance_list=lang_tagger(index_df.sent.values.tolist())\n",
    "    index_df['lang']=lang_list\n",
    "    index_df['lang_conf']=significance_list\n",
    "    index_df.lang=index_df.lang.str.split('_',n=4).str[-1]\n",
    "    index_df=index_df.loc[(index_df.lang=='en') &(index_df.lang_conf==True)]\n",
    "\n",
    "    index_df['nwords']=index_df.pos_sent.str.count(' ').add(1)\n",
    "    index_df=index_df.loc[index_df.nwords==5]\n",
    "    \n",
    "    index_df.lemma_sent=index_df.lemma_sent.str.lower()\n",
    "    #index_df.pos_sent=index_df.pos_sent.str.replace('PROPN','NOUN',regex=False)\n",
    "    #index_df.pos_sent=index_df.pos_sent.str.replace('AUX','VERB',regex=False)\n",
    "    #index_df.pos_sent=index_df.pos_sent.str.replace('CCONJ','CONJ',regex=False)\n",
    "    #index_df.g_pos=index_df.g_pos.str.replace('.','PUNCT',regex=False)\n",
    "    #index_df.g_pos=index_df.g_pos.str.replace('PRT','ADP',regex=False)\n",
    "    if index_df.shape[0]==0:\n",
    "        return index_df\n",
    "    index_df['lemma_pos']=str_joiner(index_df)\n",
    "    index_df['nX']=index_df.pos_sent.str.count('X')-index_df.pos_sent.str.count('AUX')\n",
    "    index_df=index_df.loc[~(index_df.nX>1)]\n",
    "    \n",
    "    index_df['ner_perc']=index_df.ner_length/index_df.sent.str.len()\n",
    "   \n",
    "    index_df['comp_class']=0\n",
    "\n",
    "    index_df.loc[index_df.pos_sent.str.contains(n1),'comp_class']=1\n",
    "    index_df.loc[~(index_df.pos_sent.str.contains(n1))& index_df.pos_sent.str.contains(n2),'comp_class']=2\n",
    "    index_df.loc[index_df.pos_sent.str.contains(n3),'comp_class']=3\n",
    "    index_df.loc[index_df.pos_sent.str.contains(n4),'comp_class']=4\n",
    "    index_df.loc[~(index_df.pos_sent.str.contains(n1))& index_df.pos_sent.str.contains(n5),'comp_class']=5\n",
    "    index_df.drop(['old_index','g_pos','lang','lang_conf','nwords','nX','lemma_sent','ner_length'],axis=1,inplace=True)\n",
    "    index_year_df=year_count_split(index_df)\n",
    "    index_df=index_df.merge(index_year_df, on='lemma_pos',how='right')\n",
    "    index_df=index_df.groupby(['lemma_pos','pos_sent','year','comp_class'])['count'].sum().to_frame().reset_index()\n",
    "    return index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6b7860-c1d3-4fb7-8c4b-63d2dc9cb04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_count_split(df):\n",
    "    trial_df=pd.concat([df.lemma_pos, df.year_counts.str.split(\"\\t\", expand=True)], axis=1)\n",
    "    trial_df=pd.melt(trial_df, id_vars=[\"lemma_pos\"], value_vars=list(range(len(trial_df.columns)-1))).dropna().drop(\"variable\", axis = 1)\n",
    "    trial_df[['year','count']] = trial_df.value.str.split(\",\", n=3, expand=True)[[0,1]]\n",
    "    return trial_df.drop(['value'],axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5c354a-6cb1-4248-a1be-18fe2cf1b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_joiner(df):\n",
    "    #print(df)\n",
    "    new_df=pd.DataFrame()\n",
    "    try:\n",
    "        new_df[['l1','l2','l3','l4','l5']]=df.lemma_sent.str.split(\" \",expand=True)\n",
    "        new_df[['p1','p2','p3','p4','p5']]=df.pos_sent.str.split(\" \",expand=True)\n",
    "    except:\n",
    "        print(df)\n",
    "    new_df['lemma_pos']=new_df.l1+\"_\"+new_df.p1+\" \"+\\\n",
    "                        new_df.l2+\"_\"+new_df.p2+\" \"+\\\n",
    "                        new_df.l3+\"_\"+new_df.p3+\" \"+\\\n",
    "                        new_df.l4+\"_\"+new_df.p4+\" \"+\\\n",
    "                        new_df.l5+\"_\"+new_df.p5\n",
    "    return new_df['lemma_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6429e6fd-9ee8-4bfe-93e7-1e8e87382b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnk='http://storage.googleapis.com/books/ngrams/books/20200217/eng/5-00835-of-19423.gz'\n",
    "index_df   = pd.read_csv(lnk, compression='gzip', header=None, sep=\"\\n\", quoting=csv.QUOTE_NONE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28e788e-bdde-4079-b716-9eb67caf9ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,_. which_DET emphasize_VERB the_DET individua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,_. what_PRON with_ADP you_PRON not_ADV\\t1979,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,_. when_ADV bankruptcy_NOUN proceedings_NOUN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,_. which_DET declared_VERB upon_ADP a_DET\\t18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,_. where_ADV Ben_NOUN Jonson_NOUN and_CONJ\\t1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436325</th>\n",
       "      <td>,_. when_ADV taking_VERB and_CONJ retention_NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436326</th>\n",
       "      <td>,_. which_DET has_VERB four_NUM elements_NOUN\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436327</th>\n",
       "      <td>,_. when_ADV he_PRON is_VERB divested_VERB\\t17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436328</th>\n",
       "      <td>,_. which_DET are_VERB clearly_ADV identifiabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436329</th>\n",
       "      <td>,_. where_ADV the_DET keep_NOUN is_VERB\\t1823,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3436330 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0\n",
       "0        ,_. which_DET emphasize_VERB the_DET individua...\n",
       "1        ,_. what_PRON with_ADP you_PRON not_ADV\\t1979,...\n",
       "2        ,_. when_ADV bankruptcy_NOUN proceedings_NOUN ...\n",
       "3        ,_. which_DET declared_VERB upon_ADP a_DET\\t18...\n",
       "4        ,_. where_ADV Ben_NOUN Jonson_NOUN and_CONJ\\t1...\n",
       "...                                                    ...\n",
       "3436325  ,_. when_ADV taking_VERB and_CONJ retention_NO...\n",
       "3436326  ,_. which_DET has_VERB four_NUM elements_NOUN\\...\n",
       "3436327  ,_. when_ADV he_PRON is_VERB divested_VERB\\t17...\n",
       "3436328  ,_. which_DET are_VERB clearly_ADV identifiabl...\n",
       "3436329  ,_. where_ADV the_DET keep_NOUN is_VERB\\t1823,...\n",
       "\n",
       "[3436330 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0790e0d0-b22a-4e47-b3b1-a99b0499a40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3436330"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "261e0464-26b6-402c-8fd9-5bc21f77085f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_index</th>\n",
       "      <th>year_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,_. which_DET emphasize_VERB the_DET individua...</td>\n",
       "      <td>1927,1,1\\t1941,1,1\\t1947,3,3\\t1953,4,4\\t1955,7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,_. what_PRON with_ADP you_PRON not_ADV</td>\n",
       "      <td>1979,1,1\\t1985,1,1\\t1989,1,1\\t1991,1,1\\t1998,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,_. when_ADV bankruptcy_NOUN proceedings_NOUN ...</td>\n",
       "      <td>1832,1,1\\t1876,3,3\\t1888,1,1\\t1895,1,1\\t1910,4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,_. which_DET declared_VERB upon_ADP a_DET</td>\n",
       "      <td>1874,2,2\\t1889,6,6\\t1897,9,6\\t1898,1,1\\t1900,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,_. where_ADV Ben_NOUN Jonson_NOUN and_CONJ</td>\n",
       "      <td>1803,2,2\\t1804,1,1\\t1806,1,1\\t1808,7,7\\t1809,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436325</th>\n",
       "      <td>,_. when_ADV taking_VERB and_CONJ retention_NOUN</td>\n",
       "      <td>1996,5,5\\t1997,3,3\\t1998,3,3\\t1999,2,2\\t2000,4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436326</th>\n",
       "      <td>,_. which_DET has_VERB four_NUM elements_NOUN</td>\n",
       "      <td>1920,9,9\\t1921,2,2\\t1922,1,1\\t1940,1,1\\t1955,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436327</th>\n",
       "      <td>,_. when_ADV he_PRON is_VERB divested_VERB</td>\n",
       "      <td>1721,1,1\\t1801,1,1\\t1809,1,1\\t1810,4,4\\t1811,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436328</th>\n",
       "      <td>,_. which_DET are_VERB clearly_ADV identifiabl...</td>\n",
       "      <td>1890,2,1\\t1897,1,1\\t1932,1,1\\t1933,1,1\\t1963,4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436329</th>\n",
       "      <td>,_. where_ADV the_DET keep_NOUN is_VERB</td>\n",
       "      <td>1823,1,1\\t1824,2,2\\t1826,13,13\\t1829,2,2\\t1839...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3436330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 old_index  \\\n",
       "0        ,_. which_DET emphasize_VERB the_DET individua...   \n",
       "1                  ,_. what_PRON with_ADP you_PRON not_ADV   \n",
       "2        ,_. when_ADV bankruptcy_NOUN proceedings_NOUN ...   \n",
       "3               ,_. which_DET declared_VERB upon_ADP a_DET   \n",
       "4              ,_. where_ADV Ben_NOUN Jonson_NOUN and_CONJ   \n",
       "...                                                    ...   \n",
       "3436325   ,_. when_ADV taking_VERB and_CONJ retention_NOUN   \n",
       "3436326      ,_. which_DET has_VERB four_NUM elements_NOUN   \n",
       "3436327         ,_. when_ADV he_PRON is_VERB divested_VERB   \n",
       "3436328  ,_. which_DET are_VERB clearly_ADV identifiabl...   \n",
       "3436329            ,_. where_ADV the_DET keep_NOUN is_VERB   \n",
       "\n",
       "                                               year_counts  \n",
       "0        1927,1,1\\t1941,1,1\\t1947,3,3\\t1953,4,4\\t1955,7...  \n",
       "1        1979,1,1\\t1985,1,1\\t1989,1,1\\t1991,1,1\\t1998,3...  \n",
       "2        1832,1,1\\t1876,3,3\\t1888,1,1\\t1895,1,1\\t1910,4...  \n",
       "3        1874,2,2\\t1889,6,6\\t1897,9,6\\t1898,1,1\\t1900,2...  \n",
       "4        1803,2,2\\t1804,1,1\\t1806,1,1\\t1808,7,7\\t1809,1...  \n",
       "...                                                    ...  \n",
       "3436325  1996,5,5\\t1997,3,3\\t1998,3,3\\t1999,2,2\\t2000,4...  \n",
       "3436326  1920,9,9\\t1921,2,2\\t1922,1,1\\t1940,1,1\\t1955,1...  \n",
       "3436327  1721,1,1\\t1801,1,1\\t1809,1,1\\t1810,4,4\\t1811,1...  \n",
       "3436328  1890,2,1\\t1897,1,1\\t1932,1,1\\t1933,1,1\\t1963,4...  \n",
       "3436329  1823,1,1\\t1824,2,2\\t1826,13,13\\t1829,2,2\\t1839...  \n",
       "\n",
       "[3436330 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df[['old_index','year_counts']]=index_df[0].str.split('\\t',n=1,expand=True)\n",
    "index_df=index_df.loc[index_df.old_index.str.match(\"^\"+keep_string*5+\"$\",na=False)]\n",
    "index_df.drop(0,axis=1,inplace=True)\n",
    "index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4f31c-4ca5-4060-a957-a4a8ae7ddb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parallelization\n"
     ]
    }
   ],
   "source": [
    "num_partitions=round(0.95*mp.cpu_count())\n",
    "cur_time=time.time()\n",
    "df_split = np.array_split(index_df, num_partitions)\n",
    "pool = Pool(num_partitions)\n",
    "print('Started parallelization')\n",
    "results=pool.map_async(index_processor,df_split)\n",
    "pool.close()\n",
    "pool.join()\n",
    "        \n",
    "        \n",
    "curr_df_list=results.get()\n",
    "new_index_df=pd.concat(curr_df_list,ignore_index=True)\n",
    "print(f'Total time taken {round(time.time()-cur_time)} secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1886b968-d93a-4925-b7bc-52fb3b25e614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3073386 entries, 0 to 3073385\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   0       object\n",
      "dtypes: object(1)\n",
      "memory usage: 23.4+ MB\n"
     ]
    }
   ],
   "source": [
    "index_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa290c54-13e5-4b8f-a932-5192e5b697a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_pos</th>\n",
       "      <th>pos_sent</th>\n",
       "      <th>year</th>\n",
       "      <th>comp_class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...</td>\n",
       "      <td>PUNCT PUNCT PUNCT PUNCT PUNCT</td>\n",
       "      <td>1868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...</td>\n",
       "      <td>PUNCT PUNCT PUNCT PUNCT PUNCT</td>\n",
       "      <td>1870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...</td>\n",
       "      <td>PUNCT PUNCT PUNCT PUNCT PUNCT</td>\n",
       "      <td>1875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...</td>\n",
       "      <td>PUNCT PUNCT PUNCT PUNCT PUNCT</td>\n",
       "      <td>1876</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...</td>\n",
       "      <td>PUNCT PUNCT PUNCT PUNCT PUNCT</td>\n",
       "      <td>1888</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60102870</th>\n",
       "      <td>\"_PUNCT be_AUX you_PRON listen_VERB to_ADP</td>\n",
       "      <td>PUNCT AUX PRON VERB ADP</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60102871</th>\n",
       "      <td>\"_PUNCT be_AUX you_PRON listen_VERB to_ADP</td>\n",
       "      <td>PUNCT AUX PRON VERB ADP</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60102872</th>\n",
       "      <td>\"_PUNCT be_AUX you_PRON listen_VERB to_ADP</td>\n",
       "      <td>PUNCT AUX PRON VERB ADP</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60102873</th>\n",
       "      <td>\"_PUNCT be_AUX you_PRON listen_VERB to_ADP</td>\n",
       "      <td>PUNCT AUX PRON VERB ADP</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60102874</th>\n",
       "      <td>\"_PUNCT be_AUX you_PRON listen_VERB to_ADP</td>\n",
       "      <td>PUNCT AUX PRON VERB ADP</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60102875 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  lemma_pos  \\\n",
       "0         \"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...   \n",
       "1         \"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...   \n",
       "2         \"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...   \n",
       "3         \"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...   \n",
       "4         \"_PUNCT \"_PUNCT \"_PUNCT \"_PUNCT --------------...   \n",
       "...                                                     ...   \n",
       "60102870         \"_PUNCT be_AUX you_PRON listen_VERB to_ADP   \n",
       "60102871         \"_PUNCT be_AUX you_PRON listen_VERB to_ADP   \n",
       "60102872         \"_PUNCT be_AUX you_PRON listen_VERB to_ADP   \n",
       "60102873         \"_PUNCT be_AUX you_PRON listen_VERB to_ADP   \n",
       "60102874         \"_PUNCT be_AUX you_PRON listen_VERB to_ADP   \n",
       "\n",
       "                               pos_sent  year  comp_class count  \n",
       "0         PUNCT PUNCT PUNCT PUNCT PUNCT  1868           0     1  \n",
       "1         PUNCT PUNCT PUNCT PUNCT PUNCT  1870           0     1  \n",
       "2         PUNCT PUNCT PUNCT PUNCT PUNCT  1875           0     1  \n",
       "3         PUNCT PUNCT PUNCT PUNCT PUNCT  1876           0     1  \n",
       "4         PUNCT PUNCT PUNCT PUNCT PUNCT  1888           0     2  \n",
       "...                                 ...   ...         ...   ...  \n",
       "60102870        PUNCT AUX PRON VERB ADP  2015           0     4  \n",
       "60102871        PUNCT AUX PRON VERB ADP  2016           0     6  \n",
       "60102872        PUNCT AUX PRON VERB ADP  2017           0     1  \n",
       "60102873        PUNCT AUX PRON VERB ADP  2018           0     4  \n",
       "60102874        PUNCT AUX PRON VERB ADP  2019           0     1  \n",
       "\n",
       "[60102875 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('/data/dharp/compounds/datasets/googleV3/69.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
